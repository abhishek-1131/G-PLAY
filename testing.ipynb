{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089916e0-d3a9-46d6-a1b0-f3d1d46c4728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "print(torch.zeros(1).cuda())\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "print(torch_geometric.__version__)\n",
    "\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType, OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "import networkx as nx\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import deepsnap\n",
    "from deepsnap.graph import Graph\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "from pathlib import Path as Data_Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import json\n",
    "print(\"graph-tool version: {}\".format(gt.__version__.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b44dcc-a8f9-42ad-8d4c-bf6bb5459424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../graph_pt_100.pickle\", \"rb\") as f:\n",
    "    final_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4dac8-bd7d-448d-a997-38828f47670f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of vertices:\", final_graph.num_vertices())\n",
    "print(\"Number of edges:\", final_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce8b6a-52c4-4ea4-8abc-9ddf8076e1cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('without artists as nodes:')\n",
    "print(\"Number of vertices:\", final_graph.num_vertices())\n",
    "print(\"Number of edges:\", final_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d7fb2-5821-48d9-9f8d-2bff99d281ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count_pl = sum(1 for v in final_graph.vertices() if final_graph.vp.pl_type[v] == \"playlist\")\n",
    "# print(f'num_playlists: {count_pl}')\n",
    "# count_tr = sum(1 for v in final_graph.vertices() if final_graph.vp.tr_type[v] == \"track\")\n",
    "# print(f'num_tracks: {count_tr}')\n",
    "# count_ar = sum(1 for v in final_graph.vertices() if final_graph.vp.ar_type[v] == \"artist\")\n",
    "# print(f'num_artist: {count_ar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff9dcb-d4d0-4d0e-96fd-87d382133bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('without artists as nodes:')\n",
    "count_pl = sum(1 for v in final_graph.vertices() if final_graph.vp.pl_type[v] == \"playlist\")\n",
    "print(f'num_playlists: {count_pl}')\n",
    "count_tr = sum(1 for v in final_graph.vertices() if final_graph.vp.tr_type[v] == \"track\")\n",
    "print(f'num_tracks: {count_tr}')\n",
    "count_ar = sum(1 for v in final_graph.vertices() if final_graph.vp.ar_type[v] == \"artist\")\n",
    "print(f'num_artist: {count_ar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f7199-da31-4214-b161-fb78c4bd3fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Removal of duplicate nodes from pickle file\n",
    "\n",
    "\n",
    "# prop_name = \"pl_type\"\n",
    "\n",
    "# # Create a dictionary of property values to vertex IDs\n",
    "# vertex_dict = {}\n",
    "# for v in final_graph.vertices():\n",
    "#     value = final_graph.vp[prop_name][v]\n",
    "#     if value not in vertex_dict:\n",
    "#         vertex_dict[value] = [int(v)]\n",
    "#     else:\n",
    "#         vertex_dict[value].append(int(v))\n",
    "\n",
    "# # Remove duplicate nodes\n",
    "# for value, ids in vertex_dict.items():\n",
    "#     if len(ids) > 1:\n",
    "#         print(value,ids)\n",
    "#         # # Merge the duplicate nodes into the first node\n",
    "#         # first_id = ids[0]\n",
    "#         # for other_id in ids[1:]:\n",
    "#         #     final_graph.vertex(first_id).out_edges()[:] = gt.find_edge(final_graph, final_graph.vertex(first_id), final_graph.vertex(other_id))\n",
    "#         #     final_graph.vertex(first_id).out_edges()[:] = gt.find_edge(final_graph, final_graph.vertex(other_id), final_graph.vertex(first_id))\n",
    "#         #     final_graph.remove_vertex(final_graph.vertex(other_id))\n",
    "\n",
    "\n",
    "# print(\"Number of vertices:\", final_graph.num_vertices())\n",
    "# print(\"Number of edges:\", final_graph.num_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc727a-3d43-464c-80cc-a632d1734eaf",
   "metadata": {},
   "source": [
    "### Largest component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c0c05-68c6-472b-bc4a-82b34f522814",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Graph-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdef74b-ab91-42cd-a3a8-c6417616e4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "largest_comp = gt.extract_largest_component(final_graph)\n",
    "# largest_comp = gt.GraphView(final_graph, vfilt = gt.label_largest_component(final_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c0969-d7e1-4f03-8944-c69bc2d3c082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('no artists:')\n",
    "print(\"Number of vertices:\", largest_comp.num_vertices()) \n",
    "print(\"Number of edges:\", largest_comp.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262e497-bab7-4459-b4c6-ffbd4d889e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('no artists stats:')\n",
    "print('----------------')\n",
    "count_pl = sum(1 for v in largest_comp.vertices() if largest_comp.vp.pl_type[v] == \"playlist\")\n",
    "print(f'num_playlists: {count_pl}')\n",
    "count_tr = sum(1 for v in largest_comp.vertices() if largest_comp.vp.tr_type[v] == \"track\")\n",
    "print(f'num_tracks: {count_tr}')\n",
    "count_ar = sum(1 for v in largest_comp.vertices() if largest_comp.vp.ar_type[v] == \"artist\")\n",
    "print(f'num_artist: {count_ar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e9154-e09f-436d-95b9-cd91d9a37bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #### Networkx\n",
    "# nx_graph = nx.Graph()\n",
    "# for node in final_graph.vertices():\n",
    "#     nx_graph.add_node(int(node))\n",
    "# for edge in final_graph.edges():\n",
    "#     nx_graph.add_edge(int(edge.source()), int(edge.target()))\n",
    "\n",
    "# from networkx.algorithms.components import is_connected\n",
    "# is_connected(nx_graph)\n",
    "\n",
    "# largest_cc = max(nx.connected_components(nx_graph), key=len)\n",
    "# nx_largest_comp = nx.Graph(nx_graph.subgraph(largest_cc))\n",
    "# print('Num nodes:', nx_largest_comp.number_of_nodes(), '. Num edges:', nx_largest_comp.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7eeef-d91c-4a0e-9a33-e2593ccedc3a",
   "metadata": {},
   "source": [
    "### Dataframe generation for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f164b8d-ec9a-493c-8417-d5ac9de71ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_playlist_df(playlist_id, playlist_json):\n",
    "    cols = ['plst_id', 'plst_name', 'track_id', 'track_name']\n",
    "    data_col = []\n",
    "    plst_name = playlist_json['name']\n",
    "    \n",
    "    for track in playlist_json['tracks']:\n",
    "        track_id = ''.join(track['track_uri'].split(':')[2:])\n",
    "        data_col.append([f'plst_{playlist_id}', plst_name, track_id, track['track_name']])\n",
    "        \n",
    "    plst_df = pd.DataFrame(data=data_col, columns=cols)\n",
    "    return plst_df\n",
    "\n",
    "def generate_file_df(start_index, file_json):\n",
    "    dfs = []\n",
    "    for i, plst_json in enumerate(file_json['playlists']):\n",
    "        dfs.append(generate_playlist_df(start_index + i, plst_json))\n",
    "        \n",
    "    df_sum = pd.concat(dfs)\n",
    "    return df_sum\n",
    "\n",
    "def generate_spotify_df(data_path, start_index=None, end_index=None):\n",
    "    assert (start_index is None and end_index is None) or \\\n",
    "        (start_index is not None and end_index is not None), 'Set both or none indices.'\n",
    "    json_names = [f for f in listdir(data_path) if isfile(join(data_path, f)) and '.json' in f]\n",
    "    \n",
    "    num_playlists = start_index if start_index is not None else 0\n",
    "    section = json_names if start_index is None else json_names[start_index:end_index]\n",
    "    dfs = []\n",
    "    \n",
    "    for file_name in tqdm(section, desc='Files processed: ', unit='files', total=len(section)):\n",
    "        with open(join(data_path, file_name)) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            \n",
    "        dfs.append(generate_file_df(num_playlists, data))\n",
    "        num_playlists += len(data['playlists'])\n",
    "        \n",
    "    df_total = pd.concat(dfs)\n",
    "    return df_total\n",
    "\n",
    "# data_path = '../data/'\n",
    "# df = generate_spotify_df(data_path, 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30978f4-29e7-4fb8-91b1-f435007437a2",
   "metadata": {},
   "source": [
    "### N-hop neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c5c22-2819-4ae6-88cc-7b97ae1ed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b137d90-07e9-4816-be08-3370a8a33e2a",
   "metadata": {},
   "source": [
    "### Deepsnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefdf07-327c-4f75-9070-3c49a5acb4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_nx = nx.Graph()\n",
    "\n",
    "g_nx = nx.Graph()\n",
    "for v in largest_comp.vertices():\n",
    "    g_nx.add_node(int(v))\n",
    "\n",
    "# Add edges to NetworkX graph in batches\n",
    "batch_size = 100000\n",
    "edges = [(int(e.source()), int(e.target())) for e in largest_comp.edges()]\n",
    "num_edges = len(edges)\n",
    "for i in range(0, num_edges, batch_size):\n",
    "    batch_edges = edges[i:i+batch_size]\n",
    "    g_nx.add_edges_from(batch_edges)\n",
    "\n",
    "        \n",
    "# Create a DeepSNAP graph from NetworkX graph\n",
    "ds_graph = Graph(g_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d20f51-8c12-4508-9960-95f10c63f857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of nodes:\", nx_graph.number_of_nodes())\n",
    "print(\"Number of edges:\", nx_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c05b5-8a28-4d3b-94d4-af5eb1a96032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of vertices:\", largest_comp.num_vertices()) \n",
    "print(\"Number of edges:\", largest_comp.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a015e-77b2-4dc5-8dfc-36a6ed6b694c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
