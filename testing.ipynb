{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089916e0-d3a9-46d6-a1b0-f3d1d46c4728",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], device='cuda:0')\n",
      "2.1.0\n",
      "graph-tool version: 2.46\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "print(torch.zeros(1).cuda())\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "print(torch_geometric.__version__)\n",
    "\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType, OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "import networkx as nx\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import deepsnap\n",
    "from deepsnap.graph import Graph\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "from pathlib import Path as Data_Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import json\n",
    "print(\"graph-tool version: {}\".format(gt.__version__.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b44dcc-a8f9-42ad-8d4c-bf6bb5459424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./fixed_graph.pickle\", \"rb\") as f:\n",
    "    g_nx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30978f4-29e7-4fb8-91b1-f435007437a2",
   "metadata": {},
   "source": [
    "### N-hop neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c5c22-2819-4ae6-88cc-7b97ae1ed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b137d90-07e9-4816-be08-3370a8a33e2a",
   "metadata": {},
   "source": [
    "### Deepsnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4561d2-c5a2-4ef1-adb8-c4db66a671f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DeepSNAP graph from NetworkX graph\n",
    "ds_graph = Graph(g_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f263f-9347-4ecc-9f15-ddf36cd2f968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of vertices:\", g_nx.number_of_nodes())\n",
    "print(\"Number of edges:\", g_nx.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5773f4-4af4-49ea-ba46-781b4fa3aca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = 'link_pred'\n",
    "dataset = GraphDataset([ds_graph], task=task, edge_train_mode='disjoint')\n",
    "\n",
    "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "# dataset_train[0].to('cuda')\n",
    "# dataset_val[0].to('cuda')\n",
    "# dataset_test[0].to('cuda')\n",
    "\n",
    "# dataset_train.to('cuda:0')\n",
    "# dataset_val.to('cuda:0')\n",
    "# dataset_test.to('cuda:0')\n",
    "\n",
    "print(type(dataset_train))\n",
    "print(dataset_train[0])\n",
    "print(type(dataset_train[0]))\n",
    "\n",
    "num_train_edges = dataset_train[0].edge_label_index.shape[1]\n",
    "num_val_edges = dataset_val[0].edge_label_index.shape[1]\n",
    "num_test_edges = dataset_test[0].edge_label_index.shape[1]\n",
    "\n",
    "print(\"Train set has {} supervision (positive) edges\".format(num_train_edges // 2))\n",
    "print(\"Validation set has {} supervision (positive) edges\".format(num_val_edges // 2))\n",
    "print(\"Test set has {} supervision (positive) edges\".format(num_test_edges // 2))\n",
    "\n",
    "print(\"Train set has {} message passing edges\".format(dataset_train[0].edge_index.shape[1]))\n",
    "print(\"Validation set has {} message passing edges\".format(dataset_val[0].edge_index.shape[1]))\n",
    "print(\"Test set has {} message passing edges\".format(dataset_test[0].edge_index.shape[1]))\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa4e94-d8a1-433b-a88c-961e33870a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle.dump(dataset_train, open('./fixed_graphs/train.graph', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828e39d-23b7-45f8-9d9a-cc3fa7fc8d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle.dump(dataset_val, open('./fixed_graphs/val.graph', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a09dcb-a22d-4b97-9200-dcc4fddd6a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle.dump(dataset_test, open('./fixed_graphs/test.graph', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124d69ee-b24a-4097-9f11-118f745d3214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = pickle.load(open('/home/asd27/scratch/fixed_graphs/train.graph', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ddbeb4a-e009-462e-b80f-a1ae1cf9caed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_val = pickle.load(open('/home/asd27/scratch/fixed_graphs/val.graph', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec371b74-534b-46d8-894a-17868d499384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dill\n",
      "Successfully installed dill-0.3.6\n"
     ]
    }
   ],
   "source": [
    "!pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9f67f66-d8f3-48cf-9c45-1bb84a966a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x00'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdill\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/asd27/scratch/fixed_graphs/test.graph\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     dataset_test \u001b[38;5;241m=\u001b[39m dill\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/.conda/envs/cudatorch/lib/python3.11/site-packages/dill/_dill.py:272\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, ignore, **kwds)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(file, ignore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    Unpickle an object from a file.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    See :func:`loads` for keyword arguments.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Unpickler(file, ignore\u001b[38;5;241m=\u001b[39mignore, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[0;32m~/.conda/envs/cudatorch/lib/python3.11/site-packages/dill/_dill.py:419\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     obj \u001b[38;5;241m=\u001b[39m StockUnpickler\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_main_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore:\n\u001b[1;32m    422\u001b[0m             \u001b[38;5;66;03m# point obj class to main\u001b[39;00m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x00'."
     ]
    }
   ],
   "source": [
    "import dill\n",
    "with open('/home/asd27/scratch/fixed_graphs/test.graph', 'rb') as f:\n",
    "    dataset_test = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6b4776-f7c8-4d25-80a0-6bde823c866b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_test = pickle.load(open('/home/asd27/scratch/fixed_graphs/test.graph', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59dec8f-30e8-4c5b-ab48-3cccfff33387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, normalize = True,\n",
    "                 bias = False, **kwargs):  \n",
    "        super(LightGCNConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        out = self.propagate(edge_index, x=(x, x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        out = x_j\n",
    "        return out\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "        node_dim = self.node_dim\n",
    "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce='mean')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff20e2-0434-4fd8-89a1-e8db325c3e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGCN(torch.nn.Module):\n",
    "    def __init__(self, train_data, num_layers, emb_size=16, initialize_with_words=False):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        assert (num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(num_layers):\n",
    "            self.convs.append(LightGCNConv(input_dim, input_dim))\n",
    "\n",
    "        # Initialize using custom embeddings if provided\n",
    "        num_nodes = train_data.node_label_index.size()[0]\n",
    "        self.embeddings = nn.Embedding(num_nodes, emb_size)\n",
    "        if initialize_with_words:\n",
    "            self.embeddings.weight.data.copy_(train_datanode_features)\n",
    "        \n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.num_layers = num_layers\n",
    "        self.emb_size = emb_size\n",
    "        self.num_modes = num_nodes\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index, edge_label_index, node_label_index = data.edge_index, data.edge_label_index, data.node_label_index\n",
    "        layer_embeddings = []\n",
    "        \n",
    "        x = self.embeddings(node_label_index)\n",
    "        mean_layer = x\n",
    "\n",
    "        # We take an average of ever layer's node embeddings\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            # print(\"x shape\",x.shape)\n",
    "            # print(\"mean_layer shape\",mean_layer.shape)\n",
    "            mean_layer += x\n",
    "\n",
    "        mean_layer /= 4\n",
    "\n",
    "        # Prediction head is simply dot product\n",
    "        nodes_first = torch.index_select(x, 0, edge_label_index[0,:].long())\n",
    "        nodes_second = torch.index_select(x, 0, edge_label_index[1,:].long())\n",
    "\n",
    "        # Since we don't want a rank output, we create a sigmoid of the dot product\n",
    "        out = torch.sum(nodes_first * nodes_second, dim=-1) # FOR RANKING\n",
    "        pred = torch.sigmoid(out)\n",
    "\n",
    "        return torch.flatten(pred)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return self.loss_fn(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fffe68-e6e4-4892-9b18-13be04810acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633e9c3-115c-4ed1-a559-c6d2d9267b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe5156-60c7-4699-93f5-03466c7433d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device' : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_layers' : 3,\n",
    "    'emb_size' : 32,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr': 0.04,\n",
    "    'epochs': 600\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    'train': dataset_train[0],\n",
    "    'val': dataset_val[0],\n",
    "    'test': dataset_test[0]\n",
    "}\n",
    "            \n",
    "input_dim = datasets['train'].num_node_features\n",
    "print(input_dim, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65aa42-8be4-450f-bdec-aa2206feb866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasets['train'].to(args['device'])\n",
    "# datasets['val'].to(args['device'])\n",
    "# datasets['test'].to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941df0fc-fc53-4f9d-b457-b2c562175a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "def train(model, optimizer, args):\n",
    "    val_max = 0\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        datasets['train'].to(args[\"device\"])\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(datasets['train'])\n",
    "        loss = model.loss(pred, datasets['train'].edge_label.type(pred.dtype))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {:.5f}, Val Loss: {:.5f}'\n",
    "        score_train, train_loss = test(model, 'train', args)\n",
    "        score_val, val_loss = test(model, 'val', args)\n",
    "        score_test, test_loss = test(model, 'test', args)\n",
    "\n",
    "        losses.append((train_loss, val_loss))\n",
    "\n",
    "        print(log.format(epoch, score_train, score_val, score_test, train_loss, val_loss))\n",
    "        if val_max < score_val:\n",
    "            val_max = score_val\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def test(model, mode, args):\n",
    "    model.eval()\n",
    "    score = 0\n",
    "    loss_score = 0\n",
    "\n",
    "    data = datasets[mode]\n",
    "    data.to(args[\"device\"])\n",
    "\n",
    "    pred = model(data)\n",
    "    loss = model.loss(pred, data.edge_label.type(pred.dtype))\n",
    "    score += roc_auc_score(data.edge_label.flatten().cpu().numpy(), pred.flatten().data.cpu().numpy())\n",
    "    loss_score += loss.item()\n",
    "\n",
    "    return score, loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a086b9-3cef-4997-b090-d44296f688d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed78571-2201-450e-a3aa-6bd29ba4529e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LightGCN(datasets['train'], args['num_layers'], emb_size=args['emb_size']).to(args['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "best_model = train(model, optimizer, args)\n",
    "log = \"Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Train Loss: {:.5f}, Val Loss: {:.5f}, Test Loss: {:.5f}\"\n",
    "best_train_roc, train_loss = test(best_model, 'train', args)\n",
    "best_val_roc, val_loss = test(best_model, 'val', args)\n",
    "best_test_roc, test_loss = test(best_model, 'test', args)\n",
    "print(log.format(best_train_roc, best_val_roc, best_test_roc, train_loss, val_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df4188-1bed-4ab8-9ed3-fff30a3a0207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639674ee-a6bb-4de5-8d98-6dc8ea3222ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_save\n",
    "filename = 'best_lgcn.pkl'\n",
    "torch.save(best_model, filename)\n",
    "\n",
    "#datasets save\n",
    "# with open('datasets_deepsnap_dict.pkl', 'wb') as f:\n",
    "#     # pickle the dictionary and write it to the file\n",
    "#     pickle.dump(datasets, f)\n",
    "\n",
    "# model = torch.load('../lgcn.pkl')\n",
    "# with open('../datasets_deepsnap_dict.pkl', 'rb') as f:\n",
    "#     # load the pickled dictionary from the file\n",
    "#     datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06e0ad-076a-4fb0-aa5f-1104ca357558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(losses, title):\n",
    "    train_loss, val_loss = zip(*losses)\n",
    "    steps = list(range(1, len(train_loss) + 1))\n",
    "    \n",
    "    min_val_loss = np.round(np.min(val_loss), 3)\n",
    "    # train_list = [math.log10(x) for x in train_loss]\n",
    "    # val_list = [math.log10(x) for x in val_loss]\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.plot(steps, train_loss, '-r', label='Training Loss')\n",
    "    plt.plot(steps, val_loss, '-b', label='Validation Loss')\n",
    "    plt.hlines(min_val_loss, 1, 300, colors='k', linestyles='dotted', label='Min Validation Loss: {}'.format(min_val_loss))\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.ylim((0.58, 0.71))\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bc6a1-38ca-49d8-9ecc-1d9be4dd8d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(losses, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4dfc4-cc06-41fd-a294-bf2cf2690035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = datasets['test']\n",
    "pred = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b551daf-fd42-455c-ac80-b9aa0908fe81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77372322-0b1e-4470-92ae-a839a2abfd74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e03714-d91b-4cc9-b2fb-ceffeb950090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = datasets['test']\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8a5a8-056c-4dc1-a4c0-c4b272c0af85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e088514-d2e7-48b0-80a7-def67abae7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(ds.edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba87275-4205-40ac-b8f6-774768d24d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict1 = {'preds':pred.to('cpu').detach().numpy(), 'edge_label': ds.edge_label.to('cpu').detach().numpy(), 'src_node': ds.edge_label_index[0].to('cpu').detach().numpy(), 'dest_node': ds.edge_label_index[1].to('cpu').detach().numpy()}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fb42-fc5b-4151-931b-dc027d0cf224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_0 = df[df['edge_label'] == 0]\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15da10-f9e0-405f-97be-39d17965ea92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_1 = df[df['edge_label'] == 1]\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0e93e-b815-47f1-8a14-6b56b4ac0f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lessthan = df_1[df_1['preds'] > 0.5]\n",
    "df_lessthan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549d1f9-a11c-4316-8db8-46f1eba89cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lessthan.iloc[0]['src_node']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9737a6-f63e-43e4-86c2-3f7817d9120f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_nx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a70249-0d4c-4d83-9356-4927956b0d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lessthan.iloc[0][\"src_node\"]\n",
    "counter=0\n",
    "neg=0\n",
    "for x in g_nx.nodes:\n",
    "    if(counter!=x):\n",
    "        neg=neg+x-counter\n",
    "        counter=x\n",
    "    counter=counter+1\n",
    "print(len(g_nx.nodes))\n",
    "neg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84feddca-e722-4ba3-88f6-52870d95a38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc283a02-b0bc-49ea-8776-0b79f321be6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def row_op(row):\n",
    "\n",
    "    if g_nx.nodes[row['src_node']]['name'] == g_nx.nodes[row['dest_node']]['name'] or g_nx.nodes[row['src_node']]['uri'] == g_nx.nodes[row['dest_node']]['uri']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df_lessthan['is_valid'] = df_lessthan.apply(row_op,axis=1)\n",
    "df_filter=df_lessthan[df_lessthan['is_valid']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d3ae7-48bf-480d-a8de-883fa4c6085f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getId(row):\n",
    "    return pd.Series([g_nx.nodes[row['src_node']]['name'],g_nx.nodes[row['src_node']]['uri'],g_nx.nodes[row['src_node']]['type'],g_nx.nodes[row['dest_node']]['name'],g_nx.nodes[row['dest_node']]['uri'],g_nx.nodes[row['dest_node']]['type']])\n",
    "    \n",
    "df_filter[[\"src_name\",\"src_uri\",\"src_type\",\"dest_name\",\"dest_uri\",\"dest_type\"]]=df_filter[df_lessthan['is_valid']].apply(getId,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95775e86-1b83-4f29-b8b5-373e2f0de91e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f80f71-0bae-46b0-bb2d-411ee0015f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_filter[(df_filter['src_name']==\"Party mix\") | ( df_filter['dest_name']==\"Party mix\") ]\n",
    "df_final.sort_values('preds',ascending=False)\n",
    "uri_list=list(df_final.apply(lambda x: x['src_uri'] if x['src_uri']!='' else x['dest_uri'], axis=1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8a113-86ca-4a1d-96d3-4fba616b28c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5ba22-cf68-4f75-9e03-22f582a16315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uri_list=[]\n",
    "uri_list = list(df_final[\"dest_uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083828e-03cc-4ce3-9494-fd35a83ae9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555332b-4acd-4e25-8649-8c794c3fbb23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07ffd0-0996-4152-8860-2de9e3b8762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "def gettrackname(uri_list):\n",
    "    # Replace the values below with your own Spotify API credentials\n",
    "    client_id = 'd5566a60926740f3a8070889731a2d21'\n",
    "    client_secret = 'eb5fc0638a1241c3a611186ff8d167e3'\n",
    "\n",
    "    # Initialize the Spotify API client\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "    info = []\n",
    "    for uri in uri_list:\n",
    "        # Use the track method to get information about the track\n",
    "        track_info = sp.track(uri)\n",
    "\n",
    "        # Get the track name from the track information\n",
    "        track_name = track_info['name']\n",
    "        track_info = sp.track(uri)\n",
    "\n",
    "        # Get the artist name from the track information\n",
    "        artist_name = track_info['artists'][0]['name']\n",
    "        info.append((track_name, artist_name))\n",
    "        \n",
    "    return info\n",
    "\n",
    "print(gettrackname(uri_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97554ce9-7e68-4b62-8185-f6266bf56a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81b8d7-8780-46d1-8f13-6b622f83928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b4c06-d86a-4359-9420-63bdb8742c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df22e9-6716-4101-a0a9-7a06fdace80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0b57a-939a-43c7-b90e-81f7a512aa86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d4504-c4c3-41a6-a184-7c10579874af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
