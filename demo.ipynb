{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "089916e0-d3a9-46d6-a1b0-f3d1d46c4728",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], device='cuda:0')\n",
      "2.1.0\n",
      "graph-tool version: 2.46\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "print(torch.zeros(1).cuda())\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "print(torch_geometric.__version__)\n",
    "\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType, OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "import networkx as nx\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import deepsnap\n",
    "from deepsnap.graph import Graph\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "from pathlib import Path as Data_Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import json\n",
    "print(\"graph-tool version: {}\".format(gt.__version__.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33b44dcc-a8f9-42ad-8d4c-bf6bb5459424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../graph_pt_100.pickle\", \"rb\") as f:\n",
    "    final_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1d4dac8-bd7d-448d-a997-38828f47670f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 3644438\n",
      "Number of edges: 6746550\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of vertices:\", final_graph.num_vertices())\n",
    "print(\"Number of edges:\", final_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82ce8b6a-52c4-4ea4-8abc-9ddf8076e1cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without artists as nodes:\n",
      "Number of vertices: 3644438\n",
      "Number of edges: 6746550\n"
     ]
    }
   ],
   "source": [
    "print('without artists as nodes:')\n",
    "print(\"Number of vertices:\", final_graph.num_vertices())\n",
    "print(\"Number of edges:\", final_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a1d7fb2-5821-48d9-9f8d-2bff99d281ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count_pl = sum(1 for v in final_graph.vertices() if final_graph.vp.pl_type[v] == \"playlist\")\n",
    "# print(f'num_playlists: {count_pl}')\n",
    "# count_tr = sum(1 for v in final_graph.vertices() if final_graph.vp.tr_type[v] == \"track\")\n",
    "# print(f'num_tracks: {count_tr}')\n",
    "# count_ar = sum(1 for v in final_graph.vertices() if final_graph.vp.ar_type[v] == \"artist\")\n",
    "# print(f'num_artist: {count_ar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3ff9dcb-d4d0-4d0e-96fd-87d382133bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without artists as nodes:\n",
      "num_playlists: 102000\n",
      "num_tracks: 3542438\n",
      "num_artist: 0\n"
     ]
    }
   ],
   "source": [
    "print('without artists as nodes:')\n",
    "count_pl = sum(1 for v in final_graph.vertices() if final_graph.vp.pl_type[v] == \"playlist\")\n",
    "print(f'num_playlists: {count_pl}')\n",
    "count_tr = sum(1 for v in final_graph.vertices() if final_graph.vp.tr_type[v] == \"track\")\n",
    "print(f'num_tracks: {count_tr}')\n",
    "count_ar = sum(1 for v in final_graph.vertices() if final_graph.vp.ar_type[v] == \"artist\")\n",
    "print(f'num_artist: {count_ar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f07f7199-da31-4214-b161-fb78c4bd3fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Removal of duplicate nodes from pickle file\n",
    "\n",
    "\n",
    "# prop_name = \"pl_type\"\n",
    "\n",
    "# # Create a dictionary of property values to vertex IDs\n",
    "# vertex_dict = {}\n",
    "# for v in final_graph.vertices():\n",
    "#     value = final_graph.vp[prop_name][v]\n",
    "#     if value not in vertex_dict:\n",
    "#         vertex_dict[value] = [int(v)]\n",
    "#     else:\n",
    "#         vertex_dict[value].append(int(v))\n",
    "\n",
    "# # Remove duplicate nodes\n",
    "# for value, ids in vertex_dict.items():\n",
    "#     if len(ids) > 1:\n",
    "#         print(value,ids)\n",
    "#         # # Merge the duplicate nodes into the first node\n",
    "#         # first_id = ids[0]\n",
    "#         # for other_id in ids[1:]:\n",
    "#         #     final_graph.vertex(first_id).out_edges()[:] = gt.find_edge(final_graph, final_graph.vertex(first_id), final_graph.vertex(other_id))\n",
    "#         #     final_graph.vertex(first_id).out_edges()[:] = gt.find_edge(final_graph, final_graph.vertex(other_id), final_graph.vertex(first_id))\n",
    "#         #     final_graph.remove_vertex(final_graph.vertex(other_id))\n",
    "\n",
    "\n",
    "# print(\"Number of vertices:\", final_graph.num_vertices())\n",
    "# print(\"Number of edges:\", final_graph.num_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc727a-3d43-464c-80cc-a632d1734eaf",
   "metadata": {},
   "source": [
    "### Largest component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c0c05-68c6-472b-bc4a-82b34f522814",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Graph-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbdef74b-ab91-42cd-a3a8-c6417616e4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "largest_comp = gt.extract_largest_component(final_graph)\n",
    "# largest_comp = gt.GraphView(final_graph, vfilt = gt.label_largest_component(final_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e55c0969-d7e1-4f03-8944-c69bc2d3c082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no artists:\n",
      "Number of vertices: 38565\n",
      "Number of edges: 6746550\n"
     ]
    }
   ],
   "source": [
    "print('no artists:')\n",
    "print(\"Number of vertices:\", largest_comp.num_vertices()) \n",
    "print(\"Number of edges:\", largest_comp.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f262e497-bab7-4459-b4c6-ffbd4d889e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no artists stats:\n",
      "----------------\n",
      "num_playlists: 2999\n",
      "num_tracks: 35566\n",
      "num_artist: 0\n"
     ]
    }
   ],
   "source": [
    "print('no artists stats:')\n",
    "print('----------------')\n",
    "count_pl = sum(1 for v in largest_comp.vertices() if largest_comp.vp.pl_type[v] == \"playlist\")\n",
    "print(f'num_playlists: {count_pl}')\n",
    "count_tr = sum(1 for v in largest_comp.vertices() if largest_comp.vp.tr_type[v] == \"track\")\n",
    "print(f'num_tracks: {count_tr}')\n",
    "count_ar = sum(1 for v in largest_comp.vertices() if largest_comp.vp.ar_type[v] == \"artist\")\n",
    "print(f'num_artist: {count_ar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c1e9154-e09f-436d-95b9-cd91d9a37bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #### Networkx\n",
    "# nx_graph = nx.Graph()\n",
    "# for node in final_graph.vertices():\n",
    "#     nx_graph.add_node(int(node))\n",
    "# for edge in final_graph.edges():\n",
    "#     nx_graph.add_edge(int(edge.source()), int(edge.target()))\n",
    "\n",
    "# from networkx.algorithms.components import is_connected\n",
    "# is_connected(nx_graph)\n",
    "\n",
    "# largest_cc = max(nx.connected_components(nx_graph), key=len)\n",
    "# nx_largest_comp = nx.Graph(nx_graph.subgraph(largest_cc))\n",
    "# print('Num nodes:', nx_largest_comp.number_of_nodes(), '. Num edges:', nx_largest_comp.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30978f4-29e7-4fb8-91b1-f435007437a2",
   "metadata": {},
   "source": [
    "### N-hop neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "590c5c22-2819-4ae6-88cc-7b97ae1ed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b137d90-07e9-4816-be08-3370a8a33e2a",
   "metadata": {},
   "source": [
    "### Deepsnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb4561d2-c5a2-4ef1-adb8-c4db66a671f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_nx = nx.Graph()\n",
    "\n",
    "# Add edges to NetworkX graph in batches\n",
    "nx_g = nx.Graph()\n",
    "for v in largest_comp.vertices():\n",
    "    if(largest_comp.vp.pl_type[v]=='playlist'):\n",
    "        typ='playlist'\n",
    "    elif(largest_comp.vp.tr_type[v] == \"track\"):\n",
    "        typ='track'\n",
    "    node_attributes = {'name':largest_comp.vp.pl_name[v], 'uri':largest_comp.vp.tr_uri[v], 'type':typ}\n",
    "    g_nx.add_node(int(v), **node_attributes)\n",
    "for e in largest_comp.edges():\n",
    "    g_nx.add_edge(int(e.source()), int(e.target()))\n",
    "    \n",
    "mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(g_nx.nodes()))}\n",
    "\n",
    "# reindex the nodes in the graph\n",
    "g_nx = nx.relabel_nodes(g_nx, mapping)\n",
    "        \n",
    "# Create a DeepSNAP graph from NetworkX graph\n",
    "ds_graph = Graph(g_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd00cadd-fbf1-4f34-a842-c85bdee64e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('g_nx.pickle', 'wb') as f:\n",
    "    pickle.dump(g_nx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dfdfc3d-2c82-4cd1-bdf2-d29916f54315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Awesome Playlist', 'uri': '', 'type': 'playlist'}\n"
     ]
    }
   ],
   "source": [
    "print(g_nx.nodes[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf8392c6-9ca4-4c19-b7c3-e1e144a8e27b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(560, 23578), (560, 23579), (560, 23580), (560, 23581), (560, 23582), (560, 23583), (560, 23584), (560, 23585), (560, 23586), (560, 23587), (560, 23588), (560, 23589), (560, 23590), (560, 23591), (560, 23592), (560, 23593), (560, 23594), (560, 23595), (560, 23596), (560, 23597), (560, 23598), (560, 23599), (560, 24626), (560, 24627), (560, 24628), (560, 24629), (560, 24630), (560, 24631), (560, 24632), (560, 24633), (560, 24634), (560, 24635), (560, 24636), (560, 24637), (560, 24638), (560, 24639), (560, 24640), (560, 24641), (560, 24642), (560, 24643), (560, 24644), (560, 24645), (560, 24646), (560, 24647), (560, 24648), (560, 24649), (560, 24650), (560, 24651), (560, 24652), (560, 24653), (560, 24654), (560, 24655), (560, 24656), (560, 24657), (560, 24658), (560, 24659), (560, 24660), (560, 24661), (560, 24662), (560, 24663), (560, 24664), (560, 24665), (560, 24666), (560, 24667), (560, 24668), (560, 24669), (560, 24670), (560, 24671), (560, 24672), (560, 24673), (560, 24674), (560, 24675), (560, 24676), (560, 24677), (560, 24678), (560, 24564), (560, 24565), (560, 24566), (560, 24567), (560, 24568), (560, 24569), (560, 23810), (560, 23811), (560, 23812), (560, 23813), (560, 23814), (560, 23815), (560, 23816), (560, 23817), (560, 23818), (560, 23819), (560, 23820), (560, 23821), (560, 23822), (560, 23823), (560, 23824), (560, 23825), (560, 23826), (560, 23827), (560, 23828), (560, 23829), (560, 23830), (560, 23831), (560, 23832), (560, 23833), (560, 23834), (560, 23835), (560, 23836), (560, 23837), (560, 23838), (560, 23839), (560, 23840), (560, 23841), (560, 23842), (560, 23843), (560, 23844), (560, 23845), (560, 23846), (560, 23847), (560, 23848), (560, 23849), (560, 23850), (560, 23851), (560, 23852), (560, 23853), (560, 23854), (560, 23855), (560, 23856), (560, 23857), (560, 23858), (560, 23859), (560, 23860), (560, 23861), (560, 24679), (560, 24680), (560, 24681), (560, 24682), (560, 24683), (560, 24684), (560, 24685), (560, 24686), (560, 24687), (560, 24688), (560, 24689), (560, 24690), (560, 24691), (560, 24692), (560, 24693), (560, 24694), (560, 24695), (560, 24696), (560, 24697), (560, 24698), (560, 24699), (560, 24700), (560, 24701), (560, 24702), (560, 24703), (560, 24704), (560, 24705), (560, 24751), (560, 24752), (560, 24753), (560, 24754), (560, 24755), (560, 24756), (560, 24757), (560, 24758), (560, 24759), (560, 24760), (560, 24761), (560, 24762), (560, 24763), (560, 24764), (560, 24765), (560, 24766), (560, 24767), (560, 24768), (560, 24769), (560, 24770), (560, 24771), (560, 24772), (560, 24773), (560, 24774), (560, 24775), (560, 24776), (560, 24777), (560, 24778), (560, 24779), (560, 24780), (560, 24781), (560, 24782), (560, 24783), (560, 24784), (560, 24785), (560, 24786), (560, 24787), (560, 24788), (560, 24789), (560, 24790), (560, 24791), (560, 24792), (560, 24793), (560, 24794), (560, 24795), (560, 24796), (560, 22870), (560, 22871), (560, 22872), (560, 22873), (560, 22874), (560, 22875), (560, 23133), (560, 23134), (560, 23135), (560, 23136), (560, 23137), (560, 23138), (560, 23139), (560, 23140), (560, 23141), (560, 23142), (560, 23143), (560, 23144), (560, 23145), (560, 23146), (560, 23147), (560, 23148), (560, 23149), (560, 23150), (560, 23151), (560, 23152), (560, 23153), (560, 23154), (560, 23155), (560, 23156), (560, 23157), (560, 23158), (560, 23159), (560, 23160), (560, 23161), (560, 23162), (560, 23163), (560, 23164), (560, 23165), (560, 23166), (560, 23167), (560, 23168), (560, 23169), (560, 23170), (560, 23171), (560, 23172), (560, 23173), (560, 23174), (560, 24859), (560, 24860), (560, 24861), (560, 24862), (560, 24863), (560, 24864), (560, 24865), (560, 24866), (560, 24867), (560, 22577), (560, 22578), (560, 22579), (560, 22580), (560, 22581), (560, 22582), (560, 22583), (560, 22584), (560, 22585), (560, 22586), (560, 22587), (560, 22588), (560, 22589), (560, 22590), (560, 22591), (560, 22592), (560, 22593), (560, 22594), (560, 22595), (560, 22596), (560, 22597), (560, 22598), (560, 22599), (560, 22600), (560, 22601), (560, 22602), (560, 22603), (560, 22604), (560, 22605), (560, 22606), (560, 22607), (560, 22608), (560, 22609), (560, 22610), (560, 22611), (560, 22612), (560, 22613), (560, 22614), (560, 22615), (560, 22616), (560, 22617), (560, 22618), (560, 22619), (560, 22620), (560, 22621), (560, 22444), (560, 22445), (560, 22446), (560, 22447), (560, 22448), (560, 23880), (560, 23881), (560, 23882), (560, 23883), (560, 23884), (560, 23885), (560, 23886), (560, 23887), (560, 23888), (560, 23889), (560, 23890), (560, 23891), (560, 23892), (560, 23893), (560, 23894), (560, 23895), (560, 23896), (560, 23897), (560, 23898), (560, 23899), (560, 23900), (560, 23901), (560, 23902), (560, 23903), (560, 23904), (560, 23905), (560, 23906), (560, 23907), (560, 23908), (560, 23909), (560, 23910), (560, 23911), (560, 23912), (560, 23913), (560, 23914), (560, 23915), (560, 23916), (560, 23917), (560, 23918), (560, 23919), (560, 23920), (560, 23921), (560, 23922), (560, 23923), (560, 23924), (560, 23925), (560, 23926), (560, 23927), (560, 23928), (560, 23929), (560, 23930), (560, 23931), (560, 23932), (560, 23933), (560, 23934), (560, 23935), (560, 23936), (560, 23937), (560, 23938), (560, 23939), (560, 23940), (560, 23941), (560, 23942), (560, 23943), (560, 23944), (560, 23945), (560, 23946), (560, 23947), (560, 23948), (560, 23949), (560, 23950), (560, 24522), (560, 24523), (560, 24524), (560, 24525), (560, 24526), (560, 24527), (560, 24528), (560, 24529), (560, 24530), (560, 24531), (560, 24532), (560, 24533), (560, 24534), (560, 24535), (560, 24536), (560, 24537), (560, 24538), (560, 23687), (560, 23688), (560, 23689), (560, 23690), (560, 23691), (560, 23692), (560, 23693), (560, 23694), (560, 23695), (560, 23696), (560, 23697), (560, 23698), (560, 23699), (560, 23700), (560, 23701), (560, 23702), (560, 23703), (560, 23704), (560, 23705), (560, 23706), (560, 23707), (560, 23708), (560, 23709), (560, 23710), (560, 23711), (560, 23712), (560, 23713), (560, 23714), (560, 23715), (560, 23716), (560, 23717), (560, 23718), (560, 23719), (560, 23720), (560, 23721), (560, 23722), (560, 23723), (560, 23724), (560, 23725), (560, 23726), (560, 23727), (560, 23728), (560, 23729), (560, 23730), (560, 23731), (560, 23732), (560, 23733), (560, 23734), (560, 23735), (560, 23736), (560, 23737), (560, 23738), (560, 23739), (560, 23740), (560, 23741), (560, 23742), (560, 23743), (560, 23744), (560, 23745), (560, 23746), (560, 23747), (560, 23748), (560, 23749), (560, 23750), (560, 23751), (560, 23752), (560, 23753), (560, 23754), (560, 23755), (560, 23756), (560, 23757), (560, 23758), (560, 23759), (560, 23760), (560, 23761), (560, 23762), (560, 23763), (560, 23764), (560, 23765), (560, 23766), (560, 23767), (560, 23768), (560, 23769), (560, 23770), (560, 23771), (560, 23772), (560, 23773), (560, 23774), (560, 23775), (560, 23776), (560, 23777), (560, 23778), (560, 23779), (560, 23780), (560, 23781), (560, 23782), (560, 23783), (560, 23784), (560, 23785), (560, 23786), (560, 23787), (560, 23788), (560, 23789), (560, 23790), (560, 23791), (560, 23792), (560, 23793), (560, 23794), (560, 23795), (560, 23796), (560, 23797), (560, 23798), (560, 23799), (560, 23800), (560, 23801), (560, 23802), (560, 23803), (560, 23804), (560, 23805), (560, 23806), (560, 23807), (560, 23808), (560, 23809), (560, 23960), (560, 23961), (560, 23962), (560, 24913), (560, 24914), (560, 24915), (560, 24916), (560, 24917), (560, 24918), (560, 24919), (560, 24920), (560, 24921), (560, 24922), (560, 24923), (560, 24924), (560, 24925), (560, 24926), (560, 24927), (560, 24928), (560, 24929), (560, 24930), (560, 24931), (560, 24932), (560, 24933), (560, 24934), (560, 24935), (560, 24936), (560, 24937), (560, 24938), (560, 24939), (560, 24940), (560, 24941), (560, 24942), (560, 24943), (560, 24944), (560, 24945), (560, 24946), (560, 24947), (560, 24948), (560, 24949), (560, 24950), (560, 24951), (560, 24952), (560, 24953), (560, 24954), (560, 24955), (560, 24956), (560, 24957), (560, 24958), (560, 24959), (560, 24960), (560, 24961), (560, 24962), (560, 24963), (560, 24964), (560, 24965), (560, 24966), (560, 24967), (560, 24968), (560, 24969), (560, 24970), (560, 24971), (560, 24972), (560, 24973), (560, 24974), (560, 24975), (560, 24976), (560, 24977), (560, 24978), (560, 24979), (560, 24980), (560, 24981), (560, 23980), (560, 23981), (560, 23982), (560, 23983), (560, 23984), (560, 23985), (560, 23986), (560, 23987), (560, 23988), (560, 23989), (560, 23990), (560, 23991), (560, 23992), (560, 23993), (560, 23994), (560, 23995), (560, 23996), (560, 23997), (560, 23998), (560, 23999), (560, 24000), (560, 24001), (560, 24002), (560, 24003), (560, 24004), (560, 24005), (560, 24006), (560, 24007), (560, 24008), (560, 24009), (560, 24010), (560, 24011), (560, 24012), (560, 24013), (560, 24014), (560, 24015), (560, 24016), (560, 24017), (560, 24018), (560, 24019), (560, 24020), (560, 24021), (560, 24022), (560, 24023), (560, 24024), (560, 24025), (560, 24026), (560, 24027), (560, 24327), (560, 24328), (560, 24329), (560, 24330), (560, 24331), (560, 24332), (560, 24797), (560, 24798), (560, 24799), (560, 24800), (560, 24801), (560, 24802), (560, 24803), (560, 24804), (560, 24805), (560, 24806), (560, 24807), (560, 24808), (560, 24809), (560, 24810), (560, 24811), (560, 24812), (560, 24813), (560, 24814), (560, 24815), (560, 24816), (560, 24817), (560, 24818), (560, 24819), (560, 24820), (560, 24821), (560, 24822), (560, 24823), (560, 24824), (560, 24825), (560, 24826), (560, 24827), (560, 24828), (560, 24829), (560, 24378), (560, 24379), (560, 24380), (560, 24381), (560, 24382), (560, 24383), (560, 24384), (560, 24385), (560, 24386), (560, 24387), (560, 24388), (560, 24389), (560, 24390), (560, 24391), (560, 24392), (560, 24393), (560, 24394), (560, 24395), (560, 24396), (560, 24397), (560, 24398), (560, 24399), (560, 24400), (560, 24401), (560, 24402), (560, 24403), (560, 24404), (560, 24405), (560, 24406), (560, 24407), (560, 24408), (560, 24409), (560, 24410), (560, 24411), (560, 24255), (560, 24256), (560, 24257), (560, 24258), (560, 24259), (560, 24260), (560, 24261), (560, 24262), (560, 24263), (560, 24264), (560, 24265), (560, 24266), (560, 24267), (560, 24268), (560, 24269), (560, 24270), (560, 24271), (560, 24272), (560, 24273), (560, 24274), (560, 24275), (560, 24276), (560, 24277), (560, 24278), (560, 24279), (560, 24280), (560, 24281), (560, 24282), (560, 24283), (560, 24284), (560, 24285), (560, 24286), (560, 24287), (560, 24288), (560, 24289), (560, 24290), (560, 24291), (560, 24292), (560, 24293), (560, 24294), (560, 24295), (560, 24296), (560, 24297), (560, 24298), (560, 24299), (560, 24300), (560, 24301), (560, 24302), (560, 24303), (560, 24304), (560, 24305), (560, 24306), (560, 24307), (560, 24308), (560, 24309), (560, 24310), (560, 24311), (560, 24312), (560, 24313), (560, 24314), (560, 24315), (560, 24316), (560, 24317), (560, 24318), (560, 23979), (560, 24995), (560, 24996), (560, 24997), (560, 24998), (560, 24999), (560, 25000), (560, 25001), (560, 25002), (560, 25003), (560, 25004), (560, 25005), (560, 23041), (560, 23042), (560, 23043), (560, 23044), (560, 23045), (560, 23046), (560, 23047), (560, 23048), (560, 23049), (560, 23050), (560, 23051), (560, 23052), (560, 23053), (560, 24561), (560, 24562), (560, 24563), (560, 24570), (560, 24571), (560, 24572), (560, 24554), (560, 24555), (560, 24556), (560, 24557), (560, 24558), (560, 24559), (560, 24560), (560, 24573), (560, 24574), (560, 24575), (560, 24576), (560, 24577), (560, 24578), (560, 24579), (560, 24580), (560, 24581), (560, 24582), (560, 24583), (560, 24584), (560, 24585), (560, 24586), (560, 24587), (560, 24588), (560, 24589), (560, 24590), (560, 24591), (560, 23951), (560, 23952), (560, 23953), (560, 23954), (560, 23955), (560, 23956), (560, 23957), (560, 23958), (560, 23959), (560, 23449), (560, 23450), (560, 23451), (560, 23452), (560, 23453), (560, 23454), (560, 23455), (560, 23456), (560, 23457), (560, 23458), (560, 23459), (560, 23460), (560, 23461), (560, 23462), (560, 23463), (560, 23464), (560, 23465), (560, 23466), (560, 23467), (560, 23468), (560, 23469), (560, 23470), (560, 23471), (560, 24238), (560, 24239), (560, 24240), (560, 24241), (560, 24242), (560, 24243), (560, 24244), (560, 24245), (560, 24246), (560, 24247), (560, 24248), (560, 24249), (560, 24250), (560, 24251), (560, 24252), (560, 22506), (560, 22507), (560, 22508), (560, 22509), (560, 22510), (560, 22511), (560, 22512), (560, 23378), (560, 23379), (560, 23380), (560, 23381), (560, 23382), (560, 23383), (560, 23384), (560, 23385), (560, 23386), (560, 23387), (560, 23388), (560, 23389), (560, 23403), (560, 23404), (560, 23405), (560, 23406), (560, 23407), (560, 23408), (560, 23424), (560, 23425), (560, 23426), (560, 23427), (560, 23428), (560, 23429), (560, 23430), (560, 23431), (560, 23432), (560, 23433), (560, 23434), (560, 23435), (560, 23436), (560, 23437), (560, 23438), (560, 23439), (560, 23440), (560, 23441), (560, 23442), (560, 23443), (560, 23444), (560, 23445), (560, 23446), (560, 23447), (560, 23448), (560, 22978), (560, 22979), (560, 22980), (560, 22981), (560, 22982), (560, 22983), (560, 22984), (560, 22985), (560, 22986), (560, 22987), (560, 22988), (560, 22989), (560, 22990), (560, 22991), (560, 22992), (560, 24377), (560, 23862), (560, 23863), (560, 23864), (560, 23865), (560, 23866), (560, 23867), (560, 23868), (560, 23869), (560, 23870), (560, 23871), (560, 23872), (560, 23873), (560, 23874), (560, 23875), (560, 23876), (560, 23877), (560, 23878), (560, 23879), (560, 23307), (560, 23308), (560, 23309), (560, 23310), (560, 23311), (560, 23312), (560, 23313), (560, 23314), (560, 23315), (560, 23316), (560, 23317), (560, 23318), (560, 23319), (560, 23320), (560, 23321), (560, 23322), (560, 23323), (560, 23324), (560, 23325), (560, 23326), (560, 23327), (560, 23328), (560, 23329), (560, 23330), (560, 23331), (560, 23332), (560, 23333), (560, 23334), (560, 23335), (560, 23336), (560, 23337), (560, 23338), (560, 23339), (560, 23340), (560, 23341), (560, 23342), (560, 23343), (560, 23970), (560, 23971), (560, 23972), (560, 23973), (560, 23974), (560, 23975), (560, 23976), (560, 23977), (560, 23978), (560, 23648), (560, 23649), (560, 23650), (560, 23651), (560, 23652), (560, 23653), (560, 23654), (560, 23655), (560, 23656), (560, 23657), (560, 22738), (560, 22739), (560, 22740), (560, 22741), (560, 22742), (560, 22743), (560, 22744), (560, 22745), (560, 22746), (560, 22747), (560, 22748), (560, 22749), (560, 22750), (560, 22751), (560, 22752), (560, 22753), (560, 22754), (560, 22755), (560, 22756), (560, 22757), (560, 22758), (560, 22759), (560, 22760), (560, 22761), (560, 22762), (560, 22763), (560, 22764), (560, 22765), (560, 22766), (560, 22767), (560, 24101), (560, 23118), (560, 23119), (560, 23120), (560, 23121), (560, 23122), (560, 23123), (560, 23124), (560, 23125), (560, 23126), (560, 23127), (560, 23128), (560, 23129), (560, 23130), (560, 23131), (560, 23132), (560, 23561), (560, 23562), (560, 23563), (560, 23564), (560, 23565), (560, 23566), (560, 23567), (560, 23568), (560, 23569), (560, 23570), (560, 23571), (560, 23572), (560, 23573), (560, 23574), (560, 23575), (560, 23576), (560, 23577), (560, 23600), (560, 23601), (560, 23602), (560, 23603), (560, 23604), (560, 23605), (560, 23606), (560, 23607), (560, 23608), (560, 23609), (560, 23610), (560, 22337), (560, 22338), (560, 22339), (560, 22340), (560, 22341), (560, 22342), (560, 22343), (560, 22344), (560, 22345), (560, 22346), (560, 22347), (560, 22348), (560, 22349), (560, 22350), (560, 22351), (560, 22352), (560, 22353), (560, 22354), (560, 22355), (560, 22356), (560, 22357), (560, 22358), (560, 22359), (560, 22360), (560, 22361), (560, 22362), (560, 22363), (560, 22364), (560, 22365), (560, 22366), (560, 22367), (560, 22368), (560, 22369), (560, 22370), (560, 22371), (560, 22372), (560, 22373), (560, 22374), (560, 22375), (560, 22376), (560, 22377), (560, 22378), (560, 22379), (560, 22380), (560, 22381), (560, 22382), (560, 22383), (560, 22384), (560, 22385), (560, 22386), (560, 22387), (560, 22388), (560, 22389), (560, 22390), (560, 22391), (560, 22392), (560, 22393), (560, 22394), (560, 22395), (560, 22396), (560, 22397), (560, 22398), (560, 22399), (560, 22400), (560, 22401), (560, 22402), (560, 22403), (560, 22404), (560, 22405), (560, 22406), (560, 22407), (560, 22408), (560, 22409), (560, 22410), (560, 22411), (560, 22412), (560, 22413), (560, 22414), (560, 22415), (560, 22416), (560, 22417), (560, 22418), (560, 22821), (560, 22822), (560, 22823), (560, 22824), (560, 22825), (560, 22826), (560, 22827), (560, 22828), (560, 22829), (560, 22830), (560, 22831), (560, 22832), (560, 22833), (560, 22834), (560, 22835), (560, 22836), (560, 22837), (560, 22838), (560, 22839), (560, 22840), (560, 22841), (560, 22842), (560, 22843), (560, 22844), (560, 22845), (560, 22846), (560, 22847), (560, 22848), (560, 22849), (560, 22850), (560, 22851), (560, 22852), (560, 22853), (560, 22854), (560, 22855), (560, 22856), (560, 22857), (560, 22858), (560, 22901), (560, 22902), (560, 22903), (560, 22904), (560, 22905), (560, 22906), (560, 22907), (560, 22908), (560, 22909), (560, 22910), (560, 22911), (560, 22912), (560, 22913), (560, 22914), (560, 22915), (560, 22916), (560, 22917), (560, 22918), (560, 22919), (560, 22920), (560, 22921), (560, 22922), (560, 22923), (560, 22924), (560, 22925), (560, 22926), (560, 22927), (560, 22928), (560, 22929), (560, 22930), (560, 22931), (560, 22932), (560, 22933), (560, 23479), (560, 23480), (560, 23481), (560, 23482), (560, 23483), (560, 23484), (560, 23485), (560, 23486), (560, 23350), (560, 23351), (560, 23352), (560, 23287), (560, 23288), (560, 23289), (560, 23290), (560, 23291), (560, 23292), (560, 23293), (560, 23294), (560, 23295), (560, 23296), (560, 23297), (560, 23298), (560, 23299), (560, 23300), (560, 23301), (560, 23302), (560, 23303), (560, 23304), (560, 23305), (560, 23306), (560, 25552), (560, 25553), (560, 25554), (560, 23639), (560, 23640), (560, 23641), (560, 23642), (560, 23643), (560, 23644), (560, 23645), (560, 23646), (560, 23647), (560, 25100), (560, 25101), (560, 25102), (560, 25103), (560, 25104), (560, 25105), (560, 25106), (560, 25107), (560, 25108), (560, 25109), (560, 25110), (560, 25111), (560, 25112), (560, 25113), (560, 25114), (560, 25115), (560, 25116), (560, 25117), (560, 25118), (560, 25119), (560, 25120), (560, 25121), (560, 25122), (560, 23416), (560, 23417), (560, 23418), (560, 23419), (560, 23420), (560, 23421), (560, 23422), (560, 23423), (560, 23472), (560, 23473), (560, 23474), (560, 23475), (560, 23476), (560, 23477), (560, 23478), (560, 23487), (560, 23488), (560, 23489), (560, 23490), (560, 23491), (560, 23492), (560, 23493), (560, 23494), (560, 23495), (560, 23496), (560, 23497), (560, 23498), (560, 23499), (560, 23500), (560, 23501), (560, 22419), (560, 22420), (560, 22421), (560, 22422), (560, 22423), (560, 22424), (560, 22425), (560, 22426), (560, 22427), (560, 22428), (560, 22429), (560, 22430), (560, 22431), (560, 22432), (560, 22433), (560, 22434), (560, 22435), (560, 22436), (560, 22437), (560, 22438), (560, 22439), (560, 22440), (560, 22441), (560, 22442), (560, 22443), (560, 22449), (560, 22450), (560, 22451), (560, 22452), (560, 22453), (560, 22454), (560, 22455), (560, 22456), (560, 22457), (560, 22458), (560, 22459), (560, 22460), (560, 22461), (560, 22462), (560, 22463), (560, 22464), (560, 22465), (560, 22466), (560, 22467), (560, 22468), (560, 22469), (560, 22470), (560, 22471), (560, 22472), (560, 22473), (560, 22474), (560, 22475), (560, 22476), (560, 22477), (560, 22478), (560, 22479), (560, 22480), (560, 22481), (560, 22482), (560, 22483), (560, 22484), (560, 22485), (560, 22486), (560, 22487), (560, 22488), (560, 22489), (560, 22490), (560, 22491), (560, 22492), (560, 22493), (560, 22494), (560, 22495), (560, 22496), (560, 22497), (560, 22498), (560, 22499), (560, 22500), (560, 22501), (560, 22502), (560, 22503), (560, 22504), (560, 22505), (560, 22513), (560, 22514), (560, 22515), (560, 22516), (560, 22517), (560, 22518), (560, 22519), (560, 22520), (560, 22521), (560, 22522), (560, 22523), (560, 22524), (560, 22525), (560, 22526), (560, 24544), (560, 24545), (560, 24546), (560, 24547), (560, 24548), (560, 24549), (560, 24550), (560, 24551), (560, 24552), (560, 24553), (560, 23363), (560, 23364), (560, 23365), (560, 23366), (560, 23367), (560, 23368), (560, 23369), (560, 23370), (560, 23371), (560, 23372), (560, 23373), (560, 23374), (560, 23375), (560, 23376), (560, 23377), (560, 23390), (560, 23391), (560, 23392), (560, 23393), (560, 23394), (560, 23395), (560, 23396), (560, 23397), (560, 23398), (560, 23399), (560, 23400), (560, 23401), (560, 23402), (560, 23409), (560, 23410), (560, 23411), (560, 23412), (560, 23413), (560, 23414), (560, 23415), (560, 23543), (560, 23544), (560, 23545), (560, 23546), (560, 23547), (560, 23548), (560, 23549), (560, 23550), (560, 23551), (560, 23552), (560, 23553), (560, 23554), (560, 23555), (560, 23556), (560, 23557), (560, 23558), (560, 23559), (560, 23560), (560, 23611), (560, 23612), (560, 23613), (560, 23614), (560, 23615), (560, 23616), (560, 23617), (560, 23618), (560, 23619), (560, 23620), (560, 23621), (560, 23622), (560, 23623), (560, 23624), (560, 23625), (560, 23626), (560, 23627), (560, 23628), (560, 23629), (560, 23630), (560, 23631), (560, 23632), (560, 23633), (560, 23634), (560, 23635), (560, 22806), (560, 22807), (560, 22808), (560, 22809), (560, 22810), (560, 22811), (560, 22812), (560, 22813), (560, 22814), (560, 22815), (560, 22816), (560, 22817), (560, 22818), (560, 22819), (560, 22820), (560, 24152), (560, 24153), (560, 24154), (560, 24155), (560, 24156), (560, 24157), (560, 24158), (560, 24159), (560, 24160), (560, 24161), (560, 24162), (560, 24163), (560, 24164), (560, 24165), (560, 24166), (560, 24167), (560, 24168), (560, 24169), (560, 24170), (560, 24171), (560, 24172), (560, 24173), (560, 24174), (560, 24175), (560, 24176), (560, 24177), (560, 24178), (560, 24179), (560, 24180), (560, 24181), (560, 24182), (560, 24183), (560, 24184), (560, 24185), (560, 24186), (560, 24187), (560, 24188), (560, 24189), (560, 24190), (560, 24191), (560, 24192), (560, 24193), (560, 24194), (560, 24195), (560, 24196), (560, 24197), (560, 24198), (560, 24199), (560, 24200), (560, 24201), (560, 24202), (560, 24203), (560, 24204), (560, 24205), (560, 24206), (560, 24207), (560, 24208), (560, 24209), (560, 24210), (560, 24211), (560, 24212), (560, 24213), (560, 24214), (560, 24215), (560, 24216), (560, 24217), (560, 24218), (560, 24219), (560, 24220), (560, 24221), (560, 24222), (560, 24223), (560, 24224), (560, 24225), (560, 24226), (560, 24227), (560, 24228), (560, 24229), (560, 24230), (560, 24231), (560, 24232), (560, 24233), (560, 24234), (560, 24235), (560, 24236), (560, 24237), (560, 24253), (560, 24254), (560, 22876), (560, 22877), (560, 22878), (560, 22879), (560, 22880), (560, 22881), (560, 22882), (560, 22883), (560, 22884), (560, 22885), (560, 22886), (560, 22887), (560, 22888), (560, 22889), (560, 22890), (560, 22891), (560, 22892), (560, 22893), (560, 22894), (560, 22895), (560, 22896), (560, 22897), (560, 22898), (560, 22899), (560, 22900), (560, 24539), (560, 24540), (560, 24541), (560, 24542), (560, 24543), (560, 22248), (560, 22249), (560, 22250), (560, 22251), (560, 23963), (560, 23964), (560, 23965), (560, 23966), (560, 23967), (560, 23968), (560, 23969), (560, 24448), (560, 24449), (560, 24450), (560, 24451), (560, 24452), (560, 24453), (560, 24454), (560, 24422), (560, 24423), (560, 24424), (560, 24425), (560, 24426), (560, 22961), (560, 22962), (560, 22963), (560, 22964), (560, 22965), (560, 22966), (560, 22967), (560, 22968), (560, 22969), (560, 22970), (560, 22971), (560, 22972), (560, 23221), (560, 23222), (560, 23223), (560, 23224), (560, 23225), (560, 23226), (560, 23227), (560, 23228), (560, 23229), (560, 23230), (560, 23231), (560, 23232), (560, 23233), (560, 23234), (560, 23235), (560, 23236), (560, 23237), (560, 23238), (560, 23239), (560, 23240), (560, 23241), (560, 23242), (560, 23243), (560, 23244), (560, 23245), (560, 23246), (560, 23247), (560, 23248), (560, 24455), (560, 24456), (560, 24457), (560, 24458), (560, 24459), (560, 24460), (560, 24461), (560, 24462), (560, 24463), (560, 24464), (560, 24465), (560, 24466), (560, 26065), (560, 26066), (560, 26067), (560, 26068), (560, 26069)]\n",
      "abby \n"
     ]
    }
   ],
   "source": [
    "print(g_nx.edges(560))\n",
    "print(largest_comp.vp.pl_name[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee3c05b5-8a28-4d3b-94d4-af5eb1a96032",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 38565\n",
      "Number of edges: 6746550\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of vertices:\", largest_comp.num_vertices()) \n",
    "print(\"Number of edges:\", largest_comp.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b5773f4-4af4-49ea-ba46-781b4fa3aca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'deepsnap.dataset.GraphDataset'>\n",
      "Graph(G=[], edge_index=[2, 2320892], edge_label=[1160448], edge_label_index=[2, 1160448], name=[38565], negative_label_val=[1], node_label_index=[38565], type=[38565], uri=[38565])\n",
      "<class 'deepsnap.graph.Graph'>\n",
      "Train set has 580224 supervision (positive) edges\n",
      "Validation set has 362638 supervision (positive) edges\n",
      "Test set has 362642 supervision (positive) edges\n",
      "Train set has 2320892 message passing edges\n",
      "Validation set has 2901116 message passing edges\n",
      "Test set has 3263754 message passing edges\n",
      "GraphDataset(1)\n"
     ]
    }
   ],
   "source": [
    "task = 'link_pred'\n",
    "dataset = GraphDataset([ds_graph], task=task, edge_train_mode='disjoint')\n",
    "\n",
    "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "# dataset_train[0].to('cuda')\n",
    "# dataset_val[0].to('cuda')\n",
    "# dataset_test[0].to('cuda')\n",
    "\n",
    "# dataset_train.to('cuda:0')\n",
    "# dataset_val.to('cuda:0')\n",
    "# dataset_test.to('cuda:0')\n",
    "\n",
    "print(type(dataset_train))\n",
    "print(dataset_train[0])\n",
    "print(type(dataset_train[0]))\n",
    "\n",
    "num_train_edges = dataset_train[0].edge_label_index.shape[1]\n",
    "num_val_edges = dataset_val[0].edge_label_index.shape[1]\n",
    "num_test_edges = dataset_test[0].edge_label_index.shape[1]\n",
    "\n",
    "print(\"Train set has {} supervision (positive) edges\".format(num_train_edges // 2))\n",
    "print(\"Validation set has {} supervision (positive) edges\".format(num_val_edges // 2))\n",
    "print(\"Test set has {} supervision (positive) edges\".format(num_test_edges // 2))\n",
    "\n",
    "print(\"Train set has {} message passing edges\".format(dataset_train[0].edge_index.shape[1]))\n",
    "print(\"Validation set has {} message passing edges\".format(dataset_val[0].edge_index.shape[1]))\n",
    "print(\"Test set has {} message passing edges\".format(dataset_test[0].edge_index.shape[1]))\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf025b15-6436-4d4a-b41c-222f6df524d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(G=[], edge_index=[2, 3263754], edge_label=[725284], edge_label_index=[2, 725284], name=[38565], negative_label_val=[1], node_label_index=[38565], type=[38565], uri=[38565])\n",
      "tensor([1, 1, 1,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test_ds = dataset_test[0]\n",
    "print(test_ds)\n",
    "print(test_ds.edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c015754b-4ef4-4095-874f-5c3a79fca2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(G=[], edge_index=[2, 2320892], edge_label=[1160448], edge_label_index=[2, 1160448], name=[38565], negative_label_val=[1], node_label_index=[38565], type=[38565], uri=[38565])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = dataset_train[0]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8528bba6-4360-4a89-80f2-4950ba267911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  578,   429,   991,  ..., 38065,  8079, 18137],\n",
       "        [25011, 19146, 37349,  ...,  8851,  1926, 27728]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09252d95-a116-4ab0-99e0-b6ef101bc580",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0].negative_label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5404e392-347d-444e-8cf1-3a898b6eae87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle.dump(dataset_train, open('./graphs/train.graph', 'wb'))\n",
    "# pickle.dump(dataset_val, open('./graphs/val.graph', 'wb'))\n",
    "# pickle.dump(dataset_test, open('./graphs/test.graph', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e5cb885-4942-439a-8766-a0b7f9ebbc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_train = pickle.load(open('./graphs/train.graph', 'rb'))\n",
    "# dataset_val = pickle.load(open('./graphs/val.graph', 'rb'))\n",
    "# dataset_test = pickle.load(open('./graphs/test.graph', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b59dec8f-30e8-4c5b-ab48-3cccfff33387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, normalize = True,\n",
    "                 bias = False, **kwargs):  \n",
    "        super(LightGCNConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        out = self.propagate(edge_index, x=(x, x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        out = x_j\n",
    "        return out\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "        node_dim = self.node_dim\n",
    "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce='mean')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63ff20e2-0434-4fd8-89a1-e8db325c3e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGCN(torch.nn.Module):\n",
    "    def __init__(self, train_data, num_layers, emb_size=16, initialize_with_words=False):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        assert (num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(num_layers):\n",
    "            self.convs.append(LightGCNConv(input_dim, input_dim))\n",
    "\n",
    "        # Initialize using custom embeddings if provided\n",
    "        num_nodes = train_data.node_label_index.size()[0]\n",
    "        self.embeddings = nn.Embedding(num_nodes, emb_size)\n",
    "        if initialize_with_words:\n",
    "            self.embeddings.weight.data.copy_(train_datanode_features)\n",
    "        \n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.num_layers = num_layers\n",
    "        self.emb_size = emb_size\n",
    "        self.num_modes = num_nodes\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index, edge_label_index, node_label_index = data.edge_index, data.edge_label_index, data.node_label_index\n",
    "        layer_embeddings = []\n",
    "        \n",
    "        x = self.embeddings(node_label_index)\n",
    "        mean_layer = x\n",
    "\n",
    "        # We take an average of ever layer's node embeddings\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            # print(\"x shape\",x.shape)\n",
    "            # print(\"mean_layer shape\",mean_layer.shape)\n",
    "            mean_layer += x\n",
    "\n",
    "        mean_layer /= 4\n",
    "\n",
    "        # Prediction head is simply dot product\n",
    "        nodes_first = torch.index_select(x, 0, edge_label_index[0,:].long())\n",
    "        nodes_second = torch.index_select(x, 0, edge_label_index[1,:].long())\n",
    "\n",
    "        # Since we don't want a rank output, we create a sigmoid of the dot product\n",
    "        out = torch.sum(nodes_first * nodes_second, dim=-1) # FOR RANKING\n",
    "        pred = torch.sigmoid(out)\n",
    "\n",
    "        return torch.flatten(pred)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return self.loss_fn(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8fffe68-e6e4-4892-9b18-13be04810acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8633e9c3-115c-4ed1-a559-c6d2d9267b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'deepsnap.dataset.GraphDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ebe5156-60c7-4699-93f5-03466c7433d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'device': 'cuda', 'num_layers': 3, 'emb_size': 32, 'weight_decay': 1e-05, 'lr': 0.01, 'epochs': 600}\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'device' : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_layers' : 3,\n",
    "    'emb_size' : 32,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr': 0.01,\n",
    "    'epochs': 600\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    'train': dataset_train[0],\n",
    "    'val': dataset_val[0],\n",
    "    'test': dataset_test[0]\n",
    "}\n",
    "            \n",
    "input_dim = datasets['train'].num_node_features\n",
    "print(input_dim, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed65aa42-8be4-450f-bdec-aa2206feb866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasets['train'].to(args['device'])\n",
    "# datasets['val'].to(args['device'])\n",
    "# datasets['test'].to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "941df0fc-fc53-4f9d-b457-b2c562175a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "def train(model, optimizer, args):\n",
    "    val_max = 0\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        datasets['train'].to(args[\"device\"])\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(datasets['train'])\n",
    "        loss = model.loss(pred, datasets['train'].edge_label.type(pred.dtype))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {:.5f}, Val Loss: {:.5f}'\n",
    "        score_train, train_loss = test(model, 'train', args)\n",
    "        score_val, val_loss = test(model, 'val', args)\n",
    "        score_test, test_loss = test(model, 'test', args)\n",
    "\n",
    "        losses.append((train_loss, val_loss))\n",
    "\n",
    "        print(log.format(epoch, score_train, score_val, score_test, train_loss, val_loss))\n",
    "        if val_max < score_val:\n",
    "            val_max = score_val\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def test(model, mode, args):\n",
    "    model.eval()\n",
    "    score = 0\n",
    "    loss_score = 0\n",
    "\n",
    "    data = datasets[mode]\n",
    "    data.to(args[\"device\"])\n",
    "\n",
    "    pred = model(data)\n",
    "    loss = model.loss(pred, data.edge_label.type(pred.dtype))\n",
    "    score += roc_auc_score(data.edge_label.flatten().cpu().numpy(), pred.flatten().data.cpu().numpy())\n",
    "    loss_score += loss.item()\n",
    "\n",
    "    return score, loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ed78571-2201-450e-a3aa-6bd29ba4529e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train: 0.5332, Val: 0.5286, Test: 0.5298, Loss: 0.69774, Val Loss: 0.69795\n",
      "Epoch: 002, Train: 0.5993, Val: 0.5952, Test: 0.5962, Loss: 0.69545, Val Loss: 0.69565\n",
      "Epoch: 003, Train: 0.6430, Val: 0.6393, Test: 0.6399, Loss: 0.69389, Val Loss: 0.69406\n",
      "Epoch: 004, Train: 0.6703, Val: 0.6665, Test: 0.6668, Loss: 0.69285, Val Loss: 0.69301\n",
      "Epoch: 005, Train: 0.6874, Val: 0.6841, Test: 0.6841, Loss: 0.69217, Val Loss: 0.69233\n",
      "Epoch: 006, Train: 0.6994, Val: 0.6965, Test: 0.6964, Loss: 0.69171, Val Loss: 0.69187\n",
      "Epoch: 007, Train: 0.7086, Val: 0.7061, Test: 0.7060, Loss: 0.69138, Val Loss: 0.69153\n",
      "Epoch: 008, Train: 0.7167, Val: 0.7145, Test: 0.7145, Loss: 0.69111, Val Loss: 0.69126\n",
      "Epoch: 009, Train: 0.7244, Val: 0.7225, Test: 0.7226, Loss: 0.69085, Val Loss: 0.69100\n",
      "Epoch: 010, Train: 0.7321, Val: 0.7304, Test: 0.7306, Loss: 0.69058, Val Loss: 0.69074\n",
      "Epoch: 011, Train: 0.7397, Val: 0.7382, Test: 0.7385, Loss: 0.69030, Val Loss: 0.69045\n",
      "Epoch: 012, Train: 0.7470, Val: 0.7457, Test: 0.7461, Loss: 0.69000, Val Loss: 0.69016\n",
      "Epoch: 013, Train: 0.7540, Val: 0.7527, Test: 0.7533, Loss: 0.68968, Val Loss: 0.68984\n",
      "Epoch: 014, Train: 0.7605, Val: 0.7592, Test: 0.7599, Loss: 0.68936, Val Loss: 0.68952\n",
      "Epoch: 015, Train: 0.7663, Val: 0.7650, Test: 0.7657, Loss: 0.68903, Val Loss: 0.68920\n",
      "Epoch: 016, Train: 0.7713, Val: 0.7700, Test: 0.7708, Loss: 0.68870, Val Loss: 0.68887\n",
      "Epoch: 017, Train: 0.7757, Val: 0.7742, Test: 0.7750, Loss: 0.68836, Val Loss: 0.68854\n",
      "Epoch: 018, Train: 0.7792, Val: 0.7777, Test: 0.7784, Loss: 0.68803, Val Loss: 0.68821\n",
      "Epoch: 019, Train: 0.7821, Val: 0.7805, Test: 0.7812, Loss: 0.68769, Val Loss: 0.68788\n",
      "Epoch: 020, Train: 0.7845, Val: 0.7829, Test: 0.7836, Loss: 0.68735, Val Loss: 0.68755\n",
      "Epoch: 021, Train: 0.7864, Val: 0.7847, Test: 0.7853, Loss: 0.68701, Val Loss: 0.68721\n",
      "Epoch: 022, Train: 0.7877, Val: 0.7860, Test: 0.7865, Loss: 0.68665, Val Loss: 0.68686\n",
      "Epoch: 023, Train: 0.7886, Val: 0.7868, Test: 0.7873, Loss: 0.68629, Val Loss: 0.68650\n",
      "Epoch: 024, Train: 0.7892, Val: 0.7874, Test: 0.7877, Loss: 0.68591, Val Loss: 0.68613\n",
      "Epoch: 025, Train: 0.7895, Val: 0.7876, Test: 0.7879, Loss: 0.68552, Val Loss: 0.68574\n",
      "Epoch: 026, Train: 0.7894, Val: 0.7875, Test: 0.7878, Loss: 0.68511, Val Loss: 0.68534\n",
      "Epoch: 027, Train: 0.7892, Val: 0.7871, Test: 0.7874, Loss: 0.68468, Val Loss: 0.68491\n",
      "Epoch: 028, Train: 0.7888, Val: 0.7866, Test: 0.7869, Loss: 0.68423, Val Loss: 0.68446\n",
      "Epoch: 029, Train: 0.7882, Val: 0.7860, Test: 0.7863, Loss: 0.68375, Val Loss: 0.68399\n",
      "Epoch: 030, Train: 0.7875, Val: 0.7852, Test: 0.7855, Loss: 0.68324, Val Loss: 0.68350\n",
      "Epoch: 031, Train: 0.7866, Val: 0.7844, Test: 0.7847, Loss: 0.68271, Val Loss: 0.68297\n",
      "Epoch: 032, Train: 0.7857, Val: 0.7834, Test: 0.7837, Loss: 0.68215, Val Loss: 0.68242\n",
      "Epoch: 033, Train: 0.7847, Val: 0.7823, Test: 0.7826, Loss: 0.68156, Val Loss: 0.68184\n",
      "Epoch: 034, Train: 0.7836, Val: 0.7812, Test: 0.7814, Loss: 0.68094, Val Loss: 0.68123\n",
      "Epoch: 035, Train: 0.7826, Val: 0.7801, Test: 0.7803, Loss: 0.68028, Val Loss: 0.68058\n",
      "Epoch: 036, Train: 0.7815, Val: 0.7790, Test: 0.7791, Loss: 0.67959, Val Loss: 0.67990\n",
      "Epoch: 037, Train: 0.7805, Val: 0.7779, Test: 0.7780, Loss: 0.67887, Val Loss: 0.67919\n",
      "Epoch: 038, Train: 0.7795, Val: 0.7768, Test: 0.7769, Loss: 0.67811, Val Loss: 0.67844\n",
      "Epoch: 039, Train: 0.7785, Val: 0.7758, Test: 0.7759, Loss: 0.67731, Val Loss: 0.67766\n",
      "Epoch: 040, Train: 0.7775, Val: 0.7749, Test: 0.7749, Loss: 0.67648, Val Loss: 0.67684\n",
      "Epoch: 041, Train: 0.7766, Val: 0.7740, Test: 0.7739, Loss: 0.67561, Val Loss: 0.67598\n",
      "Epoch: 042, Train: 0.7758, Val: 0.7731, Test: 0.7730, Loss: 0.67470, Val Loss: 0.67509\n",
      "Epoch: 043, Train: 0.7750, Val: 0.7723, Test: 0.7722, Loss: 0.67375, Val Loss: 0.67415\n",
      "Epoch: 044, Train: 0.7743, Val: 0.7715, Test: 0.7714, Loss: 0.67276, Val Loss: 0.67318\n",
      "Epoch: 045, Train: 0.7736, Val: 0.7709, Test: 0.7707, Loss: 0.67174, Val Loss: 0.67217\n",
      "Epoch: 046, Train: 0.7731, Val: 0.7704, Test: 0.7702, Loss: 0.67068, Val Loss: 0.67113\n",
      "Epoch: 047, Train: 0.7727, Val: 0.7699, Test: 0.7698, Loss: 0.66959, Val Loss: 0.67005\n",
      "Epoch: 048, Train: 0.7724, Val: 0.7697, Test: 0.7695, Loss: 0.66846, Val Loss: 0.66894\n",
      "Epoch: 049, Train: 0.7723, Val: 0.7695, Test: 0.7693, Loss: 0.66730, Val Loss: 0.66779\n",
      "Epoch: 050, Train: 0.7723, Val: 0.7695, Test: 0.7693, Loss: 0.66611, Val Loss: 0.66662\n",
      "Epoch: 051, Train: 0.7724, Val: 0.7696, Test: 0.7694, Loss: 0.66489, Val Loss: 0.66542\n",
      "Epoch: 052, Train: 0.7726, Val: 0.7699, Test: 0.7697, Loss: 0.66365, Val Loss: 0.66419\n",
      "Epoch: 053, Train: 0.7730, Val: 0.7703, Test: 0.7701, Loss: 0.66238, Val Loss: 0.66294\n",
      "Epoch: 054, Train: 0.7734, Val: 0.7707, Test: 0.7706, Loss: 0.66110, Val Loss: 0.66167\n",
      "Epoch: 055, Train: 0.7740, Val: 0.7714, Test: 0.7712, Loss: 0.65980, Val Loss: 0.66039\n",
      "Epoch: 056, Train: 0.7747, Val: 0.7721, Test: 0.7719, Loss: 0.65848, Val Loss: 0.65909\n",
      "Epoch: 057, Train: 0.7755, Val: 0.7728, Test: 0.7727, Loss: 0.65716, Val Loss: 0.65778\n",
      "Epoch: 058, Train: 0.7764, Val: 0.7737, Test: 0.7736, Loss: 0.65582, Val Loss: 0.65646\n",
      "Epoch: 059, Train: 0.7773, Val: 0.7746, Test: 0.7745, Loss: 0.65449, Val Loss: 0.65514\n",
      "Epoch: 060, Train: 0.7783, Val: 0.7756, Test: 0.7755, Loss: 0.65315, Val Loss: 0.65381\n",
      "Epoch: 061, Train: 0.7793, Val: 0.7767, Test: 0.7766, Loss: 0.65181, Val Loss: 0.65249\n",
      "Epoch: 062, Train: 0.7804, Val: 0.7777, Test: 0.7777, Loss: 0.65049, Val Loss: 0.65118\n",
      "Epoch: 063, Train: 0.7814, Val: 0.7788, Test: 0.7788, Loss: 0.64916, Val Loss: 0.64987\n",
      "Epoch: 064, Train: 0.7825, Val: 0.7799, Test: 0.7799, Loss: 0.64785, Val Loss: 0.64857\n",
      "Epoch: 065, Train: 0.7836, Val: 0.7810, Test: 0.7811, Loss: 0.64656, Val Loss: 0.64729\n",
      "Epoch: 066, Train: 0.7847, Val: 0.7821, Test: 0.7822, Loss: 0.64528, Val Loss: 0.64602\n",
      "Epoch: 067, Train: 0.7858, Val: 0.7832, Test: 0.7833, Loss: 0.64401, Val Loss: 0.64476\n",
      "Epoch: 068, Train: 0.7869, Val: 0.7843, Test: 0.7844, Loss: 0.64277, Val Loss: 0.64353\n",
      "Epoch: 069, Train: 0.7879, Val: 0.7853, Test: 0.7855, Loss: 0.64154, Val Loss: 0.64232\n",
      "Epoch: 070, Train: 0.7890, Val: 0.7864, Test: 0.7865, Loss: 0.64034, Val Loss: 0.64112\n",
      "Epoch: 071, Train: 0.7900, Val: 0.7874, Test: 0.7875, Loss: 0.63916, Val Loss: 0.63995\n",
      "Epoch: 072, Train: 0.7909, Val: 0.7883, Test: 0.7885, Loss: 0.63800, Val Loss: 0.63880\n",
      "Epoch: 073, Train: 0.7919, Val: 0.7893, Test: 0.7895, Loss: 0.63686, Val Loss: 0.63768\n",
      "Epoch: 074, Train: 0.7928, Val: 0.7902, Test: 0.7904, Loss: 0.63575, Val Loss: 0.63658\n",
      "Epoch: 075, Train: 0.7937, Val: 0.7910, Test: 0.7913, Loss: 0.63466, Val Loss: 0.63550\n",
      "Epoch: 076, Train: 0.7945, Val: 0.7919, Test: 0.7921, Loss: 0.63360, Val Loss: 0.63444\n",
      "Epoch: 077, Train: 0.7953, Val: 0.7927, Test: 0.7930, Loss: 0.63255, Val Loss: 0.63341\n",
      "Epoch: 078, Train: 0.7961, Val: 0.7935, Test: 0.7938, Loss: 0.63153, Val Loss: 0.63240\n",
      "Epoch: 079, Train: 0.7969, Val: 0.7943, Test: 0.7945, Loss: 0.63053, Val Loss: 0.63141\n",
      "Epoch: 080, Train: 0.7976, Val: 0.7950, Test: 0.7953, Loss: 0.62956, Val Loss: 0.63044\n",
      "Epoch: 081, Train: 0.7984, Val: 0.7957, Test: 0.7960, Loss: 0.62861, Val Loss: 0.62950\n",
      "Epoch: 082, Train: 0.7991, Val: 0.7964, Test: 0.7968, Loss: 0.62767, Val Loss: 0.62858\n",
      "Epoch: 083, Train: 0.7998, Val: 0.7971, Test: 0.7975, Loss: 0.62676, Val Loss: 0.62767\n",
      "Epoch: 084, Train: 0.8004, Val: 0.7978, Test: 0.7981, Loss: 0.62587, Val Loss: 0.62679\n",
      "Epoch: 085, Train: 0.8011, Val: 0.7985, Test: 0.7988, Loss: 0.62500, Val Loss: 0.62593\n",
      "Epoch: 086, Train: 0.8017, Val: 0.7991, Test: 0.7995, Loss: 0.62416, Val Loss: 0.62509\n",
      "Epoch: 087, Train: 0.8024, Val: 0.7997, Test: 0.8001, Loss: 0.62333, Val Loss: 0.62427\n",
      "Epoch: 088, Train: 0.8030, Val: 0.8004, Test: 0.8008, Loss: 0.62252, Val Loss: 0.62347\n",
      "Epoch: 089, Train: 0.8036, Val: 0.8010, Test: 0.8014, Loss: 0.62173, Val Loss: 0.62269\n",
      "Epoch: 090, Train: 0.8042, Val: 0.8016, Test: 0.8020, Loss: 0.62095, Val Loss: 0.62192\n",
      "Epoch: 091, Train: 0.8048, Val: 0.8022, Test: 0.8026, Loss: 0.62020, Val Loss: 0.62117\n",
      "Epoch: 092, Train: 0.8054, Val: 0.8028, Test: 0.8032, Loss: 0.61946, Val Loss: 0.62044\n",
      "Epoch: 093, Train: 0.8060, Val: 0.8033, Test: 0.8038, Loss: 0.61875, Val Loss: 0.61973\n",
      "Epoch: 094, Train: 0.8065, Val: 0.8039, Test: 0.8043, Loss: 0.61804, Val Loss: 0.61904\n",
      "Epoch: 095, Train: 0.8071, Val: 0.8044, Test: 0.8049, Loss: 0.61736, Val Loss: 0.61836\n",
      "Epoch: 096, Train: 0.8076, Val: 0.8050, Test: 0.8054, Loss: 0.61669, Val Loss: 0.61770\n",
      "Epoch: 097, Train: 0.8081, Val: 0.8055, Test: 0.8060, Loss: 0.61604, Val Loss: 0.61705\n",
      "Epoch: 098, Train: 0.8087, Val: 0.8060, Test: 0.8065, Loss: 0.61540, Val Loss: 0.61642\n",
      "Epoch: 099, Train: 0.8092, Val: 0.8065, Test: 0.8070, Loss: 0.61478, Val Loss: 0.61580\n",
      "Epoch: 100, Train: 0.8097, Val: 0.8070, Test: 0.8075, Loss: 0.61417, Val Loss: 0.61520\n",
      "Epoch: 101, Train: 0.8101, Val: 0.8074, Test: 0.8080, Loss: 0.61357, Val Loss: 0.61461\n",
      "Epoch: 102, Train: 0.8106, Val: 0.8079, Test: 0.8084, Loss: 0.61299, Val Loss: 0.61403\n",
      "Epoch: 103, Train: 0.8111, Val: 0.8084, Test: 0.8089, Loss: 0.61242, Val Loss: 0.61347\n",
      "Epoch: 104, Train: 0.8115, Val: 0.8088, Test: 0.8094, Loss: 0.61187, Val Loss: 0.61292\n",
      "Epoch: 105, Train: 0.8120, Val: 0.8092, Test: 0.8098, Loss: 0.61132, Val Loss: 0.61238\n",
      "Epoch: 106, Train: 0.8124, Val: 0.8097, Test: 0.8102, Loss: 0.61079, Val Loss: 0.61185\n",
      "Epoch: 107, Train: 0.8128, Val: 0.8101, Test: 0.8107, Loss: 0.61027, Val Loss: 0.61134\n",
      "Epoch: 108, Train: 0.8132, Val: 0.8105, Test: 0.8111, Loss: 0.60976, Val Loss: 0.61083\n",
      "Epoch: 109, Train: 0.8137, Val: 0.8109, Test: 0.8115, Loss: 0.60927, Val Loss: 0.61034\n",
      "Epoch: 110, Train: 0.8141, Val: 0.8113, Test: 0.8119, Loss: 0.60878, Val Loss: 0.60986\n",
      "Epoch: 111, Train: 0.8145, Val: 0.8117, Test: 0.8123, Loss: 0.60830, Val Loss: 0.60939\n",
      "Epoch: 112, Train: 0.8148, Val: 0.8121, Test: 0.8127, Loss: 0.60783, Val Loss: 0.60892\n",
      "Epoch: 113, Train: 0.8152, Val: 0.8125, Test: 0.8131, Loss: 0.60738, Val Loss: 0.60847\n",
      "Epoch: 114, Train: 0.8156, Val: 0.8129, Test: 0.8135, Loss: 0.60693, Val Loss: 0.60803\n",
      "Epoch: 115, Train: 0.8160, Val: 0.8132, Test: 0.8138, Loss: 0.60649, Val Loss: 0.60759\n",
      "Epoch: 116, Train: 0.8163, Val: 0.8136, Test: 0.8142, Loss: 0.60606, Val Loss: 0.60717\n",
      "Epoch: 117, Train: 0.8167, Val: 0.8140, Test: 0.8146, Loss: 0.60564, Val Loss: 0.60675\n",
      "Epoch: 118, Train: 0.8171, Val: 0.8143, Test: 0.8149, Loss: 0.60523, Val Loss: 0.60634\n",
      "Epoch: 119, Train: 0.8174, Val: 0.8147, Test: 0.8153, Loss: 0.60482, Val Loss: 0.60594\n",
      "Epoch: 120, Train: 0.8177, Val: 0.8150, Test: 0.8156, Loss: 0.60443, Val Loss: 0.60555\n",
      "Epoch: 121, Train: 0.8181, Val: 0.8154, Test: 0.8160, Loss: 0.60404, Val Loss: 0.60516\n",
      "Epoch: 122, Train: 0.8184, Val: 0.8157, Test: 0.8163, Loss: 0.60366, Val Loss: 0.60478\n",
      "Epoch: 123, Train: 0.8187, Val: 0.8160, Test: 0.8166, Loss: 0.60329, Val Loss: 0.60441\n",
      "Epoch: 124, Train: 0.8190, Val: 0.8163, Test: 0.8169, Loss: 0.60292, Val Loss: 0.60405\n",
      "Epoch: 125, Train: 0.8193, Val: 0.8166, Test: 0.8173, Loss: 0.60256, Val Loss: 0.60369\n",
      "Epoch: 126, Train: 0.8196, Val: 0.8169, Test: 0.8176, Loss: 0.60221, Val Loss: 0.60334\n",
      "Epoch: 127, Train: 0.8199, Val: 0.8172, Test: 0.8179, Loss: 0.60186, Val Loss: 0.60300\n",
      "Epoch: 128, Train: 0.8202, Val: 0.8175, Test: 0.8182, Loss: 0.60152, Val Loss: 0.60266\n",
      "Epoch: 129, Train: 0.8205, Val: 0.8178, Test: 0.8184, Loss: 0.60119, Val Loss: 0.60233\n",
      "Epoch: 130, Train: 0.8208, Val: 0.8181, Test: 0.8187, Loss: 0.60086, Val Loss: 0.60201\n",
      "Epoch: 131, Train: 0.8210, Val: 0.8184, Test: 0.8190, Loss: 0.60053, Val Loss: 0.60169\n",
      "Epoch: 132, Train: 0.8213, Val: 0.8186, Test: 0.8193, Loss: 0.60022, Val Loss: 0.60137\n",
      "Epoch: 133, Train: 0.8216, Val: 0.8189, Test: 0.8195, Loss: 0.59991, Val Loss: 0.60107\n",
      "Epoch: 134, Train: 0.8218, Val: 0.8192, Test: 0.8198, Loss: 0.59960, Val Loss: 0.60076\n",
      "Epoch: 135, Train: 0.8221, Val: 0.8194, Test: 0.8201, Loss: 0.59930, Val Loss: 0.60047\n",
      "Epoch: 136, Train: 0.8223, Val: 0.8197, Test: 0.8203, Loss: 0.59901, Val Loss: 0.60017\n",
      "Epoch: 137, Train: 0.8226, Val: 0.8199, Test: 0.8206, Loss: 0.59872, Val Loss: 0.59989\n",
      "Epoch: 138, Train: 0.8228, Val: 0.8202, Test: 0.8208, Loss: 0.59843, Val Loss: 0.59960\n",
      "Epoch: 139, Train: 0.8230, Val: 0.8204, Test: 0.8210, Loss: 0.59815, Val Loss: 0.59933\n",
      "Epoch: 140, Train: 0.8233, Val: 0.8206, Test: 0.8213, Loss: 0.59788, Val Loss: 0.59905\n",
      "Epoch: 141, Train: 0.8235, Val: 0.8209, Test: 0.8215, Loss: 0.59761, Val Loss: 0.59878\n",
      "Epoch: 142, Train: 0.8237, Val: 0.8211, Test: 0.8217, Loss: 0.59734, Val Loss: 0.59852\n",
      "Epoch: 143, Train: 0.8239, Val: 0.8213, Test: 0.8220, Loss: 0.59708, Val Loss: 0.59826\n",
      "Epoch: 144, Train: 0.8242, Val: 0.8215, Test: 0.8222, Loss: 0.59682, Val Loss: 0.59801\n",
      "Epoch: 145, Train: 0.8244, Val: 0.8217, Test: 0.8224, Loss: 0.59657, Val Loss: 0.59776\n",
      "Epoch: 146, Train: 0.8246, Val: 0.8220, Test: 0.8226, Loss: 0.59632, Val Loss: 0.59751\n",
      "Epoch: 147, Train: 0.8248, Val: 0.8222, Test: 0.8228, Loss: 0.59607, Val Loss: 0.59727\n",
      "Epoch: 148, Train: 0.8250, Val: 0.8224, Test: 0.8230, Loss: 0.59583, Val Loss: 0.59703\n",
      "Epoch: 149, Train: 0.8252, Val: 0.8226, Test: 0.8232, Loss: 0.59560, Val Loss: 0.59679\n",
      "Epoch: 150, Train: 0.8254, Val: 0.8228, Test: 0.8234, Loss: 0.59536, Val Loss: 0.59656\n",
      "Epoch: 151, Train: 0.8255, Val: 0.8229, Test: 0.8236, Loss: 0.59513, Val Loss: 0.59633\n",
      "Epoch: 152, Train: 0.8257, Val: 0.8231, Test: 0.8238, Loss: 0.59491, Val Loss: 0.59611\n",
      "Epoch: 153, Train: 0.8259, Val: 0.8233, Test: 0.8240, Loss: 0.59468, Val Loss: 0.59589\n",
      "Epoch: 154, Train: 0.8261, Val: 0.8235, Test: 0.8242, Loss: 0.59446, Val Loss: 0.59567\n",
      "Epoch: 155, Train: 0.8263, Val: 0.8237, Test: 0.8244, Loss: 0.59425, Val Loss: 0.59545\n",
      "Epoch: 156, Train: 0.8264, Val: 0.8239, Test: 0.8245, Loss: 0.59404, Val Loss: 0.59524\n",
      "Epoch: 157, Train: 0.8266, Val: 0.8240, Test: 0.8247, Loss: 0.59383, Val Loss: 0.59504\n",
      "Epoch: 158, Train: 0.8268, Val: 0.8242, Test: 0.8249, Loss: 0.59362, Val Loss: 0.59483\n",
      "Epoch: 159, Train: 0.8269, Val: 0.8244, Test: 0.8250, Loss: 0.59342, Val Loss: 0.59463\n",
      "Epoch: 160, Train: 0.8271, Val: 0.8245, Test: 0.8252, Loss: 0.59322, Val Loss: 0.59443\n",
      "Epoch: 161, Train: 0.8272, Val: 0.8247, Test: 0.8254, Loss: 0.59302, Val Loss: 0.59424\n",
      "Epoch: 162, Train: 0.8274, Val: 0.8248, Test: 0.8255, Loss: 0.59283, Val Loss: 0.59404\n",
      "Epoch: 163, Train: 0.8275, Val: 0.8250, Test: 0.8257, Loss: 0.59263, Val Loss: 0.59385\n",
      "Epoch: 164, Train: 0.8277, Val: 0.8251, Test: 0.8258, Loss: 0.59245, Val Loss: 0.59367\n",
      "Epoch: 165, Train: 0.8278, Val: 0.8253, Test: 0.8260, Loss: 0.59226, Val Loss: 0.59348\n",
      "Epoch: 166, Train: 0.8280, Val: 0.8254, Test: 0.8261, Loss: 0.59208, Val Loss: 0.59330\n",
      "Epoch: 167, Train: 0.8281, Val: 0.8256, Test: 0.8263, Loss: 0.59190, Val Loss: 0.59312\n",
      "Epoch: 168, Train: 0.8283, Val: 0.8257, Test: 0.8264, Loss: 0.59172, Val Loss: 0.59295\n",
      "Epoch: 169, Train: 0.8284, Val: 0.8259, Test: 0.8266, Loss: 0.59154, Val Loss: 0.59277\n",
      "Epoch: 170, Train: 0.8285, Val: 0.8260, Test: 0.8267, Loss: 0.59137, Val Loss: 0.59260\n",
      "Epoch: 171, Train: 0.8287, Val: 0.8261, Test: 0.8268, Loss: 0.59120, Val Loss: 0.59243\n",
      "Epoch: 172, Train: 0.8288, Val: 0.8263, Test: 0.8270, Loss: 0.59103, Val Loss: 0.59227\n",
      "Epoch: 173, Train: 0.8289, Val: 0.8264, Test: 0.8271, Loss: 0.59087, Val Loss: 0.59210\n",
      "Epoch: 174, Train: 0.8291, Val: 0.8265, Test: 0.8272, Loss: 0.59070, Val Loss: 0.59194\n",
      "Epoch: 175, Train: 0.8292, Val: 0.8267, Test: 0.8273, Loss: 0.59054, Val Loss: 0.59178\n",
      "Epoch: 176, Train: 0.8293, Val: 0.8268, Test: 0.8275, Loss: 0.59038, Val Loss: 0.59162\n",
      "Epoch: 177, Train: 0.8294, Val: 0.8269, Test: 0.8276, Loss: 0.59023, Val Loss: 0.59147\n",
      "Epoch: 178, Train: 0.8296, Val: 0.8270, Test: 0.8277, Loss: 0.59007, Val Loss: 0.59132\n",
      "Epoch: 179, Train: 0.8297, Val: 0.8271, Test: 0.8278, Loss: 0.58992, Val Loss: 0.59116\n",
      "Epoch: 180, Train: 0.8298, Val: 0.8273, Test: 0.8280, Loss: 0.58977, Val Loss: 0.59102\n",
      "Epoch: 181, Train: 0.8299, Val: 0.8274, Test: 0.8281, Loss: 0.58962, Val Loss: 0.59087\n",
      "Epoch: 182, Train: 0.8300, Val: 0.8275, Test: 0.8282, Loss: 0.58948, Val Loss: 0.59072\n",
      "Epoch: 183, Train: 0.8301, Val: 0.8276, Test: 0.8283, Loss: 0.58933, Val Loss: 0.59058\n",
      "Epoch: 184, Train: 0.8302, Val: 0.8277, Test: 0.8284, Loss: 0.58919, Val Loss: 0.59044\n",
      "Epoch: 185, Train: 0.8303, Val: 0.8278, Test: 0.8285, Loss: 0.58905, Val Loss: 0.59030\n",
      "Epoch: 186, Train: 0.8304, Val: 0.8279, Test: 0.8286, Loss: 0.58891, Val Loss: 0.59016\n",
      "Epoch: 187, Train: 0.8306, Val: 0.8280, Test: 0.8287, Loss: 0.58878, Val Loss: 0.59003\n",
      "Epoch: 188, Train: 0.8307, Val: 0.8281, Test: 0.8288, Loss: 0.58864, Val Loss: 0.58990\n",
      "Epoch: 189, Train: 0.8308, Val: 0.8282, Test: 0.8289, Loss: 0.58851, Val Loss: 0.58976\n",
      "Epoch: 190, Train: 0.8309, Val: 0.8283, Test: 0.8290, Loss: 0.58838, Val Loss: 0.58963\n",
      "Epoch: 191, Train: 0.8310, Val: 0.8284, Test: 0.8291, Loss: 0.58825, Val Loss: 0.58951\n",
      "Epoch: 192, Train: 0.8310, Val: 0.8285, Test: 0.8292, Loss: 0.58812, Val Loss: 0.58938\n",
      "Epoch: 193, Train: 0.8311, Val: 0.8286, Test: 0.8293, Loss: 0.58800, Val Loss: 0.58925\n",
      "Epoch: 194, Train: 0.8312, Val: 0.8287, Test: 0.8294, Loss: 0.58787, Val Loss: 0.58913\n",
      "Epoch: 195, Train: 0.8313, Val: 0.8288, Test: 0.8295, Loss: 0.58775, Val Loss: 0.58901\n",
      "Epoch: 196, Train: 0.8314, Val: 0.8289, Test: 0.8296, Loss: 0.58763, Val Loss: 0.58889\n",
      "Epoch: 197, Train: 0.8315, Val: 0.8290, Test: 0.8297, Loss: 0.58751, Val Loss: 0.58877\n",
      "Epoch: 198, Train: 0.8316, Val: 0.8291, Test: 0.8298, Loss: 0.58739, Val Loss: 0.58865\n",
      "Epoch: 199, Train: 0.8317, Val: 0.8292, Test: 0.8299, Loss: 0.58727, Val Loss: 0.58854\n",
      "Epoch: 200, Train: 0.8318, Val: 0.8293, Test: 0.8300, Loss: 0.58716, Val Loss: 0.58842\n",
      "Epoch: 201, Train: 0.8319, Val: 0.8294, Test: 0.8301, Loss: 0.58704, Val Loss: 0.58831\n",
      "Epoch: 202, Train: 0.8319, Val: 0.8295, Test: 0.8302, Loss: 0.58693, Val Loss: 0.58820\n",
      "Epoch: 203, Train: 0.8320, Val: 0.8295, Test: 0.8302, Loss: 0.58682, Val Loss: 0.58809\n",
      "Epoch: 204, Train: 0.8321, Val: 0.8296, Test: 0.8303, Loss: 0.58671, Val Loss: 0.58798\n",
      "Epoch: 205, Train: 0.8322, Val: 0.8297, Test: 0.8304, Loss: 0.58660, Val Loss: 0.58788\n",
      "Epoch: 206, Train: 0.8323, Val: 0.8298, Test: 0.8305, Loss: 0.58650, Val Loss: 0.58777\n",
      "Epoch: 207, Train: 0.8323, Val: 0.8299, Test: 0.8306, Loss: 0.58639, Val Loss: 0.58767\n",
      "Epoch: 208, Train: 0.8324, Val: 0.8299, Test: 0.8306, Loss: 0.58629, Val Loss: 0.58756\n",
      "Epoch: 209, Train: 0.8325, Val: 0.8300, Test: 0.8307, Loss: 0.58619, Val Loss: 0.58746\n",
      "Epoch: 210, Train: 0.8326, Val: 0.8301, Test: 0.8308, Loss: 0.58609, Val Loss: 0.58736\n",
      "Epoch: 211, Train: 0.8327, Val: 0.8302, Test: 0.8309, Loss: 0.58599, Val Loss: 0.58726\n",
      "Epoch: 212, Train: 0.8327, Val: 0.8302, Test: 0.8310, Loss: 0.58589, Val Loss: 0.58716\n",
      "Epoch: 213, Train: 0.8328, Val: 0.8303, Test: 0.8310, Loss: 0.58579, Val Loss: 0.58707\n",
      "Epoch: 214, Train: 0.8329, Val: 0.8304, Test: 0.8311, Loss: 0.58569, Val Loss: 0.58697\n",
      "Epoch: 215, Train: 0.8329, Val: 0.8305, Test: 0.8312, Loss: 0.58560, Val Loss: 0.58688\n",
      "Epoch: 216, Train: 0.8330, Val: 0.8305, Test: 0.8312, Loss: 0.58550, Val Loss: 0.58678\n",
      "Epoch: 217, Train: 0.8331, Val: 0.8306, Test: 0.8313, Loss: 0.58541, Val Loss: 0.58669\n",
      "Epoch: 218, Train: 0.8331, Val: 0.8307, Test: 0.8314, Loss: 0.58532, Val Loss: 0.58660\n",
      "Epoch: 219, Train: 0.8332, Val: 0.8307, Test: 0.8314, Loss: 0.58523, Val Loss: 0.58651\n",
      "Epoch: 220, Train: 0.8333, Val: 0.8308, Test: 0.8315, Loss: 0.58514, Val Loss: 0.58642\n",
      "Epoch: 221, Train: 0.8333, Val: 0.8309, Test: 0.8316, Loss: 0.58505, Val Loss: 0.58634\n",
      "Epoch: 222, Train: 0.8334, Val: 0.8309, Test: 0.8316, Loss: 0.58496, Val Loss: 0.58625\n",
      "Epoch: 223, Train: 0.8335, Val: 0.8310, Test: 0.8317, Loss: 0.58488, Val Loss: 0.58616\n",
      "Epoch: 224, Train: 0.8335, Val: 0.8311, Test: 0.8318, Loss: 0.58479, Val Loss: 0.58608\n",
      "Epoch: 225, Train: 0.8336, Val: 0.8311, Test: 0.8318, Loss: 0.58471, Val Loss: 0.58600\n",
      "Epoch: 226, Train: 0.8337, Val: 0.8312, Test: 0.8319, Loss: 0.58462, Val Loss: 0.58591\n",
      "Epoch: 227, Train: 0.8337, Val: 0.8312, Test: 0.8320, Loss: 0.58454, Val Loss: 0.58583\n",
      "Epoch: 228, Train: 0.8338, Val: 0.8313, Test: 0.8320, Loss: 0.58446, Val Loss: 0.58575\n",
      "Epoch: 229, Train: 0.8338, Val: 0.8314, Test: 0.8321, Loss: 0.58438, Val Loss: 0.58567\n",
      "Epoch: 230, Train: 0.8339, Val: 0.8314, Test: 0.8321, Loss: 0.58430, Val Loss: 0.58559\n",
      "Epoch: 231, Train: 0.8339, Val: 0.8315, Test: 0.8322, Loss: 0.58422, Val Loss: 0.58551\n",
      "Epoch: 232, Train: 0.8340, Val: 0.8315, Test: 0.8323, Loss: 0.58415, Val Loss: 0.58544\n",
      "Epoch: 233, Train: 0.8341, Val: 0.8316, Test: 0.8323, Loss: 0.58407, Val Loss: 0.58536\n",
      "Epoch: 234, Train: 0.8341, Val: 0.8316, Test: 0.8324, Loss: 0.58399, Val Loss: 0.58529\n",
      "Epoch: 235, Train: 0.8342, Val: 0.8317, Test: 0.8324, Loss: 0.58392, Val Loss: 0.58521\n",
      "Epoch: 236, Train: 0.8342, Val: 0.8318, Test: 0.8325, Loss: 0.58385, Val Loss: 0.58514\n",
      "Epoch: 237, Train: 0.8343, Val: 0.8318, Test: 0.8325, Loss: 0.58377, Val Loss: 0.58507\n",
      "Epoch: 238, Train: 0.8343, Val: 0.8319, Test: 0.8326, Loss: 0.58370, Val Loss: 0.58500\n",
      "Epoch: 239, Train: 0.8344, Val: 0.8319, Test: 0.8326, Loss: 0.58363, Val Loss: 0.58493\n",
      "Epoch: 240, Train: 0.8344, Val: 0.8320, Test: 0.8327, Loss: 0.58356, Val Loss: 0.58486\n",
      "Epoch: 241, Train: 0.8345, Val: 0.8320, Test: 0.8327, Loss: 0.58349, Val Loss: 0.58479\n",
      "Epoch: 242, Train: 0.8345, Val: 0.8321, Test: 0.8328, Loss: 0.58342, Val Loss: 0.58472\n",
      "Epoch: 243, Train: 0.8346, Val: 0.8321, Test: 0.8328, Loss: 0.58335, Val Loss: 0.58465\n",
      "Epoch: 244, Train: 0.8346, Val: 0.8322, Test: 0.8329, Loss: 0.58329, Val Loss: 0.58459\n",
      "Epoch: 245, Train: 0.8347, Val: 0.8322, Test: 0.8329, Loss: 0.58322, Val Loss: 0.58452\n",
      "Epoch: 246, Train: 0.8347, Val: 0.8323, Test: 0.8330, Loss: 0.58315, Val Loss: 0.58445\n",
      "Epoch: 247, Train: 0.8348, Val: 0.8323, Test: 0.8330, Loss: 0.58309, Val Loss: 0.58439\n",
      "Epoch: 248, Train: 0.8348, Val: 0.8324, Test: 0.8331, Loss: 0.58302, Val Loss: 0.58433\n",
      "Epoch: 249, Train: 0.8349, Val: 0.8324, Test: 0.8331, Loss: 0.58296, Val Loss: 0.58426\n",
      "Epoch: 250, Train: 0.8349, Val: 0.8324, Test: 0.8332, Loss: 0.58290, Val Loss: 0.58420\n",
      "Epoch: 251, Train: 0.8349, Val: 0.8325, Test: 0.8332, Loss: 0.58284, Val Loss: 0.58414\n",
      "Epoch: 252, Train: 0.8350, Val: 0.8325, Test: 0.8333, Loss: 0.58278, Val Loss: 0.58408\n",
      "Epoch: 253, Train: 0.8350, Val: 0.8326, Test: 0.8333, Loss: 0.58272, Val Loss: 0.58402\n",
      "Epoch: 254, Train: 0.8351, Val: 0.8326, Test: 0.8333, Loss: 0.58266, Val Loss: 0.58396\n",
      "Epoch: 255, Train: 0.8351, Val: 0.8327, Test: 0.8334, Loss: 0.58260, Val Loss: 0.58390\n",
      "Epoch: 256, Train: 0.8352, Val: 0.8327, Test: 0.8334, Loss: 0.58254, Val Loss: 0.58384\n",
      "Epoch: 257, Train: 0.8352, Val: 0.8327, Test: 0.8335, Loss: 0.58248, Val Loss: 0.58379\n",
      "Epoch: 258, Train: 0.8352, Val: 0.8328, Test: 0.8335, Loss: 0.58242, Val Loss: 0.58373\n",
      "Epoch: 259, Train: 0.8353, Val: 0.8328, Test: 0.8336, Loss: 0.58237, Val Loss: 0.58367\n",
      "Epoch: 260, Train: 0.8353, Val: 0.8329, Test: 0.8336, Loss: 0.58231, Val Loss: 0.58362\n",
      "Epoch: 261, Train: 0.8354, Val: 0.8329, Test: 0.8336, Loss: 0.58226, Val Loss: 0.58356\n",
      "Epoch: 262, Train: 0.8354, Val: 0.8329, Test: 0.8337, Loss: 0.58220, Val Loss: 0.58351\n",
      "Epoch: 263, Train: 0.8354, Val: 0.8330, Test: 0.8337, Loss: 0.58215, Val Loss: 0.58346\n",
      "Epoch: 264, Train: 0.8355, Val: 0.8330, Test: 0.8337, Loss: 0.58209, Val Loss: 0.58340\n",
      "Epoch: 265, Train: 0.8355, Val: 0.8331, Test: 0.8338, Loss: 0.58204, Val Loss: 0.58335\n",
      "Epoch: 266, Train: 0.8355, Val: 0.8331, Test: 0.8338, Loss: 0.58199, Val Loss: 0.58330\n",
      "Epoch: 267, Train: 0.8356, Val: 0.8331, Test: 0.8339, Loss: 0.58194, Val Loss: 0.58325\n",
      "Epoch: 268, Train: 0.8356, Val: 0.8332, Test: 0.8339, Loss: 0.58189, Val Loss: 0.58320\n",
      "Epoch: 269, Train: 0.8356, Val: 0.8332, Test: 0.8339, Loss: 0.58184, Val Loss: 0.58315\n",
      "Epoch: 270, Train: 0.8357, Val: 0.8332, Test: 0.8340, Loss: 0.58179, Val Loss: 0.58310\n",
      "Epoch: 271, Train: 0.8357, Val: 0.8333, Test: 0.8340, Loss: 0.58174, Val Loss: 0.58305\n",
      "Epoch: 272, Train: 0.8357, Val: 0.8333, Test: 0.8340, Loss: 0.58169, Val Loss: 0.58300\n",
      "Epoch: 273, Train: 0.8358, Val: 0.8333, Test: 0.8341, Loss: 0.58164, Val Loss: 0.58295\n",
      "Epoch: 274, Train: 0.8358, Val: 0.8334, Test: 0.8341, Loss: 0.58159, Val Loss: 0.58291\n",
      "Epoch: 275, Train: 0.8358, Val: 0.8334, Test: 0.8341, Loss: 0.58154, Val Loss: 0.58286\n",
      "Epoch: 276, Train: 0.8359, Val: 0.8334, Test: 0.8342, Loss: 0.58150, Val Loss: 0.58281\n",
      "Epoch: 277, Train: 0.8359, Val: 0.8335, Test: 0.8342, Loss: 0.58145, Val Loss: 0.58277\n",
      "Epoch: 278, Train: 0.8359, Val: 0.8335, Test: 0.8342, Loss: 0.58141, Val Loss: 0.58272\n",
      "Epoch: 279, Train: 0.8360, Val: 0.8335, Test: 0.8343, Loss: 0.58136, Val Loss: 0.58268\n",
      "Epoch: 280, Train: 0.8360, Val: 0.8336, Test: 0.8343, Loss: 0.58132, Val Loss: 0.58263\n",
      "Epoch: 281, Train: 0.8360, Val: 0.8336, Test: 0.8343, Loss: 0.58127, Val Loss: 0.58259\n",
      "Epoch: 282, Train: 0.8361, Val: 0.8336, Test: 0.8344, Loss: 0.58123, Val Loss: 0.58255\n",
      "Epoch: 283, Train: 0.8361, Val: 0.8337, Test: 0.8344, Loss: 0.58119, Val Loss: 0.58250\n",
      "Epoch: 284, Train: 0.8361, Val: 0.8337, Test: 0.8344, Loss: 0.58114, Val Loss: 0.58246\n",
      "Epoch: 285, Train: 0.8362, Val: 0.8337, Test: 0.8345, Loss: 0.58110, Val Loss: 0.58242\n",
      "Epoch: 286, Train: 0.8362, Val: 0.8337, Test: 0.8345, Loss: 0.58106, Val Loss: 0.58238\n",
      "Epoch: 287, Train: 0.8362, Val: 0.8338, Test: 0.8345, Loss: 0.58102, Val Loss: 0.58234\n",
      "Epoch: 288, Train: 0.8362, Val: 0.8338, Test: 0.8345, Loss: 0.58098, Val Loss: 0.58230\n",
      "Epoch: 289, Train: 0.8363, Val: 0.8338, Test: 0.8346, Loss: 0.58094, Val Loss: 0.58226\n",
      "Epoch: 290, Train: 0.8363, Val: 0.8339, Test: 0.8346, Loss: 0.58090, Val Loss: 0.58222\n",
      "Epoch: 291, Train: 0.8363, Val: 0.8339, Test: 0.8346, Loss: 0.58086, Val Loss: 0.58218\n",
      "Epoch: 292, Train: 0.8363, Val: 0.8339, Test: 0.8347, Loss: 0.58082, Val Loss: 0.58214\n",
      "Epoch: 293, Train: 0.8364, Val: 0.8339, Test: 0.8347, Loss: 0.58078, Val Loss: 0.58210\n",
      "Epoch: 294, Train: 0.8364, Val: 0.8340, Test: 0.8347, Loss: 0.58074, Val Loss: 0.58206\n",
      "Epoch: 295, Train: 0.8364, Val: 0.8340, Test: 0.8347, Loss: 0.58070, Val Loss: 0.58203\n",
      "Epoch: 296, Train: 0.8364, Val: 0.8340, Test: 0.8348, Loss: 0.58067, Val Loss: 0.58199\n",
      "Epoch: 297, Train: 0.8365, Val: 0.8340, Test: 0.8348, Loss: 0.58063, Val Loss: 0.58195\n",
      "Epoch: 298, Train: 0.8365, Val: 0.8341, Test: 0.8348, Loss: 0.58059, Val Loss: 0.58192\n",
      "Epoch: 299, Train: 0.8365, Val: 0.8341, Test: 0.8348, Loss: 0.58056, Val Loss: 0.58188\n",
      "Epoch: 300, Train: 0.8365, Val: 0.8341, Test: 0.8349, Loss: 0.58052, Val Loss: 0.58184\n",
      "Epoch: 301, Train: 0.8366, Val: 0.8341, Test: 0.8349, Loss: 0.58049, Val Loss: 0.58181\n",
      "Epoch: 302, Train: 0.8366, Val: 0.8342, Test: 0.8349, Loss: 0.58045, Val Loss: 0.58178\n",
      "Epoch: 303, Train: 0.8366, Val: 0.8342, Test: 0.8349, Loss: 0.58042, Val Loss: 0.58174\n",
      "Epoch: 304, Train: 0.8366, Val: 0.8342, Test: 0.8350, Loss: 0.58038, Val Loss: 0.58171\n",
      "Epoch: 305, Train: 0.8367, Val: 0.8342, Test: 0.8350, Loss: 0.58035, Val Loss: 0.58167\n",
      "Epoch: 306, Train: 0.8367, Val: 0.8343, Test: 0.8350, Loss: 0.58032, Val Loss: 0.58164\n",
      "Epoch: 307, Train: 0.8367, Val: 0.8343, Test: 0.8350, Loss: 0.58028, Val Loss: 0.58161\n",
      "Epoch: 308, Train: 0.8367, Val: 0.8343, Test: 0.8350, Loss: 0.58025, Val Loss: 0.58157\n",
      "Epoch: 309, Train: 0.8368, Val: 0.8343, Test: 0.8351, Loss: 0.58022, Val Loss: 0.58154\n",
      "Epoch: 310, Train: 0.8368, Val: 0.8343, Test: 0.8351, Loss: 0.58018, Val Loss: 0.58151\n",
      "Epoch: 311, Train: 0.8368, Val: 0.8344, Test: 0.8351, Loss: 0.58015, Val Loss: 0.58148\n",
      "Epoch: 312, Train: 0.8368, Val: 0.8344, Test: 0.8351, Loss: 0.58012, Val Loss: 0.58145\n",
      "Epoch: 313, Train: 0.8368, Val: 0.8344, Test: 0.8352, Loss: 0.58009, Val Loss: 0.58142\n",
      "Epoch: 314, Train: 0.8369, Val: 0.8344, Test: 0.8352, Loss: 0.58006, Val Loss: 0.58139\n",
      "Epoch: 315, Train: 0.8369, Val: 0.8345, Test: 0.8352, Loss: 0.58003, Val Loss: 0.58136\n",
      "Epoch: 316, Train: 0.8369, Val: 0.8345, Test: 0.8352, Loss: 0.58000, Val Loss: 0.58133\n",
      "Epoch: 317, Train: 0.8369, Val: 0.8345, Test: 0.8352, Loss: 0.57997, Val Loss: 0.58130\n",
      "Epoch: 318, Train: 0.8369, Val: 0.8345, Test: 0.8353, Loss: 0.57994, Val Loss: 0.58127\n",
      "Epoch: 319, Train: 0.8370, Val: 0.8345, Test: 0.8353, Loss: 0.57991, Val Loss: 0.58124\n",
      "Epoch: 320, Train: 0.8370, Val: 0.8346, Test: 0.8353, Loss: 0.57988, Val Loss: 0.58121\n",
      "Epoch: 321, Train: 0.8370, Val: 0.8346, Test: 0.8353, Loss: 0.57985, Val Loss: 0.58118\n",
      "Epoch: 322, Train: 0.8370, Val: 0.8346, Test: 0.8353, Loss: 0.57983, Val Loss: 0.58116\n",
      "Epoch: 323, Train: 0.8370, Val: 0.8346, Test: 0.8354, Loss: 0.57980, Val Loss: 0.58113\n",
      "Epoch: 324, Train: 0.8370, Val: 0.8346, Test: 0.8354, Loss: 0.57977, Val Loss: 0.58110\n",
      "Epoch: 325, Train: 0.8371, Val: 0.8346, Test: 0.8354, Loss: 0.57974, Val Loss: 0.58107\n",
      "Epoch: 326, Train: 0.8371, Val: 0.8347, Test: 0.8354, Loss: 0.57972, Val Loss: 0.58105\n",
      "Epoch: 327, Train: 0.8371, Val: 0.8347, Test: 0.8354, Loss: 0.57969, Val Loss: 0.58102\n",
      "Epoch: 328, Train: 0.8371, Val: 0.8347, Test: 0.8354, Loss: 0.57966, Val Loss: 0.58099\n",
      "Epoch: 329, Train: 0.8371, Val: 0.8347, Test: 0.8355, Loss: 0.57964, Val Loss: 0.58097\n",
      "Epoch: 330, Train: 0.8372, Val: 0.8347, Test: 0.8355, Loss: 0.57961, Val Loss: 0.58094\n",
      "Epoch: 331, Train: 0.8372, Val: 0.8348, Test: 0.8355, Loss: 0.57959, Val Loss: 0.58092\n",
      "Epoch: 332, Train: 0.8372, Val: 0.8348, Test: 0.8355, Loss: 0.57956, Val Loss: 0.58089\n",
      "Epoch: 333, Train: 0.8372, Val: 0.8348, Test: 0.8355, Loss: 0.57954, Val Loss: 0.58087\n",
      "Epoch: 334, Train: 0.8372, Val: 0.8348, Test: 0.8355, Loss: 0.57951, Val Loss: 0.58084\n",
      "Epoch: 335, Train: 0.8372, Val: 0.8348, Test: 0.8356, Loss: 0.57949, Val Loss: 0.58082\n",
      "Epoch: 336, Train: 0.8372, Val: 0.8348, Test: 0.8356, Loss: 0.57946, Val Loss: 0.58079\n",
      "Epoch: 337, Train: 0.8373, Val: 0.8348, Test: 0.8356, Loss: 0.57944, Val Loss: 0.58077\n",
      "Epoch: 338, Train: 0.8373, Val: 0.8349, Test: 0.8356, Loss: 0.57941, Val Loss: 0.58075\n",
      "Epoch: 339, Train: 0.8373, Val: 0.8349, Test: 0.8356, Loss: 0.57939, Val Loss: 0.58072\n",
      "Epoch: 340, Train: 0.8373, Val: 0.8349, Test: 0.8356, Loss: 0.57937, Val Loss: 0.58070\n",
      "Epoch: 341, Train: 0.8373, Val: 0.8349, Test: 0.8357, Loss: 0.57934, Val Loss: 0.58068\n",
      "Epoch: 342, Train: 0.8373, Val: 0.8349, Test: 0.8357, Loss: 0.57932, Val Loss: 0.58065\n",
      "Epoch: 343, Train: 0.8374, Val: 0.8349, Test: 0.8357, Loss: 0.57930, Val Loss: 0.58063\n",
      "Epoch: 344, Train: 0.8374, Val: 0.8350, Test: 0.8357, Loss: 0.57928, Val Loss: 0.58061\n",
      "Epoch: 345, Train: 0.8374, Val: 0.8350, Test: 0.8357, Loss: 0.57925, Val Loss: 0.58059\n",
      "Epoch: 346, Train: 0.8374, Val: 0.8350, Test: 0.8357, Loss: 0.57923, Val Loss: 0.58057\n",
      "Epoch: 347, Train: 0.8374, Val: 0.8350, Test: 0.8357, Loss: 0.57921, Val Loss: 0.58055\n",
      "Epoch: 348, Train: 0.8374, Val: 0.8350, Test: 0.8358, Loss: 0.57919, Val Loss: 0.58052\n",
      "Epoch: 349, Train: 0.8374, Val: 0.8350, Test: 0.8358, Loss: 0.57917, Val Loss: 0.58050\n",
      "Epoch: 350, Train: 0.8375, Val: 0.8350, Test: 0.8358, Loss: 0.57915, Val Loss: 0.58048\n",
      "Epoch: 351, Train: 0.8375, Val: 0.8350, Test: 0.8358, Loss: 0.57913, Val Loss: 0.58046\n",
      "Epoch: 352, Train: 0.8375, Val: 0.8351, Test: 0.8358, Loss: 0.57911, Val Loss: 0.58044\n",
      "Epoch: 353, Train: 0.8375, Val: 0.8351, Test: 0.8358, Loss: 0.57909, Val Loss: 0.58042\n",
      "Epoch: 354, Train: 0.8375, Val: 0.8351, Test: 0.8358, Loss: 0.57907, Val Loss: 0.58040\n",
      "Epoch: 355, Train: 0.8375, Val: 0.8351, Test: 0.8358, Loss: 0.57905, Val Loss: 0.58038\n",
      "Epoch: 356, Train: 0.8375, Val: 0.8351, Test: 0.8359, Loss: 0.57903, Val Loss: 0.58036\n",
      "Epoch: 357, Train: 0.8375, Val: 0.8351, Test: 0.8359, Loss: 0.57901, Val Loss: 0.58034\n",
      "Epoch: 358, Train: 0.8376, Val: 0.8351, Test: 0.8359, Loss: 0.57899, Val Loss: 0.58032\n",
      "Epoch: 359, Train: 0.8376, Val: 0.8352, Test: 0.8359, Loss: 0.57897, Val Loss: 0.58031\n",
      "Epoch: 360, Train: 0.8376, Val: 0.8352, Test: 0.8359, Loss: 0.57895, Val Loss: 0.58029\n",
      "Epoch: 361, Train: 0.8376, Val: 0.8352, Test: 0.8359, Loss: 0.57893, Val Loss: 0.58027\n",
      "Epoch: 362, Train: 0.8376, Val: 0.8352, Test: 0.8359, Loss: 0.57891, Val Loss: 0.58025\n",
      "Epoch: 363, Train: 0.8376, Val: 0.8352, Test: 0.8359, Loss: 0.57889, Val Loss: 0.58023\n",
      "Epoch: 364, Train: 0.8376, Val: 0.8352, Test: 0.8360, Loss: 0.57888, Val Loss: 0.58021\n",
      "Epoch: 365, Train: 0.8376, Val: 0.8352, Test: 0.8360, Loss: 0.57886, Val Loss: 0.58020\n",
      "Epoch: 366, Train: 0.8376, Val: 0.8352, Test: 0.8360, Loss: 0.57884, Val Loss: 0.58018\n",
      "Epoch: 367, Train: 0.8377, Val: 0.8352, Test: 0.8360, Loss: 0.57882, Val Loss: 0.58016\n",
      "Epoch: 368, Train: 0.8377, Val: 0.8353, Test: 0.8360, Loss: 0.57881, Val Loss: 0.58015\n",
      "Epoch: 369, Train: 0.8377, Val: 0.8353, Test: 0.8360, Loss: 0.57879, Val Loss: 0.58013\n",
      "Epoch: 370, Train: 0.8377, Val: 0.8353, Test: 0.8360, Loss: 0.57877, Val Loss: 0.58011\n",
      "Epoch: 371, Train: 0.8377, Val: 0.8353, Test: 0.8360, Loss: 0.57876, Val Loss: 0.58009\n",
      "Epoch: 372, Train: 0.8377, Val: 0.8353, Test: 0.8360, Loss: 0.57874, Val Loss: 0.58008\n",
      "Epoch: 373, Train: 0.8377, Val: 0.8353, Test: 0.8361, Loss: 0.57872, Val Loss: 0.58006\n",
      "Epoch: 374, Train: 0.8377, Val: 0.8353, Test: 0.8361, Loss: 0.57871, Val Loss: 0.58005\n",
      "Epoch: 375, Train: 0.8377, Val: 0.8353, Test: 0.8361, Loss: 0.57869, Val Loss: 0.58003\n",
      "Epoch: 376, Train: 0.8377, Val: 0.8353, Test: 0.8361, Loss: 0.57867, Val Loss: 0.58001\n",
      "Epoch: 377, Train: 0.8378, Val: 0.8353, Test: 0.8361, Loss: 0.57866, Val Loss: 0.58000\n",
      "Epoch: 378, Train: 0.8378, Val: 0.8354, Test: 0.8361, Loss: 0.57864, Val Loss: 0.57998\n",
      "Epoch: 379, Train: 0.8378, Val: 0.8354, Test: 0.8361, Loss: 0.57863, Val Loss: 0.57997\n",
      "Epoch: 380, Train: 0.8378, Val: 0.8354, Test: 0.8361, Loss: 0.57861, Val Loss: 0.57995\n",
      "Epoch: 381, Train: 0.8378, Val: 0.8354, Test: 0.8361, Loss: 0.57860, Val Loss: 0.57994\n",
      "Epoch: 382, Train: 0.8378, Val: 0.8354, Test: 0.8361, Loss: 0.57858, Val Loss: 0.57992\n",
      "Epoch: 383, Train: 0.8378, Val: 0.8354, Test: 0.8362, Loss: 0.57857, Val Loss: 0.57991\n",
      "Epoch: 384, Train: 0.8378, Val: 0.8354, Test: 0.8362, Loss: 0.57855, Val Loss: 0.57989\n",
      "Epoch: 385, Train: 0.8378, Val: 0.8354, Test: 0.8362, Loss: 0.57854, Val Loss: 0.57988\n",
      "Epoch: 386, Train: 0.8378, Val: 0.8354, Test: 0.8362, Loss: 0.57852, Val Loss: 0.57987\n",
      "Epoch: 387, Train: 0.8378, Val: 0.8354, Test: 0.8362, Loss: 0.57851, Val Loss: 0.57985\n",
      "Epoch: 388, Train: 0.8379, Val: 0.8354, Test: 0.8362, Loss: 0.57850, Val Loss: 0.57984\n",
      "Epoch: 389, Train: 0.8379, Val: 0.8355, Test: 0.8362, Loss: 0.57848, Val Loss: 0.57982\n",
      "Epoch: 390, Train: 0.8379, Val: 0.8355, Test: 0.8362, Loss: 0.57847, Val Loss: 0.57981\n",
      "Epoch: 391, Train: 0.8379, Val: 0.8355, Test: 0.8362, Loss: 0.57845, Val Loss: 0.57980\n",
      "Epoch: 392, Train: 0.8379, Val: 0.8355, Test: 0.8362, Loss: 0.57844, Val Loss: 0.57978\n",
      "Epoch: 393, Train: 0.8379, Val: 0.8355, Test: 0.8362, Loss: 0.57843, Val Loss: 0.57977\n",
      "Epoch: 394, Train: 0.8379, Val: 0.8355, Test: 0.8362, Loss: 0.57841, Val Loss: 0.57976\n",
      "Epoch: 395, Train: 0.8379, Val: 0.8355, Test: 0.8363, Loss: 0.57840, Val Loss: 0.57974\n",
      "Epoch: 396, Train: 0.8379, Val: 0.8355, Test: 0.8363, Loss: 0.57839, Val Loss: 0.57973\n",
      "Epoch: 397, Train: 0.8379, Val: 0.8355, Test: 0.8363, Loss: 0.57838, Val Loss: 0.57972\n",
      "Epoch: 398, Train: 0.8379, Val: 0.8355, Test: 0.8363, Loss: 0.57836, Val Loss: 0.57971\n",
      "Epoch: 399, Train: 0.8379, Val: 0.8355, Test: 0.8363, Loss: 0.57835, Val Loss: 0.57969\n",
      "Epoch: 400, Train: 0.8379, Val: 0.8355, Test: 0.8363, Loss: 0.57834, Val Loss: 0.57968\n",
      "Epoch: 401, Train: 0.8380, Val: 0.8355, Test: 0.8363, Loss: 0.57833, Val Loss: 0.57967\n",
      "Epoch: 402, Train: 0.8380, Val: 0.8356, Test: 0.8363, Loss: 0.57831, Val Loss: 0.57966\n",
      "Epoch: 403, Train: 0.8380, Val: 0.8356, Test: 0.8363, Loss: 0.57830, Val Loss: 0.57965\n",
      "Epoch: 404, Train: 0.8380, Val: 0.8356, Test: 0.8363, Loss: 0.57829, Val Loss: 0.57963\n",
      "Epoch: 405, Train: 0.8380, Val: 0.8356, Test: 0.8363, Loss: 0.57828, Val Loss: 0.57962\n",
      "Epoch: 406, Train: 0.8380, Val: 0.8356, Test: 0.8363, Loss: 0.57827, Val Loss: 0.57961\n",
      "Epoch: 407, Train: 0.8380, Val: 0.8356, Test: 0.8363, Loss: 0.57826, Val Loss: 0.57960\n",
      "Epoch: 408, Train: 0.8380, Val: 0.8356, Test: 0.8363, Loss: 0.57824, Val Loss: 0.57959\n",
      "Epoch: 409, Train: 0.8380, Val: 0.8356, Test: 0.8364, Loss: 0.57823, Val Loss: 0.57958\n",
      "Epoch: 410, Train: 0.8380, Val: 0.8356, Test: 0.8364, Loss: 0.57822, Val Loss: 0.57957\n",
      "Epoch: 411, Train: 0.8380, Val: 0.8356, Test: 0.8364, Loss: 0.57821, Val Loss: 0.57955\n",
      "Epoch: 412, Train: 0.8380, Val: 0.8356, Test: 0.8364, Loss: 0.57820, Val Loss: 0.57954\n",
      "Epoch: 413, Train: 0.8380, Val: 0.8356, Test: 0.8364, Loss: 0.57819, Val Loss: 0.57953\n",
      "Epoch: 414, Train: 0.8380, Val: 0.8356, Test: 0.8364, Loss: 0.57818, Val Loss: 0.57952\n",
      "Epoch: 415, Train: 0.8380, Val: 0.8356, Test: 0.8364, Loss: 0.57817, Val Loss: 0.57951\n",
      "Epoch: 416, Train: 0.8381, Val: 0.8356, Test: 0.8364, Loss: 0.57816, Val Loss: 0.57950\n",
      "Epoch: 417, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57815, Val Loss: 0.57949\n",
      "Epoch: 418, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57814, Val Loss: 0.57948\n",
      "Epoch: 419, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57813, Val Loss: 0.57947\n",
      "Epoch: 420, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57812, Val Loss: 0.57946\n",
      "Epoch: 421, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57811, Val Loss: 0.57945\n",
      "Epoch: 422, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57810, Val Loss: 0.57944\n",
      "Epoch: 423, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57809, Val Loss: 0.57943\n",
      "Epoch: 424, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57808, Val Loss: 0.57942\n",
      "Epoch: 425, Train: 0.8381, Val: 0.8357, Test: 0.8364, Loss: 0.57807, Val Loss: 0.57941\n",
      "Epoch: 426, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57806, Val Loss: 0.57940\n",
      "Epoch: 427, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57805, Val Loss: 0.57939\n",
      "Epoch: 428, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57804, Val Loss: 0.57938\n",
      "Epoch: 429, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57803, Val Loss: 0.57938\n",
      "Epoch: 430, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57802, Val Loss: 0.57937\n",
      "Epoch: 431, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57801, Val Loss: 0.57936\n",
      "Epoch: 432, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57800, Val Loss: 0.57935\n",
      "Epoch: 433, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57799, Val Loss: 0.57934\n",
      "Epoch: 434, Train: 0.8381, Val: 0.8357, Test: 0.8365, Loss: 0.57798, Val Loss: 0.57933\n",
      "Epoch: 435, Train: 0.8382, Val: 0.8357, Test: 0.8365, Loss: 0.57798, Val Loss: 0.57932\n",
      "Epoch: 436, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57797, Val Loss: 0.57931\n",
      "Epoch: 437, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57796, Val Loss: 0.57931\n",
      "Epoch: 438, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57795, Val Loss: 0.57930\n",
      "Epoch: 439, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57794, Val Loss: 0.57929\n",
      "Epoch: 440, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57793, Val Loss: 0.57928\n",
      "Epoch: 441, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57793, Val Loss: 0.57927\n",
      "Epoch: 442, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57792, Val Loss: 0.57926\n",
      "Epoch: 443, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57791, Val Loss: 0.57926\n",
      "Epoch: 444, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57790, Val Loss: 0.57925\n",
      "Epoch: 445, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57789, Val Loss: 0.57924\n",
      "Epoch: 446, Train: 0.8382, Val: 0.8358, Test: 0.8365, Loss: 0.57789, Val Loss: 0.57923\n",
      "Epoch: 447, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57788, Val Loss: 0.57923\n",
      "Epoch: 448, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57787, Val Loss: 0.57922\n",
      "Epoch: 449, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57786, Val Loss: 0.57921\n",
      "Epoch: 450, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57786, Val Loss: 0.57920\n",
      "Epoch: 451, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57785, Val Loss: 0.57920\n",
      "Epoch: 452, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57784, Val Loss: 0.57919\n",
      "Epoch: 453, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57784, Val Loss: 0.57918\n",
      "Epoch: 454, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57783, Val Loss: 0.57918\n",
      "Epoch: 455, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57782, Val Loss: 0.57917\n",
      "Epoch: 456, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57781, Val Loss: 0.57916\n",
      "Epoch: 457, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57781, Val Loss: 0.57915\n",
      "Epoch: 458, Train: 0.8382, Val: 0.8358, Test: 0.8366, Loss: 0.57780, Val Loss: 0.57915\n",
      "Epoch: 459, Train: 0.8383, Val: 0.8358, Test: 0.8366, Loss: 0.57779, Val Loss: 0.57914\n",
      "Epoch: 460, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57779, Val Loss: 0.57913\n",
      "Epoch: 461, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57778, Val Loss: 0.57913\n",
      "Epoch: 462, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57777, Val Loss: 0.57912\n",
      "Epoch: 463, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57777, Val Loss: 0.57912\n",
      "Epoch: 464, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57776, Val Loss: 0.57911\n",
      "Epoch: 465, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57775, Val Loss: 0.57910\n",
      "Epoch: 466, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57775, Val Loss: 0.57910\n",
      "Epoch: 467, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57774, Val Loss: 0.57909\n",
      "Epoch: 468, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57774, Val Loss: 0.57908\n",
      "Epoch: 469, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57773, Val Loss: 0.57908\n",
      "Epoch: 470, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57772, Val Loss: 0.57907\n",
      "Epoch: 471, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57772, Val Loss: 0.57907\n",
      "Epoch: 472, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57771, Val Loss: 0.57906\n",
      "Epoch: 473, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57771, Val Loss: 0.57905\n",
      "Epoch: 474, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57770, Val Loss: 0.57905\n",
      "Epoch: 475, Train: 0.8383, Val: 0.8359, Test: 0.8366, Loss: 0.57769, Val Loss: 0.57904\n",
      "Epoch: 476, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57769, Val Loss: 0.57904\n",
      "Epoch: 477, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57768, Val Loss: 0.57903\n",
      "Epoch: 478, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57768, Val Loss: 0.57903\n",
      "Epoch: 479, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57767, Val Loss: 0.57902\n",
      "Epoch: 480, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57767, Val Loss: 0.57902\n",
      "Epoch: 481, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57766, Val Loss: 0.57901\n",
      "Epoch: 482, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57766, Val Loss: 0.57901\n",
      "Epoch: 483, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57765, Val Loss: 0.57900\n",
      "Epoch: 484, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57765, Val Loss: 0.57899\n",
      "Epoch: 485, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57764, Val Loss: 0.57899\n",
      "Epoch: 486, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57764, Val Loss: 0.57898\n",
      "Epoch: 487, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57763, Val Loss: 0.57898\n",
      "Epoch: 488, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57763, Val Loss: 0.57897\n",
      "Epoch: 489, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57762, Val Loss: 0.57897\n",
      "Epoch: 490, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57762, Val Loss: 0.57896\n",
      "Epoch: 491, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57761, Val Loss: 0.57896\n",
      "Epoch: 492, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57761, Val Loss: 0.57896\n",
      "Epoch: 493, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57760, Val Loss: 0.57895\n",
      "Epoch: 494, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57760, Val Loss: 0.57895\n",
      "Epoch: 495, Train: 0.8383, Val: 0.8359, Test: 0.8367, Loss: 0.57759, Val Loss: 0.57894\n",
      "Epoch: 496, Train: 0.8384, Val: 0.8359, Test: 0.8367, Loss: 0.57759, Val Loss: 0.57894\n",
      "Epoch: 497, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57758, Val Loss: 0.57893\n",
      "Epoch: 498, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57758, Val Loss: 0.57893\n",
      "Epoch: 499, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57757, Val Loss: 0.57892\n",
      "Epoch: 500, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57757, Val Loss: 0.57892\n",
      "Epoch: 501, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57756, Val Loss: 0.57891\n",
      "Epoch: 502, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57756, Val Loss: 0.57891\n",
      "Epoch: 503, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57756, Val Loss: 0.57891\n",
      "Epoch: 504, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57755, Val Loss: 0.57890\n",
      "Epoch: 505, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57755, Val Loss: 0.57890\n",
      "Epoch: 506, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57754, Val Loss: 0.57889\n",
      "Epoch: 507, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57754, Val Loss: 0.57889\n",
      "Epoch: 508, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57753, Val Loss: 0.57889\n",
      "Epoch: 509, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57753, Val Loss: 0.57888\n",
      "Epoch: 510, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57753, Val Loss: 0.57888\n",
      "Epoch: 511, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57752, Val Loss: 0.57887\n",
      "Epoch: 512, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57752, Val Loss: 0.57887\n",
      "Epoch: 513, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57752, Val Loss: 0.57887\n",
      "Epoch: 514, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57751, Val Loss: 0.57886\n",
      "Epoch: 515, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57751, Val Loss: 0.57886\n",
      "Epoch: 516, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57750, Val Loss: 0.57885\n",
      "Epoch: 517, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57750, Val Loss: 0.57885\n",
      "Epoch: 518, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57750, Val Loss: 0.57885\n",
      "Epoch: 519, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57749, Val Loss: 0.57884\n",
      "Epoch: 520, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57749, Val Loss: 0.57884\n",
      "Epoch: 521, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57749, Val Loss: 0.57884\n",
      "Epoch: 522, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57748, Val Loss: 0.57883\n",
      "Epoch: 523, Train: 0.8384, Val: 0.8360, Test: 0.8367, Loss: 0.57748, Val Loss: 0.57883\n",
      "Epoch: 524, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57748, Val Loss: 0.57883\n",
      "Epoch: 525, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57747, Val Loss: 0.57882\n",
      "Epoch: 526, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57747, Val Loss: 0.57882\n",
      "Epoch: 527, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57746, Val Loss: 0.57882\n",
      "Epoch: 528, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57746, Val Loss: 0.57881\n",
      "Epoch: 529, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57746, Val Loss: 0.57881\n",
      "Epoch: 530, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57745, Val Loss: 0.57881\n",
      "Epoch: 531, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57745, Val Loss: 0.57880\n",
      "Epoch: 532, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57745, Val Loss: 0.57880\n",
      "Epoch: 533, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57745, Val Loss: 0.57880\n",
      "Epoch: 534, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57744, Val Loss: 0.57879\n",
      "Epoch: 535, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57744, Val Loss: 0.57879\n",
      "Epoch: 536, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57744, Val Loss: 0.57879\n",
      "Epoch: 537, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57743, Val Loss: 0.57878\n",
      "Epoch: 538, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57743, Val Loss: 0.57878\n",
      "Epoch: 539, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57743, Val Loss: 0.57878\n",
      "Epoch: 540, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57742, Val Loss: 0.57878\n",
      "Epoch: 541, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57742, Val Loss: 0.57877\n",
      "Epoch: 542, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57742, Val Loss: 0.57877\n",
      "Epoch: 543, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57742, Val Loss: 0.57877\n",
      "Epoch: 544, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57741, Val Loss: 0.57876\n",
      "Epoch: 545, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57741, Val Loss: 0.57876\n",
      "Epoch: 546, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57741, Val Loss: 0.57876\n",
      "Epoch: 547, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57740, Val Loss: 0.57876\n",
      "Epoch: 548, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57740, Val Loss: 0.57875\n",
      "Epoch: 549, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57740, Val Loss: 0.57875\n",
      "Epoch: 550, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57740, Val Loss: 0.57875\n",
      "Epoch: 551, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57739, Val Loss: 0.57875\n",
      "Epoch: 552, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57739, Val Loss: 0.57874\n",
      "Epoch: 553, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57739, Val Loss: 0.57874\n",
      "Epoch: 554, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57739, Val Loss: 0.57874\n",
      "Epoch: 555, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57738, Val Loss: 0.57874\n",
      "Epoch: 556, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57738, Val Loss: 0.57873\n",
      "Epoch: 557, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57738, Val Loss: 0.57873\n",
      "Epoch: 558, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57738, Val Loss: 0.57873\n",
      "Epoch: 559, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57737, Val Loss: 0.57873\n",
      "Epoch: 560, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57737, Val Loss: 0.57872\n",
      "Epoch: 561, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57737, Val Loss: 0.57872\n",
      "Epoch: 562, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57737, Val Loss: 0.57872\n",
      "Epoch: 563, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57736, Val Loss: 0.57872\n",
      "Epoch: 564, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57736, Val Loss: 0.57871\n",
      "Epoch: 565, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57736, Val Loss: 0.57871\n",
      "Epoch: 566, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57736, Val Loss: 0.57871\n",
      "Epoch: 567, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57736, Val Loss: 0.57871\n",
      "Epoch: 568, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57735, Val Loss: 0.57871\n",
      "Epoch: 569, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57735, Val Loss: 0.57870\n",
      "Epoch: 570, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57735, Val Loss: 0.57870\n",
      "Epoch: 571, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57735, Val Loss: 0.57870\n",
      "Epoch: 572, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57734, Val Loss: 0.57870\n",
      "Epoch: 573, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57734, Val Loss: 0.57869\n",
      "Epoch: 574, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57734, Val Loss: 0.57869\n",
      "Epoch: 575, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57734, Val Loss: 0.57869\n",
      "Epoch: 576, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57734, Val Loss: 0.57869\n",
      "Epoch: 577, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57733, Val Loss: 0.57869\n",
      "Epoch: 578, Train: 0.8384, Val: 0.8360, Test: 0.8368, Loss: 0.57733, Val Loss: 0.57868\n",
      "Epoch: 579, Train: 0.8384, Val: 0.8361, Test: 0.8368, Loss: 0.57733, Val Loss: 0.57868\n",
      "Epoch: 580, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57733, Val Loss: 0.57868\n",
      "Epoch: 581, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57733, Val Loss: 0.57868\n",
      "Epoch: 582, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57732, Val Loss: 0.57868\n",
      "Epoch: 583, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57732, Val Loss: 0.57868\n",
      "Epoch: 584, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57732, Val Loss: 0.57867\n",
      "Epoch: 585, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57732, Val Loss: 0.57867\n",
      "Epoch: 586, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57732, Val Loss: 0.57867\n",
      "Epoch: 587, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57732, Val Loss: 0.57867\n",
      "Epoch: 588, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57731, Val Loss: 0.57867\n",
      "Epoch: 589, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57731, Val Loss: 0.57866\n",
      "Epoch: 590, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57731, Val Loss: 0.57866\n",
      "Epoch: 591, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57731, Val Loss: 0.57866\n",
      "Epoch: 592, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57731, Val Loss: 0.57866\n",
      "Epoch: 593, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57730, Val Loss: 0.57866\n",
      "Epoch: 594, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57730, Val Loss: 0.57866\n",
      "Epoch: 595, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57730, Val Loss: 0.57865\n",
      "Epoch: 596, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57730, Val Loss: 0.57865\n",
      "Epoch: 597, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57730, Val Loss: 0.57865\n",
      "Epoch: 598, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57730, Val Loss: 0.57865\n",
      "Epoch: 599, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57729, Val Loss: 0.57865\n",
      "Epoch: 600, Train: 0.8385, Val: 0.8361, Test: 0.8368, Loss: 0.57729, Val Loss: 0.57865\n",
      "Train: 0.8385, Val: 0.8361, Test: 0.8368, Train Loss: 0.57729, Val Loss: 0.57865, Test Loss: 0.57837\n"
     ]
    }
   ],
   "source": [
    "model = LightGCN(datasets['train'], args['num_layers'], emb_size=args['emb_size']).to(args['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "best_model = train(model, optimizer, args)\n",
    "log = \"Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Train Loss: {:.5f}, Val Loss: {:.5f}, Test Loss: {:.5f}\"\n",
    "best_train_roc, train_loss = test(best_model, 'train', args)\n",
    "best_val_roc, val_loss = test(best_model, 'val', args)\n",
    "best_test_roc, test_loss = test(best_model, 'test', args)\n",
    "print(log.format(best_train_roc, best_val_roc, best_test_roc, train_loss, val_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df4188-1bed-4ab8-9ed3-fff30a3a0207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "639674ee-a6bb-4de5-8d98-6dc8ea3222ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_save\n",
    "filename = 'best_lgcn.pkl'\n",
    "torch.save(best_model, filename)\n",
    "\n",
    "#datasets save\n",
    "# with open('datasets_deepsnap_dict.pkl', 'wb') as f:\n",
    "#     # pickle the dictionary and write it to the file\n",
    "#     pickle.dump(datasets, f)\n",
    "\n",
    "# model = torch.load('../lgcn.pkl')\n",
    "# with open('../datasets_deepsnap_dict.pkl', 'rb') as f:\n",
    "#     # load the pickled dictionary from the file\n",
    "#     datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf06e0ad-076a-4fb0-aa5f-1104ca357558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(losses, title):\n",
    "    train_loss, val_loss = zip(*losses)\n",
    "    steps = list(range(1, len(train_loss) + 1))\n",
    "    \n",
    "    min_val_loss = np.round(np.min(val_loss), 3)\n",
    "    # train_list = [math.log10(x) for x in train_loss]\n",
    "    # val_list = [math.log10(x) for x in val_loss]\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.plot(steps, train_loss, '-r', label='Training Loss')\n",
    "    plt.plot(steps, val_loss, '-b', label='Validation Loss')\n",
    "    plt.hlines(min_val_loss, 1, 300, colors='k', linestyles='dotted', label='Min Validation Loss: {}'.format(min_val_loss))\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.ylim((0.58, 0.71))\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb1bc6a1-38ca-49d8-9ecc-1d9be4dd8d32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/asd27/.conda/envs/cudatorch/lib/python3.11/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(losses, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8b4dfc4-cc06-41fd-a294-bf2cf2690035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = datasets['test']\n",
    "pred = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b551daf-fd42-455c-ac80-b9aa0908fe81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6940, 0.6075, 0.6814,  ..., 0.5872, 0.6009, 0.4303], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77372322-0b1e-4470-92ae-a839a2abfd74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "725284"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71e03714-d91b-4cc9-b2fb-ceffeb950090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(G=[], edge_index=[2, 3263754], edge_label=[725284], edge_label_index=[2, 725284], name=[38565], negative_label_val=[1], node_label_index=[38565], type=[38565], uri=[38565])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets['test']\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5a8a5a8-056c-4dc1-a4c0-c4b272c0af85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e088514-d2e7-48b0-80a7-def67abae7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds.edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ba87275-4205-40ac-b8f6-774768d24d40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>src_node</th>\n",
       "      <th>dest_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.694010</td>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>26709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607457</td>\n",
       "      <td>1</td>\n",
       "      <td>959</td>\n",
       "      <td>36647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681380</td>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>24836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635903</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>12467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635222</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>12723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      preds  edge_label  src_node  dest_node\n",
       "0  0.694010           1       663      26709\n",
       "1  0.607457           1       959      36647\n",
       "2  0.681380           1       562      24836\n",
       "3  0.635903           1       225      12467\n",
       "4  0.635222           1       230      12723"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {'preds':pred.to('cpu').detach().numpy(), 'edge_label': ds.edge_label.to('cpu').detach().numpy(), 'src_node': ds.edge_label_index[0].to('cpu').detach().numpy(), 'dest_node': ds.edge_label_index[1].to('cpu').detach().numpy()}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea71fb42-fc5b-4151-931b-dc027d0cf224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>src_node</th>\n",
       "      <th>dest_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362642</th>\n",
       "      <td>0.639193</td>\n",
       "      <td>0</td>\n",
       "      <td>32716</td>\n",
       "      <td>38339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362643</th>\n",
       "      <td>0.497316</td>\n",
       "      <td>0</td>\n",
       "      <td>1707</td>\n",
       "      <td>34635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362644</th>\n",
       "      <td>0.458209</td>\n",
       "      <td>0</td>\n",
       "      <td>1060</td>\n",
       "      <td>25937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362645</th>\n",
       "      <td>0.377160</td>\n",
       "      <td>0</td>\n",
       "      <td>11428</td>\n",
       "      <td>29437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362646</th>\n",
       "      <td>0.327507</td>\n",
       "      <td>0</td>\n",
       "      <td>24659</td>\n",
       "      <td>33235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725279</th>\n",
       "      <td>0.613643</td>\n",
       "      <td>0</td>\n",
       "      <td>8207</td>\n",
       "      <td>11693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725280</th>\n",
       "      <td>0.340819</td>\n",
       "      <td>0</td>\n",
       "      <td>20530</td>\n",
       "      <td>31785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725281</th>\n",
       "      <td>0.587192</td>\n",
       "      <td>0</td>\n",
       "      <td>29022</td>\n",
       "      <td>33586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725282</th>\n",
       "      <td>0.600884</td>\n",
       "      <td>0</td>\n",
       "      <td>22040</td>\n",
       "      <td>18148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725283</th>\n",
       "      <td>0.430271</td>\n",
       "      <td>0</td>\n",
       "      <td>36582</td>\n",
       "      <td>22023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362642 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           preds  edge_label  src_node  dest_node\n",
       "362642  0.639193           0     32716      38339\n",
       "362643  0.497316           0      1707      34635\n",
       "362644  0.458209           0      1060      25937\n",
       "362645  0.377160           0     11428      29437\n",
       "362646  0.327507           0     24659      33235\n",
       "...          ...         ...       ...        ...\n",
       "725279  0.613643           0      8207      11693\n",
       "725280  0.340819           0     20530      31785\n",
       "725281  0.587192           0     29022      33586\n",
       "725282  0.600884           0     22040      18148\n",
       "725283  0.430271           0     36582      22023\n",
       "\n",
       "[362642 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df[df['edge_label'] == 0]\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c15da10-f9e0-405f-97be-39d17965ea92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>src_node</th>\n",
       "      <th>dest_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.694010</td>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>26709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607457</td>\n",
       "      <td>1</td>\n",
       "      <td>959</td>\n",
       "      <td>36647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681380</td>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>24836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635903</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>12467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635222</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>12723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362637</th>\n",
       "      <td>0.690186</td>\n",
       "      <td>1</td>\n",
       "      <td>22543</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362638</th>\n",
       "      <td>0.639454</td>\n",
       "      <td>1</td>\n",
       "      <td>9774</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362639</th>\n",
       "      <td>0.671365</td>\n",
       "      <td>1</td>\n",
       "      <td>19429</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362640</th>\n",
       "      <td>0.669155</td>\n",
       "      <td>1</td>\n",
       "      <td>18315</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362641</th>\n",
       "      <td>0.670911</td>\n",
       "      <td>1</td>\n",
       "      <td>20103</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362642 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           preds  edge_label  src_node  dest_node\n",
       "0       0.694010           1       663      26709\n",
       "1       0.607457           1       959      36647\n",
       "2       0.681380           1       562      24836\n",
       "3       0.635903           1       225      12467\n",
       "4       0.635222           1       230      12723\n",
       "...          ...         ...       ...        ...\n",
       "362637  0.690186           1     22543        525\n",
       "362638  0.639454           1      9774        163\n",
       "362639  0.671365           1     19429        412\n",
       "362640  0.669155           1     18315        401\n",
       "362641  0.670911           1     20103        423\n",
       "\n",
       "[362642 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df[df['edge_label'] == 1]\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffb0e93e-b815-47f1-8a14-6b56b4ac0f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>src_node</th>\n",
       "      <th>dest_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.694010</td>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>26709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607457</td>\n",
       "      <td>1</td>\n",
       "      <td>959</td>\n",
       "      <td>36647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681380</td>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>24836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635903</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>12467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635222</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>12723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362637</th>\n",
       "      <td>0.690186</td>\n",
       "      <td>1</td>\n",
       "      <td>22543</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362638</th>\n",
       "      <td>0.639454</td>\n",
       "      <td>1</td>\n",
       "      <td>9774</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362639</th>\n",
       "      <td>0.671365</td>\n",
       "      <td>1</td>\n",
       "      <td>19429</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362640</th>\n",
       "      <td>0.669155</td>\n",
       "      <td>1</td>\n",
       "      <td>18315</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362641</th>\n",
       "      <td>0.670911</td>\n",
       "      <td>1</td>\n",
       "      <td>20103</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362550 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           preds  edge_label  src_node  dest_node\n",
       "0       0.694010           1       663      26709\n",
       "1       0.607457           1       959      36647\n",
       "2       0.681380           1       562      24836\n",
       "3       0.635903           1       225      12467\n",
       "4       0.635222           1       230      12723\n",
       "...          ...         ...       ...        ...\n",
       "362637  0.690186           1     22543        525\n",
       "362638  0.639454           1      9774        163\n",
       "362639  0.671365           1     19429        412\n",
       "362640  0.669155           1     18315        401\n",
       "362641  0.670911           1     20103        423\n",
       "\n",
       "[362550 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lessthan = df_1[df_1['preds'] > 0.5]\n",
    "df_lessthan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0549d1f9-a11c-4316-8db8-46f1eba89cef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lessthan.iloc[0]['src_node']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a9737a6-f63e-43e4-86c2-3f7817d9120f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({1000: {}, 1001: {}, 1002: {}, 1003: {}, 1004: {}, 1005: {}, 1006: {}, 1007: {}, 1008: {}, 1009: {}, 1010: {}, 1011: {}, 1012: {}, 1013: {}, 1014: {}, 1015: {}, 1016: {}, 1017: {}, 1018: {}, 1019: {}, 1020: {}, 1021: {}, 1022: {}, 1023: {}, 1024: {}, 1025: {}, 1026: {}, 1027: {}, 1028: {}, 1029: {}, 1030: {}, 1031: {}, 1032: {}, 1033: {}, 1034: {}, 1035: {}, 1036: {}, 1037: {}, 1038: {}, 1039: {}, 1040: {}, 1041: {}, 1042: {}, 1043: {}, 1044: {}, 1045: {}, 1046: {}, 1047: {}, 1048: {}, 1049: {}, 1050: {}, 1051: {}, 1052: {}, 1053: {}, 1054: {}, 1055: {}, 1056: {}, 1057: {}, 1058: {}, 1059: {}, 1060: {}, 1061: {}, 1062: {}, 1063: {}, 1064: {}, 1065: {}, 1066: {}, 1067: {}, 1068: {}, 1069: {}, 1070: {}, 1071: {}, 1072: {}, 1073: {}, 1074: {}, 1075: {}, 1076: {}, 1077: {}, 1078: {}, 1079: {}, 1080: {}, 1081: {}, 1082: {}, 1083: {}, 1084: {}, 1085: {}, 1086: {}, 1087: {}, 1088: {}, 1089: {}, 1090: {}, 1091: {}, 1092: {}, 1093: {}, 1094: {}, 1095: {}, 1096: {}, 1097: {}, 1098: {}, 1099: {}, 1100: {}, 1101: {}, 1102: {}, 1103: {}, 1104: {}, 1105: {}, 1106: {}, 1107: {}, 1108: {}, 1109: {}, 1110: {}, 1111: {}, 1112: {}, 1113: {}, 1114: {}, 1115: {}, 1116: {}, 1117: {}, 1118: {}, 1119: {}, 1120: {}, 1121: {}, 1122: {}, 1123: {}, 1124: {}, 1125: {}, 1126: {}, 1127: {}, 1128: {}, 1129: {}, 1130: {}, 1131: {}, 1132: {}, 1133: {}, 1134: {}, 1135: {}, 1136: {}, 1137: {}, 1138: {}, 1139: {}, 1140: {}, 1141: {}, 1142: {}, 1143: {}, 1144: {}, 1145: {}, 1146: {}, 1147: {}, 1148: {}, 1149: {}, 1150: {}, 1151: {}, 1152: {}, 1153: {}, 1154: {}, 1155: {}, 1156: {}, 1157: {}, 1158: {}, 1159: {}, 1160: {}, 1161: {}, 1162: {}, 1163: {}, 1164: {}, 1165: {}, 1166: {}, 1167: {}, 1168: {}, 1169: {}, 1170: {}, 1171: {}, 1172: {}, 1173: {}, 1174: {}, 1175: {}, 1176: {}, 1177: {}, 1178: {}, 1179: {}, 1180: {}, 1181: {}, 1182: {}, 1183: {}, 1184: {}, 1185: {}, 1186: {}, 1187: {}, 1188: {}, 1189: {}, 1190: {}, 1191: {}, 1192: {}, 1193: {}, 1194: {}, 1195: {}, 1196: {}, 1197: {}, 1198: {}, 1199: {}, 1200: {}, 1201: {}, 1202: {}, 1203: {}, 1204: {}, 1205: {}, 1206: {}, 1207: {}, 1208: {}, 1209: {}, 1210: {}, 1211: {}, 1212: {}, 1213: {}, 1214: {}, 1215: {}, 1216: {}, 1217: {}, 1218: {}, 1219: {}, 1220: {}, 1221: {}, 1222: {}, 1223: {}, 1224: {}, 1225: {}, 1226: {}, 1227: {}, 1228: {}, 1229: {}, 1230: {}, 1231: {}, 1232: {}, 1233: {}, 1234: {}, 1235: {}})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_nx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2a70249-0d4c-4d83-9356-4927956b0d99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lessthan.iloc[0][\"src_node\"]\n",
    "counter=0\n",
    "neg=0\n",
    "for x in g_nx.nodes:\n",
    "    if(counter!=x):\n",
    "        neg=neg+x-counter\n",
    "        counter=x\n",
    "    counter=counter+1\n",
    "print(len(g_nx.nodes))\n",
    "neg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84feddca-e722-4ba3-88f6-52870d95a38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc283a02-b0bc-49ea-8776-0b79f321be6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def row_op(row):\n",
    "\n",
    "    if g_nx.nodes[row['src_node']]['name'] == g_nx.nodes[row['dest_node']]['name'] or g_nx.nodes[row['src_node']]['uri'] == g_nx.nodes[row['dest_node']]['uri']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df_lessthan['is_valid'] = df_lessthan.apply(row_op,axis=1)\n",
    "df_filter=df_lessthan[df_lessthan['is_valid']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e9d3ae7-48bf-480d-a8de-883fa4c6085f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getId(row):\n",
    "    return pd.Series([g_nx.nodes[row['src_node']]['name'],g_nx.nodes[row['src_node']]['uri'],g_nx.nodes[row['src_node']]['type'],g_nx.nodes[row['dest_node']]['name'],g_nx.nodes[row['dest_node']]['uri'],g_nx.nodes[row['dest_node']]['type']])\n",
    "    \n",
    "df_filter[[\"src_name\",\"src_uri\",\"src_type\",\"dest_name\",\"dest_uri\",\"dest_type\"]]=df_filter[df_lessthan['is_valid']].apply(getId,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95775e86-1b83-4f29-b8b5-373e2f0de91e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>src_node</th>\n",
       "      <th>dest_node</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_uri</th>\n",
       "      <th>src_type</th>\n",
       "      <th>dest_name</th>\n",
       "      <th>dest_uri</th>\n",
       "      <th>dest_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.694010</td>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>26709</td>\n",
       "      <td>True</td>\n",
       "      <td>2000s hits</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:15KUDgDxvkghmtB6FxI7Dt</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681380</td>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>24836</td>\n",
       "      <td>True</td>\n",
       "      <td>Country summer</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:3Cx9j78Z0NE6jYwBWvvV3P</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635903</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>12467</td>\n",
       "      <td>True</td>\n",
       "      <td>Volleyball</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:5VJjhHyG8NZ5xdgG6uTb3P</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635222</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>12723</td>\n",
       "      <td>True</td>\n",
       "      <td>Summer of love</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:1mXejq3WXXF7YaXnRoP1gq</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.643328</td>\n",
       "      <td>1</td>\n",
       "      <td>338</td>\n",
       "      <td>15711</td>\n",
       "      <td>True</td>\n",
       "      <td>((chris))</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:3gx6E5B42WHKf5agVWQAf2</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362637</th>\n",
       "      <td>0.690186</td>\n",
       "      <td>1</td>\n",
       "      <td>22543</td>\n",
       "      <td>525</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:3z9e5b0P7zoIeV6I3iyX8O</td>\n",
       "      <td>track</td>\n",
       "      <td>Tejano</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362638</th>\n",
       "      <td>0.639454</td>\n",
       "      <td>1</td>\n",
       "      <td>9774</td>\n",
       "      <td>163</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:0scQIzgcOhnmfqfOTpRUFH</td>\n",
       "      <td>track</td>\n",
       "      <td>pump</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362639</th>\n",
       "      <td>0.671365</td>\n",
       "      <td>1</td>\n",
       "      <td>19429</td>\n",
       "      <td>412</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:48td6xvpokdYwvbl3JIiXP</td>\n",
       "      <td>track</td>\n",
       "      <td>Country</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362640</th>\n",
       "      <td>0.669155</td>\n",
       "      <td>1</td>\n",
       "      <td>18315</td>\n",
       "      <td>401</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:1ntaQ5nSrrbJwEuwAAbHiY</td>\n",
       "      <td>track</td>\n",
       "      <td>GET DOWN</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362641</th>\n",
       "      <td>0.670911</td>\n",
       "      <td>1</td>\n",
       "      <td>20103</td>\n",
       "      <td>423</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:18dQgDh5WDUH99YIkRf0dA</td>\n",
       "      <td>track</td>\n",
       "      <td>New</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357336 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           preds  edge_label  src_node  dest_node  is_valid        src_name  \\\n",
       "0       0.694010           1       663      26709      True      2000s hits   \n",
       "2       0.681380           1       562      24836      True  Country summer   \n",
       "3       0.635903           1       225      12467      True      Volleyball   \n",
       "4       0.635222           1       230      12723      True  Summer of love   \n",
       "5       0.643328           1       338      15711      True       ((chris))   \n",
       "...          ...         ...       ...        ...       ...             ...   \n",
       "362637  0.690186           1     22543        525      True                   \n",
       "362638  0.639454           1      9774        163      True                   \n",
       "362639  0.671365           1     19429        412      True                   \n",
       "362640  0.669155           1     18315        401      True                   \n",
       "362641  0.670911           1     20103        423      True                   \n",
       "\n",
       "                                     src_uri  src_type dest_name  \\\n",
       "0                                             playlist             \n",
       "2                                             playlist             \n",
       "3                                             playlist             \n",
       "4                                             playlist             \n",
       "5                                             playlist             \n",
       "...                                      ...       ...       ...   \n",
       "362637  spotify:track:3z9e5b0P7zoIeV6I3iyX8O     track    Tejano   \n",
       "362638  spotify:track:0scQIzgcOhnmfqfOTpRUFH     track      pump   \n",
       "362639  spotify:track:48td6xvpokdYwvbl3JIiXP     track   Country   \n",
       "362640  spotify:track:1ntaQ5nSrrbJwEuwAAbHiY     track  GET DOWN   \n",
       "362641  spotify:track:18dQgDh5WDUH99YIkRf0dA     track       New   \n",
       "\n",
       "                                    dest_uri dest_type  \n",
       "0       spotify:track:15KUDgDxvkghmtB6FxI7Dt     track  \n",
       "2       spotify:track:3Cx9j78Z0NE6jYwBWvvV3P     track  \n",
       "3       spotify:track:5VJjhHyG8NZ5xdgG6uTb3P     track  \n",
       "4       spotify:track:1mXejq3WXXF7YaXnRoP1gq     track  \n",
       "5       spotify:track:3gx6E5B42WHKf5agVWQAf2     track  \n",
       "...                                      ...       ...  \n",
       "362637                                        playlist  \n",
       "362638                                        playlist  \n",
       "362639                                        playlist  \n",
       "362640                                        playlist  \n",
       "362641                                        playlist  \n",
       "\n",
       "[357336 rows x 11 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68f80f71-0bae-46b0-bb2d-411ee0015f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_filter[(df_filter['src_name']==\"Party mix\") | ( df_filter['dest_name']==\"Party mix\") ]\n",
    "df_final.sort_values('preds',ascending=False)\n",
    "uri_list=list(df_final.apply(lambda x: x['src_uri'] if x['src_uri']!='' else x['dest_uri'], axis=1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cde8a113-86ca-4a1d-96d3-4fba616b28c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74b5ba22-cf68-4f75-9e03-22f582a16315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uri_list=[]\n",
    "uri_list = list(df_final[\"dest_uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6083828e-03cc-4ce3-9494-fd35a83ae9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>src_node</th>\n",
       "      <th>dest_node</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_uri</th>\n",
       "      <th>src_type</th>\n",
       "      <th>dest_name</th>\n",
       "      <th>dest_uri</th>\n",
       "      <th>dest_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.684027</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>24909</td>\n",
       "      <td>True</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:7kT30Qf4aSg9lrwxsnGS2I</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.687354</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>23810</td>\n",
       "      <td>True</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:5AnszA1GMtDt8CFIWMnwyg</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.687035</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>23886</td>\n",
       "      <td>True</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:2AgnbuzvnfPvq1sAYNB4pj</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.684099</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>23476</td>\n",
       "      <td>True</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:1EAb9MI3olU3eiyGhrMylw</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.659459</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>26096</td>\n",
       "      <td>True</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:56DJzEuZugYdTYxi6VAdVh</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358416</th>\n",
       "      <td>0.688048</td>\n",
       "      <td>1</td>\n",
       "      <td>24256</td>\n",
       "      <td>575</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:7ek8SSCHpRuZQclgonvjJh</td>\n",
       "      <td>track</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359953</th>\n",
       "      <td>0.676060</td>\n",
       "      <td>1</td>\n",
       "      <td>25420</td>\n",
       "      <td>575</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:3RZrtVbjRfs9QTJx5nexVi</td>\n",
       "      <td>track</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361173</th>\n",
       "      <td>0.687955</td>\n",
       "      <td>1</td>\n",
       "      <td>24390</td>\n",
       "      <td>575</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:4vByq0ENplmS7kXAVOVNvq</td>\n",
       "      <td>track</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361419</th>\n",
       "      <td>0.676737</td>\n",
       "      <td>1</td>\n",
       "      <td>22833</td>\n",
       "      <td>575</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:4Pa5XXpn3sdBPMVCSWGEhB</td>\n",
       "      <td>track</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362179</th>\n",
       "      <td>0.685765</td>\n",
       "      <td>1</td>\n",
       "      <td>23578</td>\n",
       "      <td>575</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>spotify:track:2HCaIYjkvWSZzaSKUoOh3d</td>\n",
       "      <td>track</td>\n",
       "      <td>Party mix</td>\n",
       "      <td></td>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           preds  edge_label  src_node  dest_node  is_valid   src_name  \\\n",
       "377     0.684027           1       575      24909      True  Party mix   \n",
       "467     0.687354           1       575      23810      True  Party mix   \n",
       "712     0.687035           1       575      23886      True  Party mix   \n",
       "1011    0.684099           1       575      23476      True  Party mix   \n",
       "1148    0.659459           1       575      26096      True  Party mix   \n",
       "...          ...         ...       ...        ...       ...        ...   \n",
       "358416  0.688048           1     24256        575      True              \n",
       "359953  0.676060           1     25420        575      True              \n",
       "361173  0.687955           1     24390        575      True              \n",
       "361419  0.676737           1     22833        575      True              \n",
       "362179  0.685765           1     23578        575      True              \n",
       "\n",
       "                                     src_uri  src_type  dest_name  \\\n",
       "377                                           playlist              \n",
       "467                                           playlist              \n",
       "712                                           playlist              \n",
       "1011                                          playlist              \n",
       "1148                                          playlist              \n",
       "...                                      ...       ...        ...   \n",
       "358416  spotify:track:7ek8SSCHpRuZQclgonvjJh     track  Party mix   \n",
       "359953  spotify:track:3RZrtVbjRfs9QTJx5nexVi     track  Party mix   \n",
       "361173  spotify:track:4vByq0ENplmS7kXAVOVNvq     track  Party mix   \n",
       "361419  spotify:track:4Pa5XXpn3sdBPMVCSWGEhB     track  Party mix   \n",
       "362179  spotify:track:2HCaIYjkvWSZzaSKUoOh3d     track  Party mix   \n",
       "\n",
       "                                    dest_uri dest_type  \n",
       "377     spotify:track:7kT30Qf4aSg9lrwxsnGS2I     track  \n",
       "467     spotify:track:5AnszA1GMtDt8CFIWMnwyg     track  \n",
       "712     spotify:track:2AgnbuzvnfPvq1sAYNB4pj     track  \n",
       "1011    spotify:track:1EAb9MI3olU3eiyGhrMylw     track  \n",
       "1148    spotify:track:56DJzEuZugYdTYxi6VAdVh     track  \n",
       "...                                      ...       ...  \n",
       "358416                                        playlist  \n",
       "359953                                        playlist  \n",
       "361173                                        playlist  \n",
       "361419                                        playlist  \n",
       "362179                                        playlist  \n",
       "\n",
       "[406 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e555332b-4acd-4e25-8649-8c794c3fbb23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spotify:track:7kT30Qf4aSg9lrwxsnGS2I',\n",
       " 'spotify:track:5AnszA1GMtDt8CFIWMnwyg',\n",
       " 'spotify:track:2AgnbuzvnfPvq1sAYNB4pj',\n",
       " 'spotify:track:1EAb9MI3olU3eiyGhrMylw',\n",
       " 'spotify:track:56DJzEuZugYdTYxi6VAdVh',\n",
       " 'spotify:track:6K1UgfyTeJOW1pQkIw9cHL',\n",
       " 'spotify:track:4J0S4iVmMT2RD4LaSCvLrT',\n",
       " 'spotify:track:3GXJpmAGmA7SHUcB7xiejo',\n",
       " 'spotify:track:4TkVE9FZudrKDdchZNTMqL',\n",
       " 'spotify:track:5M3Y5AtDjsiXsEYtah1c0R',\n",
       " 'spotify:track:1yxoUrEVFXcvKe8jrlXGVd',\n",
       " 'spotify:track:4fIRVjtM6yoWPUrpQ1WH3H',\n",
       " 'spotify:track:13Jvkdmbus4Cf6D91CSO6p',\n",
       " 'spotify:track:1D7RHL8KWWOyPl5X7cElsw',\n",
       " 'spotify:track:3Naj4ZtvX9VpVqJH5EKmJE',\n",
       " 'spotify:track:6MfpM5Z0gY42xmOwQ3nrm3',\n",
       " 'spotify:track:4LtHd4nHs1LRyFrGsU9s3v',\n",
       " 'spotify:track:22kJbF8NaXKDwFEDjQxcf2',\n",
       " 'spotify:track:2QDf6mnHb0psGcXU2UO9Mp',\n",
       " 'spotify:track:5kKVGP5CQNuGiFN30cFZVw',\n",
       " 'spotify:track:3pwhYvXh6ttZfxEqkeInQv',\n",
       " 'spotify:track:1bU5AEaGYVTRt6j5IpYjTF',\n",
       " 'spotify:track:5HPYc7OqbVUYZQpKEI6YPR',\n",
       " 'spotify:track:7z3hDHOkDUJxB1ofhrSfhG',\n",
       " 'spotify:track:5FXinDq5ECCkhl1fHhhB90',\n",
       " 'spotify:track:0gRedthAOexVO8oOmJvq9F',\n",
       " 'spotify:track:643E7BAZ933AZJM0QvjlxR',\n",
       " 'spotify:track:1SkJ8HjZUZRPYT3R2rh5sA',\n",
       " 'spotify:track:4tgxRBUUwNxCVden2yWyBw',\n",
       " 'spotify:track:3qgPPTB31zBqv7EtZG6HBN',\n",
       " 'spotify:track:3oiHKYb11NDsLlHJZXYa53',\n",
       " 'spotify:track:2xNZeeqmwMPVKnD7FSQfgt',\n",
       " 'spotify:track:2Vdub5mY4lad7w64bFPUez',\n",
       " 'spotify:track:29V94tQgMoSJjbzuTliPj6',\n",
       " 'spotify:track:16GmLvMVnRY9HIUyeFzbKy',\n",
       " 'spotify:track:3zyySJVPMSDF57tB7KbWlI',\n",
       " 'spotify:track:2Kj7fT9h3jRAYIpRBOjsh9',\n",
       " 'spotify:track:1UafwyGQRo7BXijO1h3nGR',\n",
       " 'spotify:track:4zsusQcOGMYEQQFDz5iSWl',\n",
       " 'spotify:track:0KcqdKaqEOU41IX0WatVFN',\n",
       " 'spotify:track:47mjwLEG8w4ml03hGUKABi',\n",
       " 'spotify:track:6oYZ98ovzxx4rCspU6F5v4',\n",
       " 'spotify:track:6Ehy8wRUYjAZcMMRCxMZVM',\n",
       " 'spotify:track:3CAvPsgqfGkCaxkdgqNf5j',\n",
       " 'spotify:track:1mzPFYtJgR26JqpL5DYkCA',\n",
       " 'spotify:track:43nCRvhyrjS11bLH1oldw6',\n",
       " 'spotify:track:6ZtUAt1b7sEY6RmRSGfIaB',\n",
       " 'spotify:track:6CTxqx9pxaoOxOYZSbsqDc',\n",
       " 'spotify:track:12tihA9wedPwtlvS8kWMuM',\n",
       " 'spotify:track:5jpmn1Bza0X1jBbq69Wij7',\n",
       " 'spotify:track:3R9iSdYqV6eFSPtNxvgb7x',\n",
       " 'spotify:track:4IJolHVEyC8D92jULBjmKj',\n",
       " 'spotify:track:0ERGzuyTquZmQwOmeZLZpr',\n",
       " 'spotify:track:70zZclGWOjOVv9VRJ7RCyq',\n",
       " 'spotify:track:1dbt3sOwRmUOLfQZSpSz9O',\n",
       " 'spotify:track:3Ylsz3BQ8mJ9D6gE6XqDlz',\n",
       " 'spotify:track:5BcPxSGHqapDTpOdZHvc4G',\n",
       " 'spotify:track:1J2NzDowtDbeJBlMpAC3II',\n",
       " 'spotify:track:2awizf15wPZXElxgWb92D9',\n",
       " 'spotify:track:0fuCG8Lf378CSOBFzkSr1E',\n",
       " 'spotify:track:13zBKBrKYnew5n3SGrDoyT',\n",
       " 'spotify:track:7JmPqImeW3kLoYVNBA9v11',\n",
       " 'spotify:track:2yuyaYAELoMG4ApV5wJsWR',\n",
       " 'spotify:track:4tJB5f9Pw6yuVjMmAzNK8U',\n",
       " 'spotify:track:7AISfO3poeXEWsuiqhX9MN',\n",
       " 'spotify:track:1zEGq2ScBI7ecxAKh7K0Qt',\n",
       " 'spotify:track:2oCIHudP9wgI3OshvOtNfG',\n",
       " 'spotify:track:7p8vwbbf9sMQbrdQrsmTlI',\n",
       " 'spotify:track:6MbH1QiphMCPTqVEVC7UYi',\n",
       " 'spotify:track:1zuGHW5axtzu3NNrEr4vvY',\n",
       " 'spotify:track:6F7QV44CtTLFUQFmfD8neM',\n",
       " 'spotify:track:0LWINYMC4s8QTdDSb1B3Q3',\n",
       " 'spotify:track:1csCL23aUFKAhf60AJLLXZ',\n",
       " 'spotify:track:2QmU4B8fsyWcTQLVDl06Pk',\n",
       " 'spotify:track:1KONmY3enP3r3nIPQidWAy',\n",
       " 'spotify:track:1dx0My2ZqgsCmnHqkYBQYQ',\n",
       " 'spotify:track:7EaScyD2SKCSvZHqsY0RSK',\n",
       " 'spotify:track:0AgvoyAbNRuLVgTQXtsk6q',\n",
       " 'spotify:track:2FUPJxcJwZu4F7H4gs3wCu',\n",
       " 'spotify:track:3hE1UD7Mbcvd8j9rsbhoch',\n",
       " 'spotify:track:5DjLed65sri5juDG6kdPPK',\n",
       " 'spotify:track:2HfKAe4ZlaJXjrggObJ24P',\n",
       " 'spotify:track:1pVfFIMl22irgWpMxZWdFa',\n",
       " 'spotify:track:4L55p6txv9vuCWhpNnY6eY',\n",
       " 'spotify:track:0xMdUMEDwuRQ9DCg67V8eh',\n",
       " 'spotify:track:5AeWBUrE7lciBJP3YlzzIw',\n",
       " 'spotify:track:07dwsKa2Hp36BumkF9vKWt',\n",
       " 'spotify:track:2yvjjJrWzVzA2zg4VsoEmo',\n",
       " 'spotify:track:5fghXy9xCMweLOu6kQgAul',\n",
       " 'spotify:track:42DlsaUqEatNl8Md9VlFLr',\n",
       " 'spotify:track:0tyJAX9WrXG40nJGn3DzpS',\n",
       " 'spotify:track:305xhcwBs5dKxh8Uih0Svz',\n",
       " 'spotify:track:18WhWzFnqEbE04y4H5Y13z',\n",
       " 'spotify:track:3CrZCobEktNOnE2HSPU0jN',\n",
       " 'spotify:track:0QiUEowZX0wzCOePBOHgs6',\n",
       " 'spotify:track:7412fpVfB2PSSb1nENQczC',\n",
       " 'spotify:track:20g7GNNbr6lSlhVGb37vjT',\n",
       " 'spotify:track:4t1dkVSUytQdV6VstXWPmN',\n",
       " 'spotify:track:5yXILCffBoNoDK55bZ4tV3',\n",
       " 'spotify:track:2CsFqLUceIkQhXdfgOe6u1',\n",
       " 'spotify:track:1CyyowhXfQTd549mtotdag',\n",
       " 'spotify:track:48soTbO64fT2Xw3xxvAXY5',\n",
       " 'spotify:track:0Clb9aiXWa0dvVff5aN4VN',\n",
       " 'spotify:track:3IiDwgqzxsCp4BjMQaRbc6',\n",
       " 'spotify:track:65gflrWoZCPgxq1wusZbdW',\n",
       " 'spotify:track:0d8osZ7OdN7VeoswbwTrGl',\n",
       " 'spotify:track:7kGOXJNLRBJ8WfIAYnFxfu',\n",
       " 'spotify:track:3ygeH2d1KSSAW4AdkVz0dj',\n",
       " 'spotify:track:0dY7CeoOMM3dhE7gqRwyXN',\n",
       " 'spotify:track:0ZUJJOh6eD2Vsp0DPIDn6m',\n",
       " 'spotify:track:7cU84qjHFxJ39COxWltHyY',\n",
       " 'spotify:track:7kMUnG3NBADRQ07MLLul0J',\n",
       " 'spotify:track:6BXCXOJGvuhks2xDxj5opi',\n",
       " 'spotify:track:0KETaRfod0c2Qow4MaPW9r',\n",
       " 'spotify:track:3ahf0PSKlkJ0rYSNCJpsPI',\n",
       " 'spotify:track:6kyTI5SOVZP7Z45ad2DnyW',\n",
       " 'spotify:track:3XRosKfSgFSDIb6YVpApIl',\n",
       " 'spotify:track:2kzi8vfSiPsXbchZy9T0aC',\n",
       " 'spotify:track:1eREJIBdqeCcqNCB1pbz7w',\n",
       " 'spotify:track:5X4xiGkbxJxsgxRJrTlCpo',\n",
       " 'spotify:track:0FRDRVD3PCsp5EwroPcXxi',\n",
       " 'spotify:track:0bDl8ztrF7V5d4s7zjcCEi',\n",
       " 'spotify:track:0gZXockVcE7rEhSf4mcGLO',\n",
       " 'spotify:track:2w0nIRl9BhixD3DcS1Mz3g',\n",
       " 'spotify:track:0VMGij4wSGBM5pSTcqjxeD',\n",
       " 'spotify:track:6JWLeCDXGkCFlB6aIDNsCF',\n",
       " 'spotify:track:4I7B083Xi0GdfjRoW8HZU6',\n",
       " 'spotify:track:0prF3F4FoKvxBObaeXLVHv',\n",
       " 'spotify:track:2p2VPbDlG1JBkHNwfaV5DB',\n",
       " 'spotify:track:5htB2gxndGHrLb09x1Q3Vp',\n",
       " 'spotify:track:7J2c7zGkjwSEkBXtEWbK6Q',\n",
       " 'spotify:track:4vJC6quMqr0iLTBgliJKRj',\n",
       " 'spotify:track:41PzVCv2ZfKlJo19JhfBU2',\n",
       " 'spotify:track:6AwhEQqt6vhnJBc2jBYvWI',\n",
       " 'spotify:track:0SHaXghBSGuF9JJfTtWVfE',\n",
       " 'spotify:track:4CigRqWjnodWWGJcd9Wee9',\n",
       " 'spotify:track:4SSUj4OC7giqpMNCqSQSCf',\n",
       " 'spotify:track:4WC72P8F0CnYmqoPYQ7JDD',\n",
       " 'spotify:track:5CLgxLf4wuOgxRgZVc4gJ1',\n",
       " 'spotify:track:7hOT8pFf1nuYDdKXNoJLhq',\n",
       " 'spotify:track:323bMKFBvCrQ7YSrdCps3W',\n",
       " 'spotify:track:55YYsAeziwm3etSsQsOIHj',\n",
       " 'spotify:track:4YhITuwINLCfXYB2WCXbCZ',\n",
       " 'spotify:track:23Sf3sg4zl4op3rAedJflk',\n",
       " 'spotify:track:4qkwbl6SxwLE09pxLAFINt',\n",
       " 'spotify:track:33umhvUI5zJRxXDQcYk4Uj',\n",
       " 'spotify:track:2iqIPpMrW9DCcs6XmxNFsY',\n",
       " 'spotify:track:3UHx9VPh33R8BnJZGOQEbI',\n",
       " 'spotify:track:5ewr9QysrDiVbplvOjSM4q',\n",
       " 'spotify:track:7cKeJC6BEEFiHH6pEBVMx5',\n",
       " 'spotify:track:6lE0EQBi3rDPATJwK8l1Lb',\n",
       " 'spotify:track:1o9XCbgjktDuSuUyGqQxL2',\n",
       " 'spotify:track:3qRHCvn70YpVFFkx3lrAYf',\n",
       " 'spotify:track:4cRBqWBjuccCowYVHFlXK6',\n",
       " 'spotify:track:2vBiZ7nBe0OqTZKWGP0s4K',\n",
       " 'spotify:track:72C7aUQECOhNtnD0AC36ua',\n",
       " 'spotify:track:5i4zbHovxe43ohUdiso6Od',\n",
       " 'spotify:track:4ZVBqVlBh5cIPfN7A3gIFh',\n",
       " 'spotify:track:1Y6Dv0tWYUP3Za2Es9FUL2',\n",
       " 'spotify:track:2piOfmTVFKnBGPpF23wMzi',\n",
       " 'spotify:track:5H0dVldtI6HJZnEXzigKfY',\n",
       " 'spotify:track:6UlVoivrSMVoyhdc5S2tVk',\n",
       " 'spotify:track:0PF4cbrLPZsteUM79VGKGE',\n",
       " 'spotify:track:20aASiwfsbiLlaJxLiC0PQ',\n",
       " 'spotify:track:1kFlDnWmBTvCBxxeGDpIdp',\n",
       " 'spotify:track:4Th9Lu8GK0mt5fZZ945FI7',\n",
       " 'spotify:track:2sKPcYAyK5mvxpMCQ1H3tn',\n",
       " 'spotify:track:5eReOqbysgLsqGp2ukMUYp',\n",
       " 'spotify:track:3rB2bdrGTsyRuqapUeOMz1',\n",
       " 'spotify:track:1QWmv7Q5ZJ6U8JhuDpjlbs',\n",
       " 'spotify:track:2xaBVOUpin9dEatw4XmDM2',\n",
       " 'spotify:track:5pyB5WEAEwqwl18UaBLeBl',\n",
       " 'spotify:track:1CAijerspiGnyZHAVsGNL1',\n",
       " 'spotify:track:3YimpODfNhxj3rN81v4WvE',\n",
       " 'spotify:track:57YdMPc7dJ6bqGPZmOAwFU',\n",
       " 'spotify:track:0gw9a1fn6zjm5R2so99TOT',\n",
       " 'spotify:track:1rbo24aGVuICTyvOc6oXCd',\n",
       " 'spotify:track:0v9kGNjkKdQUdDoBIuiph4',\n",
       " 'spotify:track:5Bh8l8evdBSIoaK6EP1bWI',\n",
       " 'spotify:track:4q4hefWcEkJiJtRvuJealM',\n",
       " 'spotify:track:453spNn4mGdYErYt3rGhSX',\n",
       " 'spotify:track:1fYypIR0kaFzaSRbzvtjl9',\n",
       " 'spotify:track:2LjmbI7LJt0RDg612cBi7U',\n",
       " 'spotify:track:1z35crfs2inLHpArGKuHFd',\n",
       " 'spotify:track:1rqabwvXVdFg5PtQ5dbk1U',\n",
       " 'spotify:track:5056hl2cR0ay3PeGDJD9hN',\n",
       " 'spotify:track:6n2F1s16SE5Uvy8707zdLh',\n",
       " 'spotify:track:76MFbWyoqceiUK92eOynGh',\n",
       " 'spotify:track:06XyjfMYbg5kcMyRHSlg4o',\n",
       " 'spotify:track:0Q9f1NBvKCC37V4oJVEgCh',\n",
       " 'spotify:track:6KDuspKQIGzhrPtaIrKNFG',\n",
       " 'spotify:track:4yEgz7iwiZklR8Xw28BbGR',\n",
       " 'spotify:track:0xaHohEUNSAwNsGedLAtBf',\n",
       " 'spotify:track:67IGg0W5lTFncEOlZzFDlt',\n",
       " 'spotify:track:2xqgc94vuJbV6JVLYfQspx',\n",
       " 'spotify:track:44KCu0cY5QnVqtQr6JWI4P',\n",
       " 'spotify:track:08ks6P9JP6uG9CCsySfnZq',\n",
       " 'spotify:track:2npw9XuCQpHXM9ramYL4HR',\n",
       " 'spotify:track:7ek8SSCHpRuZQclgonvjJh',\n",
       " 'spotify:track:3RZrtVbjRfs9QTJx5nexVi',\n",
       " 'spotify:track:4vByq0ENplmS7kXAVOVNvq',\n",
       " 'spotify:track:4Pa5XXpn3sdBPMVCSWGEhB',\n",
       " 'spotify:track:2HCaIYjkvWSZzaSKUoOh3d',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f07ffd0-0996-4152-8860-2de9e3b8762d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SpotifyException",
     "evalue": "http status: 400, code:-1 - Unsupported URL / URI., reason: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSpotifyException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         info\u001b[38;5;241m.\u001b[39mappend((track_name, artist_name))\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m info\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(gettrackname(uri_list))\n",
      "Cell \u001b[0;32mIn[81], line 16\u001b[0m, in \u001b[0;36mgettrackname\u001b[0;34m(uri_list)\u001b[0m\n\u001b[1;32m     13\u001b[0m info \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uri \u001b[38;5;129;01min\u001b[39;00m uri_list:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Use the track method to get information about the track\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     track_info \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mtrack(uri)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Get the track name from the track information\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     track_name \u001b[38;5;241m=\u001b[39m track_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/cudatorch/lib/python3.11/site-packages/spotipy/client.py:368\u001b[0m, in \u001b[0;36mSpotify.track\u001b[0;34m(self, track_id, market)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack\u001b[39m(\u001b[38;5;28mself\u001b[39m, track_id, market\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124;03m\"\"\" returns a single track given the track's ID, URI or URL\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m        Parameters:\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m            - track_id - a spotify URI, URL or ID\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m            - market - an ISO 3166-1 alpha-2 country code.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     trid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m, track_id)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtracks/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m trid, market\u001b[38;5;241m=\u001b[39mmarket)\n",
      "File \u001b[0;32m~/.conda/envs/cudatorch/lib/python3.11/site-packages/spotipy/client.py:1988\u001b[0m, in \u001b[0;36mSpotify._get_id\u001b[0;34m(self, type, id)\u001b[0m\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mid\u001b[39m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;66;03m# TODO change to a ValueError in v3\u001b[39;00m\n\u001b[0;32m-> 1988\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m SpotifyException(\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported URL / URI.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mSpotifyException\u001b[0m: http status: 400, code:-1 - Unsupported URL / URI., reason: None"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "def gettrackname(uri_list):\n",
    "    # Replace the values below with your own Spotify API credentials\n",
    "    client_id = 'd5566a60926740f3a8070889731a2d21'\n",
    "    client_secret = 'eb5fc0638a1241c3a611186ff8d167e3'\n",
    "\n",
    "    # Initialize the Spotify API client\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "    info = []\n",
    "    for uri in uri_list:\n",
    "        # Use the track method to get information about the track\n",
    "        track_info = sp.track(uri)\n",
    "\n",
    "        # Get the track name from the track information\n",
    "        track_name = track_info['name']\n",
    "        track_info = sp.track(uri)\n",
    "\n",
    "        # Get the artist name from the track information\n",
    "        artist_name = track_info['artists'][0]['name']\n",
    "        info.append((track_name, artist_name))\n",
    "        \n",
    "    return info\n",
    "\n",
    "print(gettrackname(uri_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97554ce9-7e68-4b62-8185-f6266bf56a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81b8d7-8780-46d1-8f13-6b622f83928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b4c06-d86a-4359-9420-63bdb8742c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df22e9-6716-4101-a0a9-7a06fdace80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0b57a-939a-43c7-b90e-81f7a512aa86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d4504-c4c3-41a6-a184-7c10579874af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
