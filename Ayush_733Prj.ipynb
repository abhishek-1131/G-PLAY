{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tDg8TUDrFDl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "print(torch.zeros(1).cuda())\n",
        "\n",
        "import torch_geometric\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "print(torch_geometric.__version__)\n",
        "\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType, OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "\n",
        "import networkx as nx\n",
        "from deepsnap.hetero_graph import HeteroGraph\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import pickle\n",
        "\n",
        "import deepsnap\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from deepsnap.hetero_gnn import forward_op\n",
        "from deepsnap.hetero_graph import HeteroGraph\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import json\n",
        "from pathlib import Path as Data_Path\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from itertools import combinations\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import graph_tool.all as gt\n",
        "import json\n",
        "print(\"graph-tool version: {}\".format(gt.__version__.split(' ')[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/home/asa489/Downloads/updated_fixed_graph.pickle\", \"rb\") as f:\n",
        "    g_nx = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "NW9h7O-QrH4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(g_nx.nodes()))}\n",
        "\n",
        "# reindex the nodes in the graph\n",
        "g_nx = nx.relabel_nodes(g_nx, mapping)\n"
      ],
      "metadata": {
        "id": "uPHD5s8QrJfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DeepSNAP graph from NetworkX graph\n",
        "ds_graph = Graph(g_nx)"
      ],
      "metadata": {
        "id": "YQQfq_1ErLLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of vertices:\", g_nx.number_of_nodes())\n",
        "print(\"Number of edges:\", g_nx.number_of_edges())\n"
      ],
      "metadata": {
        "id": "KBTruUaHrMpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = 'link_pred'\n",
        "dataset = GraphDataset([ds_graph], task=task, edge_train_mode='disjoint')\n",
        "\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "# dataset_train[0].to('cuda')\n",
        "# dataset_val[0].to('cuda')\n",
        "# dataset_test[0].to('cuda')\n",
        "\n",
        "# dataset_train.to('cuda:0')\n",
        "# dataset_val.to('cuda:0')\n",
        "# dataset_test.to('cuda:0')\n",
        "\n",
        "print(type(dataset_train))\n",
        "print(dataset_train[0])\n",
        "print(type(dataset_train[0]))\n",
        "\n",
        "num_train_edges = dataset_train[0].edge_label_index.shape[1]\n",
        "num_val_edges = dataset_val[0].edge_label_index.shape[1]\n",
        "num_test_edges = dataset_test[0].edge_label_index.shape[1]\n",
        "\n",
        "print(\"Train set has {} supervision (positive) edges\".format(num_train_edges // 2))\n",
        "print(\"Validation set has {} supervision (positive) edges\".format(num_val_edges // 2))\n",
        "print(\"Test set has {} supervision (positive) edges\".format(num_test_edges // 2))\n",
        "\n",
        "print(\"Train set has {} message passing edges\".format(dataset_train[0].edge_index.shape[1]))\n",
        "print(\"Validation set has {} message passing edges\".format(dataset_val[0].edge_index.shape[1]))\n",
        "print(\"Test set has {} message passing edges\".format(dataset_test[0].edge_index.shape[1]))\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "08wGelzbrN63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(dataset_train, open('./fixed_graphs/train.graph', 'wb'))"
      ],
      "metadata": {
        "id": "WmNah0aarQEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(dataset_val, open('./fixed_graphs/val.graph', 'wb'))"
      ],
      "metadata": {
        "id": "c8RFaDEirSA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(dataset_test, open('./fixed_graphs/test.graph', 'wb'))"
      ],
      "metadata": {
        "id": "7897UMgQrTWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = pickle.load(open('/home/asa489/fixed_graphs/train.graph', 'rb'))"
      ],
      "metadata": {
        "id": "kjDpraozrUxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_val = pickle.load(open('/home/asa489/fixed_graphs/val.graph', 'rb'))"
      ],
      "metadata": {
        "id": "thm1MDG1rWG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodeUri=nx.get_node_attributes(g_nx,'uri')\n",
        "node_dict = {v: k for k, v in nx.get_node_attributes(g_nx,'uri').items() if v}\n",
        "nodeId=nx.get_node_attributes(g_nx,'name')\n",
        "pl_dict={}\n",
        "for k, v in nx.get_node_attributes(g_nx,'name').items():\n",
        "    if(v):\n",
        "        if(v in pl_dict):\n",
        "            continue\n",
        "        else:\n",
        "            pl_dict[v]=k\n",
        "    \n",
        "track_nodes=red_nodes = [n for n, d in g_nx.nodes(data=True) if d.get(\"uri\") != \"\"]\n",
        "playlist_exist=[]\n",
        "\n",
        "playlist_node_label=[]\n",
        "playlist_edge_label=[[],[]]\n",
        "for u,v in g_nx.edges(1):\n",
        "    playlist_exist.append(v)\n",
        "\n",
        "for  x in track_nodes:\n",
        "    if(x in playlist_exist):\n",
        "        continue\n",
        "    else:\n",
        "        playlist_edge_label[0].append(1)\n",
        "        playlist_edge_label[1].append(x)\n",
        "        playlist_node_label.append(0)\n",
        "\n",
        "node_label_tensor=torch.tensor(playlist_node_label)\n",
        "edge_label_tensor=torch.tensor(playlist_edge_label)\n",
        "ds_graph.edge_label_index=edge_label_tensor\n",
        "ds_graph"
      ],
      "metadata": {
        "id": "mwVvjwzTrXZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=dataset_train[0].edge_label_index[torchdataset_train[0].edge_label==1]\n",
        "b=dataset_train[0].edge_label_index[1][dataset_train[0].edge_label==0]\n",
        "c=dataset_train[0].edge_label_index[0][dataset_train[0].edge_label==1]\n",
        "d=dataset_train[0].edge_label_index[0][dataset_train[0].edge_label==0]\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "NsFkkOTZrZAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "condition = torch.tensor([True, False, True])\n",
        "\n",
        "selected = x[condition]\n",
        "\n",
        "print(selected)"
      ],
      "metadata": {
        "id": "0XJSMH6IrXgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(torch.sort(c))\n",
        "print(torch.sort(a))\n",
        "print(torch.sort(d))\n",
        "print(torch.sort(b))\n",
        "print(c)\n",
        "print(a)\n",
        "print(d)\n",
        "print(b)\n",
        "print(torch.max(torch.sort(c).indices))\n",
        "print(torch.max(torch.sort(a).indices))\n",
        "dataset_train[0].edge_label_index"
      ],
      "metadata": {
        "id": "gy1tbWl7rbqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_graph.edge_index=ds_graph.edge_index.cpu()\n",
        "ds_graph.edge_label_index=ds_graph.edge_label_index.cpu()\n",
        "ds_graph.node_label_index=ds_graph.node_label_index.cpu()\n",
        "\n"
      ],
      "metadata": {
        "id": "Sx3FiMqtrdEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_dict"
      ],
      "metadata": {
        "id": "Mn2lLxjPrerN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls=[]\n",
        "counter=0\n",
        "for x,y in g_nx.nodes(data=True):\n",
        "    if(counter!=x):\n",
        "        print(x,counter,y)\n",
        "    ls.append(x)\n",
        "    counter=counter+1\n",
        "print(max(ls),len(ls))\n"
      ],
      "metadata": {
        "id": "_ZJjFwJwrgc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):  \n",
        "        super(LightGCNConv, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        out = self.propagate(edge_index, x=(x, x))\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "        out = x_j\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "        node_dim = self.node_dim\n",
        "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce='mean')\n",
        "        return out"
      ],
      "metadata": {
        "id": "kg1Gmjucri-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCN(torch.nn.Module):\n",
        "    def __init__(self, train_data, num_layers, emb_size=16, initialize_with_words=False):\n",
        "        super(LightGCN, self).__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        assert (num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(num_layers):\n",
        "            self.convs.append(LightGCNConv(input_dim, input_dim))\n",
        "\n",
        "        # Initialize using custom embeddings if provided\n",
        "        num_nodes = train_data.node_label_index.size()[0]\n",
        "        self.embeddings = nn.Embedding(num_nodes, emb_size)\n",
        "        if initialize_with_words:\n",
        "            self.embeddings.weight.data.copy_(train_datanode_features)\n",
        "        \n",
        "        self.loss_fn = nn.BCELoss()\n",
        "        self.num_layers = num_layers\n",
        "        self.emb_size = emb_size\n",
        "        self.num_modes = num_nodes\n",
        "\n",
        "    def forward(self, data):\n",
        "        edge_index, edge_label_index, node_label_index = data.edge_index, data.edge_label_index, data.node_label_index\n",
        "        layer_embeddings = []\n",
        "        \n",
        "        x = self.embeddings(node_label_index)\n",
        "        mean_layer = x\n",
        "\n",
        "        # We take an average of ever layer's node embeddings\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            # print(\"x shape\",x.shape)\n",
        "            # print(\"mean_layer shape\",mean_layer.shape)\n",
        "            mean_layer += x\n",
        "\n",
        "        mean_layer /= 4\n",
        "\n",
        "        # Prediction head is simply dot product\n",
        "        nodes_first = torch.index_select(x, 0, edge_label_index[0,:].long())\n",
        "        nodes_second = torch.index_select(x, 0, edge_label_index[1,:].long())\n",
        "\n",
        "        # Since we don't want a rank output, we create a sigmoid of the dot product\n",
        "        out = torch.sum(nodes_first * nodes_second, dim=-1) # FOR RANKING\n",
        "        pred = torch.sigmoid(out)\n",
        "\n",
        "        return torch.flatten(pred)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        pos_edge_label=label[label==1]\n",
        "        neg_edge_label=label[label==0]\n",
        "        pos_edge=pred[label==1]\n",
        "        neg_edge=pred[label==0]\n",
        "        pos_edg\n",
        "        return self.loss_fn(pred, label)"
      ],
      "metadata": {
        "id": "LKKqfZ2vrkps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device' : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'num_layers' : 4,\n",
        "    'emb_size' : 32,\n",
        "    'weight_decay': 1e-6,\n",
        "    'lr': 0.2,\n",
        "    'epochs': 200\n",
        "}\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "JhQYvXDgrmvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   \n",
        "datasets = {\n",
        "\n",
        "     'test': dataset_test[0]\n",
        "}     \n",
        "input_dim =0\n",
        "print(input_dim, args)"
      ],
      "metadata": {
        "id": "swQHIjprrowr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "def train(model, optimizer, args):\n",
        "    val_max = 0\n",
        "    best_model = model\n",
        "\n",
        "    for epoch in range(1, args['epochs'] + 1):\n",
        "        datasets['train'].to(args[\"device\"])\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(datasets['train'])\n",
        "        loss = model.loss(pred, datasets['train'].edge_label.type(pred.dtype))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Loss: {:.5f}, Val Loss: {:.5f}'\n",
        "        score_train, train_loss = test(model, 'train', args)\n",
        "        score_val, val_loss = test(model, 'val', args)\n",
        "#         score_test, test_loss = test(model, 'test', args)\n",
        "\n",
        "        losses.append((train_loss, val_loss))\n",
        "\n",
        "        print(log.format(epoch, score_train, score_val, train_loss, val_loss))\n",
        "        if val_max < score_val:\n",
        "            val_max = score_val\n",
        "            best_model = copy.deepcopy(model)\n",
        "\n",
        "    return best_model\n",
        "\n",
        "def test(model, mode, args):\n",
        "    model.eval()\n",
        "    score = 0\n",
        "    loss_score = 0\n",
        "\n",
        "    data = datasets[mode]\n",
        "    data.to(args[\"device\"])\n",
        "\n",
        "    pred = model(data)\n",
        "    loss = model.loss(pred, data.edge_label.type(pred.dtype))\n",
        "    score += roc_auc_score(data.edge_label.flatten().cpu().numpy(), pred.flatten().data.cpu().numpy())\n",
        "    loss_score += loss.item()\n",
        "\n",
        "    return score, loss_score"
      ],
      "metadata": {
        "id": "_cEx0Pwzrsln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightGCN(datasets['train'], args['num_layers'], emb_size=args['emb_size']).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "best_model = train(model, optimizer, args)\n",
        "log = \"Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Train Loss: {:.5f}, Val Loss: {:.5f}, Test Loss: {:.5f}\"\n",
        "best_train_roc, train_loss = test(best_model, 'train', args)\n",
        "best_val_roc, val_loss = test(best_model, 'val', args)\n",
        "best_test_roc, test_loss = test(best_model, 'test', args)\n",
        "print(log.format(best_train_roc, best_val_roc, train_loss, val_loss))"
      ],
      "metadata": {
        "id": "qhDe3-0-ruPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic=model.state_dict()\n",
        "torch.save(dic, 'pm_latest.pt')"
      ],
      "metadata": {
        "id": "fA47uqLbrv8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(losses, title):\n",
        "    train_loss, val_loss = zip(*losses)\n",
        "    steps = list(range(1, len(train_loss) + 1))\n",
        "    \n",
        "    min_val_loss = np.round(np.min(val_loss), 3)\n",
        "    # train_list = [math.log10(x) for x in train_loss]\n",
        "    # val_list = [math.log10(x) for x in val_loss]\n",
        "    \n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.plot(steps, train_loss, '-r', label='Training Loss')\n",
        "    plt.plot(steps, val_loss, '-b', label='Validation Loss')\n",
        "    plt.hlines(min_val_loss, 1, 50, colors='k', linestyles='dotted', label='Min Validation Loss: {}'.format(min_val_loss))\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    # plt.ylim((0.58, 0.71))\n",
        "    plt.title(title)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(title)\n",
        "    plt.savefig('train_val_loss.png')\n",
        "\n",
        "    return plt"
      ],
      "metadata": {
        "id": "x7JQQ_biryCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(losses, 'test')\n"
      ],
      "metadata": {
        "id": "ZUkxKvWPr3X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets['test']\n",
        "pred = model(data)\n"
      ],
      "metadata": {
        "id": "zVVsuIZdr7Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim=0\n",
        "newModel = LightGCN(dataset_train[0], args['num_layers'], emb_size=args['emb_size'])\n",
        "\n",
        "newModel.load_state_dict(torch.load('pm_latest.pt'))"
      ],
      "metadata": {
        "id": "a6mIa-Z4r9uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(newModel.embeddings(torch.tensor([1])).device)\n",
        "print(ds_graph.edge_label_index)\n",
        "pred=newModel(datasets['test'])\n"
      ],
      "metadata": {
        "id": "Z2KuVpVosDml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "RocCurveDisplay.from_predictions(\n",
        "  datasets['test'].edge_label,\n",
        "    pred.detach().numpy(),\n",
        "    color=\"darkorange\",\n",
        ")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
        "plt.axis(\"square\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BNfvZsDesF48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict={'pred':pred.detach().numpy(),'Track_node_label':ds_graph.edge_label_index[1].detach().numpy(),'Track_Uri':ls_trUri}\n",
        "df_rec_list=pd.DataFrame(df_dict)\n",
        "df_lessthan = df_rec_list[df_rec_list['pred'] > 0.5]\n",
        "df_lessthan=df_lessthan.sort_values('pred',ascending=False)\n",
        "uri_list=list(df_lessthan['Track_Uri'])\n",
        "ls_trUri=[]\n",
        "for x in ds_graph.edge_label_index[1]:\n",
        "    ls_trUri.append(g_nx.nodes[x.item()]['uri'])"
      ],
      "metadata": {
        "id": "32zvcwMisMVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = datasets['test']\n",
        "ds"
      ],
      "metadata": {
        "id": "zll65nuLsPCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.edge_label"
      ],
      "metadata": {
        "id": "9oZoSNwPscYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(ds.edge_label_index)"
      ],
      "metadata": {
        "id": "K3HTo44XseAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {'preds':pred.to('cpu').detach().numpy(), 'edge_label': ds.edge_label.to('cpu').detach().numpy(), 'src_node': ds.edge_label_index[0].to('cpu').detach().numpy(), 'dest_node': ds.edge_label_index[1].to('cpu').detach().numpy()}\n",
        "df = pd.DataFrame(dict1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4BvbFEDssfio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0 = df[df['edge_label'] == 0]\n",
        "df_0"
      ],
      "metadata": {
        "id": "kEWAtCpfsg42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = df[df['edge_label'] == 1]\n",
        "df_1"
      ],
      "metadata": {
        "id": "nMJpFApcsihN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lessthan = df_rec_list[df_rec_list['pred'] > 0.5]\n",
        "df_lessthan=df_lessthan.sort_values('pred',ascending=False)\n",
        "uri_list=list(df_lessthan['Track_Uri'])"
      ],
      "metadata": {
        "id": "EMyccr-Usj7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lessthan.iloc[0]['src_node']"
      ],
      "metadata": {
        "id": "0O9Bi6eQslLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_nx[0]"
      ],
      "metadata": {
        "id": "apET4ZNqsmhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lessthan.iloc[0][\"src_node\"]\n",
        "counter=0\n",
        "neg=0\n",
        "for x in g_nx.nodes:\n",
        "    if(counter!=x):\n",
        "        neg=neg+x-counter\n",
        "        counter=x\n",
        "    counter=counter+1\n",
        "print(len(g_nx.nodes))\n",
        "neg\n",
        "        "
      ],
      "metadata": {
        "id": "UL_Hqw78sofs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def row_op(row):\n",
        "\n",
        "    if g_nx.nodes[row['src_node']]['name'] == g_nx.nodes[row['dest_node']]['name'] or g_nx.nodes[row['src_node']]['uri'] == g_nx.nodes[row['dest_node']]['uri']:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "df_lessthan['is_valid'] = df_lessthan.apply(row_op,axis=1)\n",
        "df_filter=df_lessthan[df_lessthan['is_valid']] "
      ],
      "metadata": {
        "id": "3L84eORhsqAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getId(row):\n",
        "    return pd.Series([g_nx.nodes[row['src_node']]['name'],g_nx.nodes[row['src_node']]['uri'],g_nx.nodes[row['src_node']]['type'],g_nx.nodes[row['dest_node']]['name'],g_nx.nodes[row['dest_node']]['uri'],g_nx.nodes[row['dest_node']]['type']])\n",
        "    \n",
        "df_filter[[\"src_name\",\"src_uri\",\"src_type\",\"dest_name\",\"dest_uri\",\"dest_type\"]]=df_filter[df_lessthan['is_valid']].apply(getId,axis=1)"
      ],
      "metadata": {
        "id": "IM-ZwFawsrYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_filter[(df_filter['src_name']==\"Party mix\") | ( df_filter['dest_name']==\"Party mix\") ]\n",
        "df_final.sort_values('preds',ascending=False)\n",
        "uri_list=list(df_final.apply(lambda x: x['src_uri'] if x['src_uri']!='' else x['dest_uri'], axis=1 ))"
      ],
      "metadata": {
        "id": "icUyanW2stLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uri_list=[]\n",
        "uri_list = list(df_final[\"dest_uri\"])"
      ],
      "metadata": {
        "id": "pEfUdN1asukt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "def gettrackname(uri_list):\n",
        "    # Replace the values below with your own Spotify API credentials\n",
        "    client_id = 'd5566a60926740f3a8070889731a2d21'\n",
        "    client_secret = 'eb5fc0638a1241c3a611186ff8d167e3'\n",
        "\n",
        "    # Initialize the Spotify API client\n",
        "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
        "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
        "    counter=1\n",
        "\n",
        "    info = []\n",
        "    for uri in uri_list:\n",
        "        # Use the track method to get information about the track\n",
        "        track_info = sp.track(uri)\n",
        "\n",
        "        # Get the track name from the track information\n",
        "        track_name = track_info['name']\n",
        "        track_info = sp.track(uri)\n",
        "        print(track_info)\n",
        "        album=track_info['album']['uri']\n",
        "        album_info = sp.album(album)\n",
        "        image_uri=album_info['images'][0]['url']\n",
        "        preview_url = track_info['preview_url']\n",
        "        external_url = track_info['external_urls']['spotify']\n",
        "        # Get the artist name from the track information\n",
        "        artist_name = track_info['artists'][0]['name']\n",
        "        info.append((track_name, artist_name, image_uri, preview_url, external_url))\n",
        "        if(counter>10):\n",
        "            break\n",
        "        counter=counter+1\n",
        "        \n",
        "    return info\n",
        "\n",
        "print(gettrackname(uri_list))\n"
      ],
      "metadata": {
        "id": "NoI0Sjl8swpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}